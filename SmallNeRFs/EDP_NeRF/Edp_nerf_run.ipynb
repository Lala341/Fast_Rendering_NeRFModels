{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lala341/Fast_Rendering_Plenoctrees/blob/ChidiebereO/Edp_nerf_run.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the python3-venv package\n",
        "!apt install python3.10-venv\n",
        "\n",
        "# Create a virtual environment\n",
        "!python3 -m venv myenv\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcQjUqd5lmUb",
        "outputId": "768a25e5-ac44-4030-af11-39e462f35e41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  python3-pip-whl python3-setuptools-whl\n",
            "The following NEW packages will be installed:\n",
            "  python3-pip-whl python3-setuptools-whl python3.10-venv\n",
            "0 upgraded, 3 newly installed, 0 to remove and 19 not upgraded.\n",
            "Need to get 2,473 kB of archives.\n",
            "After this operation, 2,882 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-pip-whl all 22.0.2+dfsg-1ubuntu0.3 [1,679 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-setuptools-whl all 59.6.0-1.2ubuntu0.22.04.1 [788 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3.10-venv amd64 3.10.12-1~22.04.2 [5,724 B]\n",
            "Fetched 2,473 kB in 1s (3,192 kB/s)\n",
            "Selecting previously unselected package python3-pip-whl.\n",
            "(Reading database ... 120874 files and directories currently installed.)\n",
            "Preparing to unpack .../python3-pip-whl_22.0.2+dfsg-1ubuntu0.3_all.deb ...\n",
            "Unpacking python3-pip-whl (22.0.2+dfsg-1ubuntu0.3) ...\n",
            "Selecting previously unselected package python3-setuptools-whl.\n",
            "Preparing to unpack .../python3-setuptools-whl_59.6.0-1.2ubuntu0.22.04.1_all.deb ...\n",
            "Unpacking python3-setuptools-whl (59.6.0-1.2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package python3.10-venv.\n",
            "Preparing to unpack .../python3.10-venv_3.10.12-1~22.04.2_amd64.deb ...\n",
            "Unpacking python3.10-venv (3.10.12-1~22.04.2) ...\n",
            "Setting up python3-setuptools-whl (59.6.0-1.2ubuntu0.22.04.1) ...\n",
            "Setting up python3-pip-whl (22.0.2+dfsg-1ubuntu0.3) ...\n",
            "Setting up python3.10-venv (3.10.12-1~22.04.2) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Activate the virtual environment\n",
        "%env MYENV_DIR=myenv\n",
        "!source $MYENV_DIR/bin/activate\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUijf0r_lkNu",
        "outputId": "2deab55b-c691-4b97-ab26-e83900f1e878"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: MYENV_DIR=myenv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pil7ek6LznFF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cb7aa2c-5c78-46c8-ef17-2f41f4cb6326"
      },
      "source": [
        "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
        "%env CUDA_VISIBLE_DEVICES=0\n",
        "%env XLA_PYTHON_CLIENT_PREALLOCATE=false"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
            "env: CUDA_VISIBLE_DEVICES=0\n",
            "env: XLA_PYTHON_CLIENT_PREALLOCATE=false\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade rich -q\n",
        "!pip install ibis-framework rich==12.4.4 -q\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHhcbyNXr-GZ",
        "outputId": "b8afec5f-5e40-44b2-a3f6-153401933440"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/232.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.0/232.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/51.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nykOgSlZz2Nv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ec74bb3-0344-4c4a-d9ba-c8827adc26e9"
      },
      "source": [
        "# !pip install flax -q\n",
        "!pip install optax -q\n",
        "!pip install flax==0.5.3 -q"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.0/202.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m217.3/217.3 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ibis-framework 6.2.0 requires rich<14,>=12.4.4, but you have rich 11.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install --upgrade jax jaxlib -q\n",
        "# !pip install jaxlib==0.4.0 -q\n",
        "!pip install jax==0.3.2 -q\n",
        "!pip install jaxlib==0.1.75 -f https://storage.googleapis.com/jax-releases/jax_releases.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5UrAAoxp9dX",
        "outputId": "a68b136c-931b-4247-be9e-d339f7de963d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/926.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/926.4 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m926.4/926.4 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for jax (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "chex 0.1.7 requires jax>=0.4.6, but you have jax 0.3.2 which is incompatible.\n",
            "orbax-checkpoint 0.4.1 requires jax>=0.4.9, but you have jax 0.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in links: https://storage.googleapis.com/jax-releases/jax_releases.html\n",
            "Collecting jaxlib==0.1.75\n",
            "  Downloading https://storage.googleapis.com/jax-releases/nocuda/jaxlib-0.1.75-cp310-none-manylinux2010_x86_64.whl (62.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.2/62.2 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from jaxlib==0.1.75) (1.11.3)\n",
            "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.10/dist-packages (from jaxlib==0.1.75) (1.23.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from jaxlib==0.1.75) (1.4.0)\n",
            "Collecting flatbuffers<3.0,>=1.12 (from jaxlib==0.1.75)\n",
            "  Downloading flatbuffers-2.0.7-py2.py3-none-any.whl (26 kB)\n",
            "Installing collected packages: flatbuffers, jaxlib\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 23.5.26\n",
            "    Uninstalling flatbuffers-23.5.26:\n",
            "      Successfully uninstalled flatbuffers-23.5.26\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.4.16+cuda11.cudnn86\n",
            "    Uninstalling jaxlib-0.4.16+cuda11.cudnn86:\n",
            "      Successfully uninstalled jaxlib-0.4.16+cuda11.cudnn86\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "chex 0.1.7 requires jax>=0.4.6, but you have jax 0.3.2 which is incompatible.\n",
            "orbax-checkpoint 0.4.1 requires jax>=0.4.9, but you have jax 0.3.2 which is incompatible.\n",
            "tensorflow 2.14.0 requires flatbuffers>=23.5.26, but you have flatbuffers 2.0.7 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed flatbuffers-2.0.7 jaxlib-0.1.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HB0L-JkLznFJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "outputId": "369d5c77-1870-4c95-e2a6-e324d2cc43b8"
      },
      "source": [
        "import json\n",
        "import os\n",
        "from collections import defaultdict\n",
        "from functools import partial\n",
        "from random import sample as sample_no_duplicates\n",
        "\n",
        "import cv2\n",
        "import jax\n",
        "# import jax.v0_3_2\n",
        "import jax.numpy as jnp\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from flax import linen as nn\n",
        "import optax as optax\n",
        "# from flax import serialization\n",
        "# import flax as fx\n",
        "# from flax import optim\n",
        "from flax import optim, serialization\n",
        "from jax import grad, jit, random, value_and_grad, vmap\n",
        "from jax.config import config\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from tqdm.notebook import tqdm\n",
        "# config.enable_omnistaging()\n",
        "\n",
        "# Generate key which is used to generate random numbers\n",
        "rng = random.PRNGKey(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-758661642b14>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# import jax.v0_3_2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# We want the exported object to be the class, so we first import the module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# to make sure a later import doesn't overwrite the class.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mjax\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_config_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0m_config_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/config.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# flake8: noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_src\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/config.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_src\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_src\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjax_jit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxla_extension_version\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m58\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/lib/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0mversion_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjaxlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m version = check_jaxlib_version(\n\u001b[0m\u001b[1;32m     88\u001b[0m   \u001b[0mjax_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m   \u001b[0mjaxlib_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjaxlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/lib/__init__.py\u001b[0m in \u001b[0;36mcheck_jaxlib_version\u001b[0;34m(jax_version, jaxlib_version, minimum_jaxlib_version)\u001b[0m\n\u001b[1;32m     74\u001b[0m     msg = (f'jaxlib is version {jaxlib_version}, but this version '\n\u001b[1;32m     75\u001b[0m            f'of jax requires version >= {minimum_jaxlib_version}.')\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_jaxlib_version\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_jax_version\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: jaxlib is version 0.1.75, but this version of jax requires version >= 0.3.0."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "\n",
        "print(\"JAX version:\", jax.__version__)\n"
      ],
      "metadata": {
        "id": "rG_65QLAhjOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhPpG-s2znFJ"
      },
      "source": [
        "from enum import Enum\n",
        "class DatasetEnum(Enum):\n",
        "    NERF = \"nerf_example\"\n",
        "    TINY = \"tiny_nerf\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SG1ZprwHznFK"
      },
      "source": [
        "class AttrDict(dict):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(AttrDict, self).__init__(*args, **kwargs)\n",
        "        self.__dict__ = self\n",
        "cfg={\n",
        "    \"gpu_id\": 0,\n",
        "    \"lr\": 0.001,\n",
        "    \"num_epochs\": 200,\n",
        "    \"comments\": \"Final model + use 3D for view dir\",\n",
        "    \"near_clip\": 2.0,\n",
        "    \"far_clip\": 6.0,\n",
        "    \"ray_sample\": 32,\n",
        "    \"fine_ray_sample\": 64,\n",
        "    \"encode_num\": 10,\n",
        "    \"encode_num_view\": 4,\n",
        "    \"layer_num\": 6,\n",
        "    \"hidden_ch\": 128,\n",
        "    \"dataset_type\": \"NERF\",  # \"NERF\", \"TINY\"\n",
        "    \"half_res\": True,\n",
        "    \"testset_num\": 32,\n",
        "    \"workers\": 2,\n",
        "}\n",
        "cfg = AttrDict(cfg)\n",
        "\n",
        "\n",
        "# import wandb\n",
        "# wandb.init(\n",
        "#     project=\"nerf_practice\",\n",
        "#     config=cfg,\n",
        "# )\n",
        "# cfg = wandb.config\n",
        "cfg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fmwpgfy3znFK"
      },
      "source": [
        "ch_dim = 3\n",
        "view_dim = 3\n",
        "if not os.path.exists('./results'):\n",
        "    os.mkdir('./results')\n",
        "if not os.path.exists('./checkpoints'):\n",
        "    os.mkdir('./checkpoints')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTrAI7LZznFK"
      },
      "source": [
        "DATASET = getattr(DatasetEnum, cfg.dataset_type)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Gfb5RIMrznFK"
      },
      "source": [
        "DATASET"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MATdtvfAznFL"
      },
      "source": [
        "from os.path import join\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class TinyNeRFDataset(Dataset):\n",
        "    def __init__(self, npy_filename, split_type=\"train\", transform=None):\n",
        "        # Load data\n",
        "        data = np.load(npy_filename)\n",
        "        self.samples = []\n",
        "        for img, pose in zip(data[\"images\"], data[\"poses\"]):\n",
        "            # Adjust poses so that camera front is z+\n",
        "            T = np.eye(3)\n",
        "            T[1, 1] = -1\n",
        "            T[2, 2] = -1\n",
        "            pose[:3, :3] = pose[:3, :3].dot(T)\n",
        "            self.samples.append((img, pose))\n",
        "        self.focal = data[\"focal\"]\n",
        "\n",
        "        test_idx = 100\n",
        "        if split_type == \"train\":\n",
        "            self.samples = self.samples[:test_idx]\n",
        "        else:\n",
        "            self.samples = self.samples[test_idx:]\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img, pose = self.samples[idx]\n",
        "        sample = {\"img\": img, \"pose\": pose}\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "        sample[\"focal\"] = self.focal\n",
        "        return sample\n",
        "\n",
        "\n",
        "class NeRFDataset(Dataset):\n",
        "    object_names = [\n",
        "        \"chair\",\n",
        "        \"drums\",\n",
        "        \"ficus\",\n",
        "        \"hotdog\",\n",
        "        \"lego\",\n",
        "        \"materials\",\n",
        "        \"mic\",\n",
        "        \"ship\",\n",
        "    ]\n",
        "\n",
        "    def __init__(self, root_dir, split_type=\"train\", transform=None, half_res=False):\n",
        "        # Load data\n",
        "        self.root_dir = root_dir\n",
        "        self.half_res = half_res\n",
        "        json_filename = join(self.root_dir, f\"transforms_{split_type}.json\")\n",
        "        with open(json_filename) as f:\n",
        "            json_data = json.load(f)\n",
        "\n",
        "        self.samples = []\n",
        "        for frame in json_data[\"frames\"]:\n",
        "            img_fname = join(self.root_dir, frame[\"file_path\"] + \".png\")\n",
        "\n",
        "            pose = np.array(frame[\"transform_matrix\"])\n",
        "            # Adjust poses so that camera front is z+\n",
        "            T = np.eye(3)\n",
        "            T[1, 1] = -1\n",
        "            T[2, 2] = -1\n",
        "            pose[:3, :3] = pose[:3, :3].dot(T)\n",
        "            self.samples.append((img_fname, pose))\n",
        "\n",
        "        # focal length\n",
        "        img = self.load_image(img_fname)\n",
        "        h, w = img.shape[:2]\n",
        "        camera_angle_x = float(json_data[\"camera_angle_x\"])\n",
        "        self.focal = 0.5 * w / np.tan(0.5 * camera_angle_x)\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def load_image(self, img_fname):\n",
        "        img = cv2.imread(img_fname, cv2.IMREAD_UNCHANGED)\n",
        "        # Downsample\n",
        "        if self.half_res:\n",
        "            img = cv2.resize(img, (0, 0), fx=0.5, fy=0.5)\n",
        "        img = img.astype(np.float32) / 255.0\n",
        "\n",
        "        if img.shape[2] == 4:\n",
        "            # Add arbitrary background color for image with alpha\n",
        "            bkg = np.array([1.0, 1.0, 1.0], dtype=np.float32)\n",
        "            img_rgb = img[..., :3]\n",
        "            img_alpha = img[..., 3:]\n",
        "            img = img_rgb*img_alpha + bkg*(1.-img_alpha)\n",
        "        # BGR to RGB\n",
        "        img = np.array(img[...,::-1])\n",
        "        return img\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_fname, pose = self.samples[idx]\n",
        "        img = self.load_image(img_fname)\n",
        "        sample = {\"img\": img, \"pose\": pose}\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "        sample[\"focal\"] = self.focal\n",
        "        return sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYptnAf9znFL"
      },
      "source": [
        "# Data visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOFT7CFSznFL"
      },
      "source": [
        "if not os.path.exists('data/'):\n",
        "    # Load dataset using official script\n",
        "    !wget https://raw.githubusercontent.com/bmild/nerf/master/download_example_data.sh\n",
        "    !bash download_example_data.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yttBqshXznFL"
      },
      "source": [
        "from torch.utils.data import Subset\n",
        "print(\"Dataset type:\", DATASET)\n",
        "if DATASET == DatasetEnum.NERF:\n",
        "    root_dir = './data/nerf_synthetic/lego'\n",
        "    if not os.path.split(root_dir)[-1] in NeRFDataset.object_names:\n",
        "        print(\"The object might not be included\")\n",
        "    trainset = NeRFDataset(root_dir, split_type=\"train\", half_res=cfg.half_res)\n",
        "    all_testset = NeRFDataset(root_dir, split_type=\"test\", half_res=cfg.half_res)\n",
        "elif DATASET == DatasetEnum.TINY:\n",
        "    tiny_data = \"tiny_nerf_data.npz\"\n",
        "    trainset = TinyNeRFDataset(tiny_data, split_type=\"train\")\n",
        "    all_testset = TinyNeRFDataset(tiny_data, split_type=\"test\")\n",
        "    cfg.testset_num = 0\n",
        "else:\n",
        "    raise Exception(\"Unknown dataset\")\n",
        "\n",
        "if cfg.testset_num > 0:\n",
        "    testset = Subset(all_testset, range(cfg.testset_num))\n",
        "else:\n",
        "    testset = all_testset\n",
        "print(f\"Dataset size:\", len(trainset), len(testset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2M9zyYaxznFM"
      },
      "source": [
        "def drawAxis(T=np.eye(4), scale=0.3, colors=[\"r\", \"g\", \"b\"]):\n",
        "    tvec = T[:3, 3]\n",
        "    R = T[:3, :3]\n",
        "    start = tvec.flatten()[np.newaxis].repeat(3, axis=0)\n",
        "    end = start + scale * R.T\n",
        "    for s, e, c in zip(start, end, colors):\n",
        "        ax.plot([s[0], e[0]], [s[1], e[1]], [s[2], e[2]], c=c)\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWTbsSyzznFM"
      },
      "source": [
        "# Load data\n",
        "sample = trainset[0]\n",
        "img = sample['img']\n",
        "pose = sample['pose']\n",
        "focal = sample['focal']\n",
        "print(\"focal:\", focal)\n",
        "\n",
        "camera_bnd = np.array([it['pose'][:3, 3] for it in trainset])\n",
        "print(\"Camera position range\")\n",
        "print(camera_bnd.max())\n",
        "print(camera_bnd.min())\n",
        "camera_bnd_max = max(abs(camera_bnd.max()), abs(camera_bnd.min()))\n",
        "print(camera_bnd_max)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-GV1PCNznFM"
      },
      "source": [
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fO12YCGznFN"
      },
      "source": [
        "def collate_fn(batch):\n",
        "    sample = {key: [] for key in batch[0].keys()}\n",
        "    for it in batch:\n",
        "        for key, val in it.items():\n",
        "            sample[key].append(val)\n",
        "    sample = {key: np.stack(val) for key, val in sample.items()}\n",
        "    return sample\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZjWKamZznFN"
      },
      "source": [
        "# Get data from batch\n",
        "# batch = iter(DataLoader(trainset, batch_size=32, shuffle=False, collate_fn=collate_fn)).next()\n",
        "# imgs = batch[\"img\"]\n",
        "# poses = batch[\"pose\"]\n",
        "\n",
        "\n",
        "# Get data from batch\n",
        "data_loader = DataLoader(trainset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
        "batch = next(iter(data_loader))\n",
        "imgs = batch[\"img\"]\n",
        "poses = batch[\"pose\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPGDv0F4znFN"
      },
      "source": [
        "idx = 0\n",
        "fig, ax = plt.subplots(1, 4, figsize=(7, 4))\n",
        "for i in range(4):\n",
        "    ax[i].imshow(imgs[idx + i])\n",
        "\n",
        "# 3D Plot\n",
        "fig = plt.figure(figsize=(6, 6))\n",
        "ax = Axes3D(fig)\n",
        "ax.set_xlabel(\"X\")\n",
        "ax.set_ylabel(\"Y\")\n",
        "ax.set_zlabel(\"Z\")\n",
        "# ax.axis('off')\n",
        "c = [\"c\", \"y\", \"k\", \"b\"]\n",
        "\n",
        "for i in range(4):\n",
        "    colors = [\"r\", \"g\", c[i]]\n",
        "    drawAxis(poses[idx + i], 0.6, colors)\n",
        "\n",
        "# Origin\n",
        "drawAxis()\n",
        "\n",
        "# adjust scale\n",
        "scale = 7\n",
        "start = np.zeros((3, 3)) - scale / 2\n",
        "end = start + scale * np.eye(3)\n",
        "for s, e in zip(start, end):\n",
        "    ax.plot([s[0], e[0]], [s[1], e[1]], [s[2], e[2]], c=\"none\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARmeTgfDznFN"
      },
      "source": [
        "## Camera pose generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJ6dcqtzznFN"
      },
      "source": [
        "def spherical_to_xyz(r, theta, phi):\n",
        "    assert theta.shape == phi.shape == r.shape\n",
        "    x = r * jnp.sin(theta) * jnp.cos(phi)\n",
        "    y = r * jnp.sin(theta) * jnp.sin(phi)\n",
        "    z = r * jnp.cos(theta)\n",
        "    return jnp.stack([x, y, z], axis=-1)\n",
        "\n",
        "\n",
        "def xyz_to_spherical(pts):\n",
        "    x = pts[..., 0]\n",
        "    y = pts[..., 1]\n",
        "    z = pts[..., 2]\n",
        "\n",
        "    len_xy = jnp.hypot(x, y)\n",
        "    r = jnp.hypot(z, len_xy)\n",
        "    theta = jnp.arctan2(z, len_xy)\n",
        "    phi = jnp.arctan2(y, x)\n",
        "    return r, theta, phi\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFg-CN0cznFN"
      },
      "source": [
        "# Generate camera pose\n",
        "def get_camera_poses(\n",
        "    r, theta, phi, lookat=np.array([0, 0, 0.5]), up=np.array([0, 0, 1])\n",
        "):\n",
        "    # Camera position in world coord\n",
        "    cam_pts = spherical_to_xyz(r, theta, phi)\n",
        "    # Camera orientation\n",
        "    zaxis = lookat - cam_pts\n",
        "    zaxis /= np.linalg.norm(zaxis, axis=-1, keepdims=True)\n",
        "    xaxis = np.cross(zaxis, up)\n",
        "    xaxis /= np.linalg.norm(xaxis, axis=-1, keepdims=True)\n",
        "    yaxis = np.cross(zaxis, xaxis)\n",
        "\n",
        "    R = np.stack([xaxis, yaxis, zaxis], axis=-1)\n",
        "\n",
        "    # Transform matrix camera coord to world coord\n",
        "    T_wc = np.array([np.eye(4) for _ in range(cam_pts.shape[0])])\n",
        "    T_wc[..., :3, :3] = R\n",
        "    T_wc[..., :3, 3] = cam_pts\n",
        "    return T_wc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGPEMeo4znFN"
      },
      "source": [
        "# r = np.array()\n",
        "pose_num = 10\n",
        "r = np.full((pose_num), 3.5)\n",
        "theta = np.full((pose_num), np.deg2rad(80))\n",
        "phi = np.linspace(-np.pi, np.pi, pose_num, endpoint=False)\n",
        "cam_pts = spherical_to_xyz(r, theta, phi)\n",
        "\n",
        "cam_poses = get_camera_poses(r, theta, phi)\n",
        "\n",
        "# 3D Plot\n",
        "fig = plt.figure(figsize=(6, 6))\n",
        "ax = Axes3D(fig)\n",
        "ax.set_xlabel(\"X\")\n",
        "ax.set_ylabel(\"Y\")\n",
        "ax.set_zlabel(\"Z\")\n",
        "# ax.axis('off')\n",
        "c = [\"c\", \"y\", \"k\", \"b\"]\n",
        "\n",
        "for i, pose in enumerate(cam_poses):\n",
        "    colors = [\"r\", \"g\", c[i % len(c)]]\n",
        "    drawAxis(pose, 0.6, colors)\n",
        "\n",
        "# Origin\n",
        "drawAxis()\n",
        "\n",
        "# ax.scatter(pts[...,0], pts[...,1], pts[...,2])\n",
        "\n",
        "# adjust scale\n",
        "scale = 7\n",
        "start = np.zeros((3, 3)) - scale / 2\n",
        "end = start + scale * np.eye(3)\n",
        "for s, e in zip(start, end):\n",
        "    ax.plot([s[0], e[0]], [s[1], e[1]], [s[2], e[2]], c=\"none\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrhAWiiOznFO"
      },
      "source": [
        "# Setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9znveK5GznFO"
      },
      "source": [
        "height, width, ch = imgs.shape[1:]\n",
        "cx = width / 2\n",
        "cy = height / 2\n",
        "print(f\"image height:{height}, width:{width}, f:{focal:.2f}, cx:{cx:.2f}, cy:{cy:.2f}\")\n",
        "\n",
        "# ray direction from cam\n",
        "x_grid = np.arange(width) - cx + 0.5\n",
        "y_grid = np.arange(height) - cy + 0.5\n",
        "x_grid, y_grid = np.meshgrid(x_grid, y_grid)\n",
        "ray_cam = np.stack([x_grid, y_grid, np.full_like(x_grid, focal)], axis=-1)\n",
        "\n",
        "# TODO divided by norm or z\n",
        "ray_cam /= np.linalg.norm(ray_cam, axis=-1, keepdims=True)\n",
        "ray_tmp = ray_cam[::10, ::10]  # For debug"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Pg66qsMznFO"
      },
      "source": [
        "# 3D Plot\n",
        "fig = plt.figure(figsize=(6, 6))\n",
        "ax = Axes3D(fig)\n",
        "ax.set_xlabel(\"X\")\n",
        "ax.set_ylabel(\"Y\")\n",
        "ax.set_zlabel(\"Z\")\n",
        "# ax.axis('off')\n",
        "c = [\"c\", \"y\", \"k\", \"b\"]\n",
        "\n",
        "i = 0\n",
        "pose = poses[idx + i]\n",
        "colors = [\"r\", \"g\", c[i]]\n",
        "drawAxis(pose, 0.6, colors)\n",
        "\n",
        "# Camera optical center\n",
        "t = pose[:3, 3]\n",
        "# Cam coord to world coord rotation\n",
        "R = pose[:3, :3]\n",
        "\n",
        "ray_world = ray_tmp.dot(R.T) + t\n",
        "ray_world = ray_world.reshape(-1, 3)\n",
        "ax.scatter(ray_world[:, 0], ray_world[:, 1], ray_world[:, 2])\n",
        "\n",
        "# Origin\n",
        "drawAxis()\n",
        "\n",
        "# adjust scale\n",
        "scale = 7\n",
        "start = np.zeros((3, 3)) - scale / 2\n",
        "end = start + scale * np.eye(3)\n",
        "for s, e in zip(start, end):\n",
        "    ax.plot([s[0], e[0]], [s[1], e[1]], [s[2], e[2]], c=\"none\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kufWZTRyznFO"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBadvqbZznFO"
      },
      "source": [
        "# NeRF Model\n",
        "## Generate model params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9SIwn1rznFP"
      },
      "source": [
        "def encode_variables(x, encode_num):\n",
        "    # No positional encoding\n",
        "    if encode_num == 0:\n",
        "        return x\n",
        "    # Positional encoding\n",
        "    frequency_bands = 2.0 ** jnp.linspace(0.0, encode_num - 1, encode_num)\n",
        "    encoded_grid = []\n",
        "    for freq in frequency_bands:\n",
        "        for func in [jnp.sin, jnp.cos]:\n",
        "            encoded_grid.append(func(jnp.pi * x * freq))\n",
        "    encoded_grid = jnp.concatenate(encoded_grid, axis=-1)\n",
        "    return encoded_grid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ufb427BznFP"
      },
      "source": [
        "from typing import List, Tuple\n",
        "\n",
        "\n",
        "class NeRF(nn.Module):\n",
        "    layer_num: int\n",
        "    hidden_ch: int\n",
        "    encode_num: int\n",
        "    encode_num_view: int\n",
        "    skips: Tuple[int] = (4,)\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, x):\n",
        "        # Encode input\n",
        "        xyz = x[:3]\n",
        "        view = x[3:]\n",
        "        xyz = encode_variables(xyz, self.encode_num)\n",
        "        view = encode_variables(view, self.encode_num_view)\n",
        "\n",
        "        # fc\n",
        "        x = xyz\n",
        "        for i in range(self.layer_num):\n",
        "            if i in self.skips:\n",
        "                x = jnp.concatenate([xyz, x])\n",
        "            x = nn.Dense(self.hidden_ch, name=f\"fc{i}\")(x)\n",
        "            x = jax.nn.relu(x)\n",
        "\n",
        "        # sigma\n",
        "        sigma_out = nn.Dense(1, name=f\"sigma_fc\")(x)\n",
        "        sigma = jax.nn.relu(sigma_out)\n",
        "\n",
        "        # rgb\n",
        "        bottleneck = nn.Dense(self.hidden_ch, name=\"rgb_fc0\")(x)\n",
        "        x = jnp.concatenate([view, bottleneck])\n",
        "        x = nn.Dense(self.hidden_ch // 2, name=f\"rgb_fc1\")(x)\n",
        "        x = jax.nn.relu(x)\n",
        "        x = nn.Dense(3, name=f\"rgb_fc2\")(x)\n",
        "        rgb = jax.nn.sigmoid(x)\n",
        "\n",
        "        return sigma, rgb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JihcjefznFP"
      },
      "source": [
        "def model():\n",
        "    global cfg\n",
        "    return NeRF(\n",
        "        layer_num=cfg.layer_num,\n",
        "        hidden_ch=cfg.hidden_ch,\n",
        "        encode_num=cfg.encode_num,\n",
        "        encode_num_view=cfg.encode_num_view,\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIGqQSzIznFP"
      },
      "source": [
        "x = random.normal(rng, (ch_dim + view_dim,))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDSmDY4YznFP"
      },
      "source": [
        "rng, k1, k2 = random.split(rng, num=3)\n",
        "params = {}\n",
        "params['coarse'] = model().init(k1, x)\n",
        "params['fine'] = model().init(k2, x)\n",
        "# out = model().apply(params, x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Wz_xAW3YznFP"
      },
      "source": [
        "# jax.tree_map(lambda x: x.shape, params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHipqoOzznFP"
      },
      "source": [
        "test_sample = testset[0]\n",
        "test_img = test_sample['img']\n",
        "test_pose = test_sample['pose']\n",
        "plt.imshow(test_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0TVSFRSznFQ"
      },
      "source": [
        "print(\"train images number:\", len(trainset))\n",
        "print(\"test images number:\", len(testset))\n",
        "trainloader = DataLoader(\n",
        "    trainset, batch_size=1, shuffle=True, collate_fn=collate_fn, num_workers=cfg.workers\n",
        ")\n",
        "testloader = DataLoader(\n",
        "    testset, batch_size=1, shuffle=False, collate_fn=collate_fn, num_workers=cfg.workers\n",
        ")\n",
        "\n",
        "# pixel ray direction in cam coord\n",
        "ray_dir_cam = jnp.asarray(ray_cam)\n",
        "ray_dist = jnp.linspace(cfg.near_clip, cfg.far_clip, cfg.ray_sample)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6kPf2g1znFQ"
      },
      "source": [
        "def prediction(params, x):\n",
        "    sigma, rgb = model().apply(params, x)\n",
        "    return sigma, rgb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1exdxjkznFQ"
      },
      "source": [
        "x = jnp.ones((ch_dim + view_dim, ))\n",
        "sigma, rgb = prediction(params[\"coarse\"], x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZJSfhX2znFQ"
      },
      "source": [
        "# Sample points along one ray\n",
        "def _sample_points(ray_dir, t, ray_dist, camera_bnd=6.0):\n",
        "    # Sample points\n",
        "    pts = ray_dist[..., None] * ray_dir + t\n",
        "\n",
        "    # Normalize for positional encoder\n",
        "    pts = pts/camera_bnd\n",
        "\n",
        "    # With direction\n",
        "    use_theta_phi = False\n",
        "    if(use_theta_phi):\n",
        "        # With direction\n",
        "        r, theta, phi = xyz_to_spherical(ray_dir)\n",
        "\n",
        "        theta = theta/jnp.pi*2\n",
        "        phi = phi/jnp.pi\n",
        "\n",
        "        pts = jnp.concatenate(\n",
        "            [pts, jnp.full_like(pts[:, :1], theta), jnp.full_like(pts[:, :1], phi)], axis=-1\n",
        "        )\n",
        "    else:\n",
        "        pts = jnp.concatenate([pts, ray_dir[None].repeat(pts.shape[0], 0)], axis=-1)\n",
        "\n",
        "    # Distance\n",
        "    dists = ray_dist[1:] - ray_dist[:-1]\n",
        "    dists = jnp.pad(dists, (0, 1), 'constant', constant_values=(1e10))\n",
        "\n",
        "    return pts, dists\n",
        "\n",
        "sample_points = partial(_sample_points, camera_bnd=camera_bnd_max)\n",
        "\n",
        "def integrate_color(sigma, rgb, dists, bkg = jnp.array([1.0, 1.0, 1.0])):\n",
        "    transparency = jnp.exp(-sigma.squeeze() * dists)\n",
        "    alpha = 1 - transparency\n",
        "    # cumprod_exclusive\n",
        "    T = jnp.cumprod(transparency)[:-1]\n",
        "    T = jnp.pad(T, (1, 0), 'constant', constant_values=1)\n",
        "\n",
        "    # accumulate\n",
        "    weights = alpha[..., None]*T[..., None]\n",
        "    colors = rgb*weights\n",
        "    # Add background color\n",
        "    colors = colors.sum(axis=0) + bkg * (1.0 - weights.sum())\n",
        "\n",
        "    return colors, weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5SV_ghdznFQ"
      },
      "source": [
        "# prediction along a ray\n",
        "ray_prediction = vmap(prediction, in_axes=(None, 0))\n",
        "\n",
        "def render_ray(params, ray_dir, t, ray_dist):\n",
        "    pts, dists = sample_points(ray_dir, t, ray_dist)\n",
        "    sigma, rgb = ray_prediction(params, pts)\n",
        "    colors, weights = integrate_color(sigma, rgb, dists)\n",
        "    return colors, weights\n",
        "\n",
        "# Render multiple rays\n",
        "render_pixels = vmap(render_ray, in_axes=(None, 0, None, None))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E14JDKlgznFQ"
      },
      "source": [
        "def sample_pdf(weights, sample_num):\n",
        "    # Calculate pdf and cdf\n",
        "    weights = weights + 1e-5\n",
        "    pdf = weights/weights.sum()\n",
        "    cdf = jnp.cumsum(pdf)\n",
        "\n",
        "    # linspace(0, 1) without start or end points\n",
        "    start = 1/(sample_num+1)\n",
        "    end = 1 - start\n",
        "    uniform_prob = jnp.linspace(start, end, sample_num)\n",
        "\n",
        "    # TODO check out of range?\n",
        "    right_idx = jnp.searchsorted(cdf, uniform_prob, side='right')\n",
        "    left_idx = right_idx - 1\n",
        "\n",
        "    # Linear interpolation\n",
        "    right_factor = (uniform_prob - cdf[left_idx]) / (cdf[right_idx] - cdf[left_idx])\n",
        "    left_factor = 1.0 - right_factor\n",
        "\n",
        "    return left_idx, left_factor\n",
        "\n",
        "\n",
        "def render_ray_fine(params, weights, ray_dir, fine_ray_sample, t, ray_dist):\n",
        "    # Importance sampling\n",
        "    l_idx, l_factor = sample_pdf(weights, fine_ray_sample)\n",
        "    fine_ray_dist = l_factor * ray_dist[l_idx] + (1 - l_factor) * ray_dist[l_idx + 1]\n",
        "    fine_ray_dist = jax.lax.stop_gradient(fine_ray_dist)\n",
        "    pts, dists = sample_points(ray_dir, t, fine_ray_dist)\n",
        "\n",
        "    # Color\n",
        "    sigma, rgb = ray_prediction(params, pts)\n",
        "    colors, weights = integrate_color(sigma, rgb, dists)\n",
        "    return colors, weights\n",
        "\n",
        "render_pixels_fine = vmap(render_ray_fine, in_axes=(None, 0, 0, None, None, None))\n",
        "\n",
        "# fine_colors, _ = render_pixels_fine(params, weights, batch_dirs, fine_ray_sample, t, ray_dist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5FYC82FznFQ"
      },
      "source": [
        "@partial(jit, static_argnums=2)\n",
        "def render_pixels_coarse_fine(params, batch_dirs, fine_ray_sample, t, ray_dist):\n",
        "    # Coarse sampling\n",
        "    coarse_colors, weights = render_pixels(params['coarse'], batch_dirs, t, ray_dist)\n",
        "    # Fine sampling\n",
        "    fine_colors, _ = render_pixels_fine(\n",
        "        params['fine'], weights, batch_dirs, fine_ray_sample, t, ray_dist\n",
        "    )\n",
        "    return fine_colors, coarse_colors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGjlxyZ0znFQ"
      },
      "source": [
        "def loss_fn(params, batch_dirs, batch_pixels, t, ray_dist, fine_ray_sample):\n",
        "    # Coarse and fine sampling\n",
        "    fine_colors, coarse_colors = render_pixels_coarse_fine(\n",
        "        params, batch_dirs, fine_ray_sample, t, ray_dist\n",
        "    )\n",
        "\n",
        "    # Calculate loss\n",
        "    coarse_loss = jnp.mean((batch_pixels - coarse_colors) ** 2)\n",
        "    fine_loss = jnp.mean((batch_pixels - fine_colors) ** 2)\n",
        "    total_loss = coarse_loss + fine_loss\n",
        "\n",
        "    return total_loss\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKqbZ7ssznFQ"
      },
      "source": [
        "# when you use @jit here, it causes out of gpu memory\n",
        "# I guess it's because @jit unroll for loop and try to execute once.\n",
        "# Just use @jit for core function, e.g., render_pixels_coarse_fine\n",
        "def render_image(params, pose, ray_dir_cam, fine_ray_sample):\n",
        "    # Camera optical center\n",
        "    t = pose[:3, 3]\n",
        "    # Cam coord to world coord rotation\n",
        "    R = pose[:3, :3]\n",
        "    # ray direction in world coord\n",
        "    ray_dir_world = ray_dir_cam.dot(R.T)\n",
        "    flatten_ray_dir_world = ray_dir_world.reshape(-1, 3)\n",
        "\n",
        "    coarse_colors = []\n",
        "    fine_colors = []\n",
        "    batch_ray_num = 4096\n",
        "    for pix_idx in range(0, len(flatten_ray_dir_world), batch_ray_num):\n",
        "        batch_dirs = flatten_ray_dir_world[pix_idx : pix_idx + batch_ray_num]\n",
        "        # Coarse and fine sampling\n",
        "        fine, coarse = render_pixels_coarse_fine(\n",
        "            params, batch_dirs, fine_ray_sample, t, ray_dist\n",
        "        )\n",
        "        coarse_colors.append(coarse)\n",
        "        fine_colors.append(fine)\n",
        "\n",
        "    # Convert colors into 2d image\n",
        "    coarse_img = jnp.concatenate(coarse_colors).reshape(ray_dir_cam.shape)\n",
        "    coarse_img = jnp.clip(coarse_img, a_min=0.0, a_max=1.0)\n",
        "    fine_img = jnp.concatenate(fine_colors).reshape(ray_dir_cam.shape)\n",
        "    fine_img = jnp.clip(fine_img, a_min=0.0, a_max=1.0)\n",
        "    return fine_img, coarse_img\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6N9V7Ee9b9Iy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUgE6iYgznFR"
      },
      "source": [
        "# Optimizer\n",
        "optimizer_def = fx.optim.Adam(learning_rate=cfg.lr)\n",
        "optimizer = optimizer_def.create(params)\n",
        "\n",
        "# LR scheduler\n",
        "def create_exponential_lr(initial_lr, decay_steps, decay_rate):\n",
        "    def learning_rate_fn(step):\n",
        "        lr = initial_lr*decay_rate**(step/decay_steps)\n",
        "        return lr\n",
        "    return learning_rate_fn\n",
        "\n",
        "# Final learning rate is cfg.lr*0.01\n",
        "learning_rate_fn = create_exponential_lr(cfg.lr, len(trainloader) * cfg.num_epochs / 2, 0.1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import optax\n",
        "\n",
        "# # Create an Adam optimizer\n",
        "# optimizer_def = optax.adam(learning_rate=cfg.lr)\n",
        "# optimizer = optimizer_def.init(params)\n",
        "\n",
        "# # LR scheduler\n",
        "# def create_exponential_lr(initial_lr, decay_steps, decay_rate):\n",
        "#     def learning_rate_fn(step):\n",
        "#         lr = initial_lr * decay_rate ** (step / decay_steps)\n",
        "#         return lr\n",
        "#     return learning_rate_fn\n",
        "\n",
        "# # Final learning rate is cfg.lr * 0.01\n",
        "# learning_rate_fn = create_exponential_lr(cfg.lr, len(trainloader) * cfg.num_epochs / 2, 0.1)\n"
      ],
      "metadata": {
        "id": "1x2sqkSmb9ii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TASVkRYhznFR"
      },
      "source": [
        "from functools import partial\n",
        "\n",
        "\n",
        "# def _optim_step(\n",
        "#     optimizer, batch_dirs, batch_pixels, t, ray_dist, fine_ray_sample, learning_rate_fn\n",
        "# ):\n",
        "#     loss_values, grads = value_and_grad(loss_fn)(\n",
        "#         optimizer.target, batch_dirs, batch_pixels, t, ray_dist, fine_ray_sample\n",
        "#     )\n",
        "#     lr = learning_rate_fn(optimizer.state.step)\n",
        "#     optimizer = optimizer.apply_gradient(grads, learning_rate=lr)\n",
        "#     return loss_values, optimizer\n",
        "\n",
        "def _optim_step(\n",
        "    optimizer, batch_dirs, batch_pixels, t, ray_dist, fine_ray_sample, learning_rate_fn\n",
        "):\n",
        "    loss_values, grads = value_and_grad(loss_fn)(\n",
        "        optimizer.target, batch_dirs, batch_pixels, t, ray_dist, fine_ray_sample\n",
        "    )\n",
        "    lr = learning_rate_fn(optimizer.state.step)\n",
        "    optimizer = optimizer.apply_gradient(grads, learning_rate=lr)\n",
        "    return loss_values, optimizer  # Remove the tuple wrapper\n",
        "\n",
        "\n",
        "# Make fine_ray_sample and learning_rate_fun static args\n",
        "optim_step = jit(\n",
        "    partial(\n",
        "        _optim_step,\n",
        "        fine_ray_sample=cfg.fine_ray_sample,\n",
        "        learning_rate_fn=learning_rate_fn,\n",
        "    )\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ov9qhmlmeVWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTJcZCuJznFR"
      },
      "source": [
        "from skimage.metrics import structural_similarity\n",
        "\n",
        "\n",
        "def calculate_error_metrics(gt, pred):\n",
        "    gt = np.array(gt)\n",
        "    pred = np.array(pred)\n",
        "    mse = np.mean((gt - pred) ** 2)\n",
        "    psnr = -10 * np.log(mse) / np.log(10)\n",
        "    # compatible with tf.image.ssim\n",
        "    ssim = structural_similarity(\n",
        "        gt,\n",
        "        pred,\n",
        "        multichannel=True,\n",
        "        data_range=1.0,\n",
        "        win_size=11,\n",
        "        K1=0.01,\n",
        "        K2=0.03,\n",
        "        sigma=1.5,\n",
        "    )\n",
        "    return {\"psnr\": psnr, \"ssim\": ssim}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "9R5xlNFuznFR"
      },
      "source": [
        "batch_ray_num = 4096\n",
        "interval_test_metrics = 100\n",
        "interval_save_model = 100\n",
        "interval_visualize_image = 10\n",
        "until_visualize_image = 5\n",
        "\n",
        "for epoch in range(cfg.num_epochs):\n",
        "    total_loss = 0\n",
        "    cnt = 0\n",
        "    pbar = tqdm(trainloader, total=len(trainloader), desc=f\"[Train] Epoch:{epoch}\")\n",
        "    for batch in pbar:\n",
        "        img = batch[\"img\"][0]\n",
        "        pose = batch[\"pose\"][0]\n",
        "\n",
        "        # Camera optical center\n",
        "        t = pose[:3, 3]\n",
        "        # Cam coord to world coord rotation\n",
        "        R = pose[:3, :3]\n",
        "\n",
        "        # ray direction in world coord\n",
        "        ray_dir_world = ray_dir_cam.dot(R.T)\n",
        "        flatten_ray_dir_world = ray_dir_world.reshape(-1, 3)\n",
        "        flatten_image = img.reshape(-1, 3)\n",
        "\n",
        "        # Batch ray select index\n",
        "        HxW = flatten_ray_dir_world.shape[0]\n",
        "        batch_idx = np.array(sample_no_duplicates(range(HxW), batch_ray_num))\n",
        "\n",
        "        # Forward\n",
        "        batch_dirs = flatten_ray_dir_world[batch_idx]\n",
        "        batch_pixels = flatten_image[batch_idx]\n",
        "        loss_vals, optimizer = optim_step(\n",
        "            optimizer, batch_dirs, batch_pixels, t, ray_dist\n",
        "        )\n",
        "        loss_vals = float(loss_vals)  # jax array to float\n",
        "        total_loss += loss_vals\n",
        "        log_data = {\"loss\": loss_vals}\n",
        "\n",
        "        # Loss plot\n",
        "        pbar.set_postfix(log_data)\n",
        "#         wandb.log(log_data, commit=False)\n",
        "    print(f\"Epoch:{epoch}, total_loss:{total_loss}\")\n",
        "    # Plot lr for debug\n",
        "#     wandb.log({'lr':float(learning_rate_fn(optimizer.state.step))}, commit=False)\n",
        "\n",
        "    # Calculate test metrics\n",
        "    if epoch !=0 and (not epoch % interval_test_metrics or epoch == (cfg.num_epochs - 1)):\n",
        "        total_test_metrics = defaultdict(list)\n",
        "        pbar = tqdm(testloader, total=len(testloader), desc=f\"[Test] Epoch:{epoch}\")\n",
        "        for batch in pbar:\n",
        "            img = batch[\"img\"][0]\n",
        "            pose = batch[\"pose\"][0]\n",
        "            viz_img, _ = render_image(\n",
        "                optimizer.target, pose, ray_dir_cam, cfg.fine_ray_sample\n",
        "            )\n",
        "            test_metrics = calculate_error_metrics(img, viz_img)\n",
        "            for key, val in test_metrics.items():\n",
        "                total_test_metrics[key].append(val)\n",
        "\n",
        "        log_data = {}\n",
        "        for key, val in total_test_metrics.items():\n",
        "            log_data[\"test_ave_\" + key] = np.array(val).mean()\n",
        "        print(json.dumps(log_data, indent=1))\n",
        "#         wandb.log(log_data, commit=False)\n",
        "\n",
        "    # Visualize one test images\n",
        "    if not epoch % interval_visualize_image or epoch < until_visualize_image:\n",
        "        viz_img, coarse_img = render_image(\n",
        "            optimizer.target, testset[0][\"pose\"], ray_dir_cam, cfg.fine_ray_sample\n",
        "        )\n",
        "        fig, ax = plt.subplots(1, 1)\n",
        "        ax.set_title(f\"Epoch:{epoch}\")\n",
        "        ax.imshow(viz_img)\n",
        "        fig.tight_layout()\n",
        "#         wandb.log({\"result_imgs\": wandb.Image(fig)}, commit=False)\n",
        "        fig, ax = plt.subplots(1, 1)\n",
        "        ax.set_title(f\"coarse Epoch:{epoch}\")\n",
        "        ax.imshow(coarse_img)\n",
        "        fig.tight_layout()\n",
        "#         wandb.log({\"coarse_imgs(debug)\": wandb.Image(fig)}, commit=False)\n",
        "        plt.show()\n",
        "\n",
        "    # Commit log\n",
        "#     wandb.log({}, commit=True)\n",
        "\n",
        "    # Save model\n",
        "    if not epoch % interval_save_model or epoch == (cfg.num_epochs - 1):\n",
        "        fname = f\"checkpoints/nerf_jax_{epoch}.pkl\"\n",
        "        print(\"save model:\", fname)\n",
        "        with open(fname, mode=\"wb\") as f:\n",
        "            f.write(serialization.to_bytes(optimizer))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sq03RZDJznFR"
      },
      "source": [
        "# Calculate metrics using all testset\n",
        "total_test_metrics = defaultdict(list)\n",
        "alltestloader = DataLoader(all_testset, batch_size=1, shuffle=False, collate_fn=collate_fn, num_workers=cfg.workers)\n",
        "pbar = tqdm(alltestloader, total=len(alltestloader),desc=f\"[Final Test]\")\n",
        "for batch in pbar:\n",
        "    img = batch[\"img\"][0]\n",
        "    pose = batch[\"pose\"][0]\n",
        "    viz_img, _ = render_image(optimizer.target, pose, ray_dir_cam, cfg.fine_ray_sample)\n",
        "    test_metrics = calculate_error_metrics(img, viz_img)\n",
        "    pbar.set_postfix(test_metrics)\n",
        "    for key, val in test_metrics.items():\n",
        "        total_test_metrics[key].append(val)\n",
        "\n",
        "log_data = {}\n",
        "for k, v in total_test_metrics.items():\n",
        "    key = 'final_ave_'+k\n",
        "    mean_val = np.array(v).mean()\n",
        "    log_data[key] = mean_val\n",
        "#     wandb.run.summary[key] = mean_val\n",
        "print(json.dumps(log_data, indent=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhCkdJsAznFR"
      },
      "source": [
        "# Inference\n",
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgUtwXxuznFR"
      },
      "source": [
        "fname"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29fFbPucznFR"
      },
      "source": [
        "load_params = optimizer.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxfzqRTGznFR"
      },
      "source": [
        "# # Load test\n",
        "# with open(fname, 'rb') as f:\n",
        "#     data = f.read()\n",
        "#     loaded_optimizer = serialization.from_bytes(optimizer, data)\n",
        "# load_params = loaded_optimizer.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQnc7QIwznFR"
      },
      "source": [
        "# Visualize test images\n",
        "img = test_img\n",
        "pose = test_pose\n",
        "viz_img, _ = render_image(load_params, pose, ray_dir_cam, cfg.fine_ray_sample)\n",
        "fig, ax = plt.subplots(1, 1)\n",
        "ax.set_title(f\"Test visualization\")\n",
        "ax.imshow(viz_img)\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxbBgpm8znFS"
      },
      "source": [
        "pose_num = 100\n",
        "r = np.full((pose_num), 3.5)\n",
        "theta = np.full((pose_num), np.deg2rad(80))\n",
        "phi = np.linspace(-np.pi, np.pi, pose_num, endpoint=False)\n",
        "cam_poses = get_camera_poses(r, theta, phi).astype(np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XnI7t_TznFS"
      },
      "source": [
        "viz_imgs = []\n",
        "for pose in tqdm(cam_poses):\n",
        "    viz_img, _ = render_image(load_params, pose, ray_dir_cam, cfg.fine_ray_sample)\n",
        "    viz_imgs.append(np.array(viz_img))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "6_CkdXC4znFS"
      },
      "source": [
        "from PIL import Image\n",
        "import IPython\n",
        "output_gifname = f\"results/nerf_jax_final_{epoch}.gif\"\n",
        "gif_imgs = [Image.fromarray((255*it).astype(np.uint8)) for it in viz_imgs]\n",
        "gif_imgs[0].save(\n",
        "    output_gifname,\n",
        "    save_all=True,\n",
        "    append_images=gif_imgs[1:],\n",
        "    optimize=False,\n",
        "    duration=50,\n",
        "    loop=0,\n",
        ")\n",
        "caption = f\"Final fine animation ({epoch})\"\n",
        "print(caption)\n",
        "IPython.display.Image(output_gifname, format=\"png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNBNVWAaznFS"
      },
      "source": [
        "# wandb.finish()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8xgqiTeznFS"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lq4UpyEFznFS"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}