{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3TTHYn9-Ypc"
      },
      "outputs": [],
      "source": [
        "#! pip3 install -U jax[tpu] -f https://storage.googleapis.com/jax-releases/libtpu_releases.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KY6c5OvE_Fsh",
        "outputId": "01631d92-8cf3-4176-8b70-8d9038db0651"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VP7A7GqV_TNK",
        "outputId": "33985cee-36e9-4b5d-80a4-754f783e6a9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flax>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/datasets/requirements2.txt (line 1)) (0.7.5)\n",
            "Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/datasets/requirements2.txt (line 2)) (1.23.5)\n",
            "Requirement already satisfied: opencv-python>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/datasets/requirements2.txt (line 3)) (4.8.0.76)\n",
            "Requirement already satisfied: Pillow>=7.2.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/datasets/requirements2.txt (line 4)) (9.4.0)\n",
            "Requirement already satisfied: matplotlib>=3.3.4 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/datasets/requirements2.txt (line 5)) (3.7.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/datasets/requirements2.txt (line 6)) (4.66.1)\n",
            "Collecting gpustat (from -r /content/drive/MyDrive/datasets/requirements2.txt (line 7))\n",
            "  Downloading gpustat-1.1.1.tar.gz (98 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/98.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.1/98.1 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jax>=0.4.19 in /usr/local/lib/python3.10/dist-packages (from flax>=0.3.0->-r /content/drive/MyDrive/datasets/requirements2.txt (line 1)) (0.4.20)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from flax>=0.3.0->-r /content/drive/MyDrive/datasets/requirements2.txt (line 1)) (1.0.7)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.10/dist-packages (from flax>=0.3.0->-r /content/drive/MyDrive/datasets/requirements2.txt (line 1)) (0.1.7)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.10/dist-packages (from flax>=0.3.0->-r /content/drive/MyDrive/datasets/requirements2.txt (line 1)) (0.4.3)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.10/dist-packages (from flax>=0.3.0->-r /content/drive/MyDrive/datasets/requirements2.txt (line 1)) (0.1.45)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.10/dist-packages (from flax>=0.3.0->-r /content/drive/MyDrive/datasets/requirements2.txt (line 1)) (13.7.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.10/dist-packages (from flax>=0.3.0->-r /content/drive/MyDrive/datasets/requirements2.txt (line 1)) (4.5.0)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from flax>=0.3.0->-r /content/drive/MyDrive/datasets/requirements2.txt (line 1)) (6.0.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->-r /content/drive/MyDrive/datasets/requirements2.txt (line 5)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->-r /content/drive/MyDrive/datasets/requirements2.txt (line 5)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->-r /content/drive/MyDrive/datasets/requirements2.txt (line 5)) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->-r /content/drive/MyDrive/datasets/requirements2.txt (line 5)) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->-r /content/drive/MyDrive/datasets/requirements2.txt (line 5)) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->-r /content/drive/MyDrive/datasets/requirements2.txt (line 5)) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->-r /content/drive/MyDrive/datasets/requirements2.txt (line 5)) (2.8.2)\n",
            "Collecting nvidia-ml-py>=11.450.129 (from gpustat->-r /content/drive/MyDrive/datasets/requirements2.txt (line 7))\n",
            "  Downloading nvidia_ml_py-12.535.133-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: psutil>=5.6.0 in /usr/local/lib/python3.10/dist-packages (from gpustat->-r /content/drive/MyDrive/datasets/requirements2.txt (line 7)) (5.9.5)\n",
            "Collecting blessed>=1.17.1 (from gpustat->-r /content/drive/MyDrive/datasets/requirements2.txt (line 7))\n",
            "  Downloading blessed-1.20.0-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from blessed>=1.17.1->gpustat->-r /content/drive/MyDrive/datasets/requirements2.txt (line 7)) (0.2.12)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from blessed>=1.17.1->gpustat->-r /content/drive/MyDrive/datasets/requirements2.txt (line 7)) (1.16.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.19->flax>=0.3.0->-r /content/drive/MyDrive/datasets/requirements2.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.19->flax>=0.3.0->-r /content/drive/MyDrive/datasets/requirements2.txt (line 1)) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.19->flax>=0.3.0->-r /content/drive/MyDrive/datasets/requirements2.txt (line 1)) (1.11.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax>=0.3.0->-r /content/drive/MyDrive/datasets/requirements2.txt (line 1)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax>=0.3.0->-r /content/drive/MyDrive/datasets/requirements2.txt (line 1)) (2.16.1)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from optax->flax>=0.3.0->-r /content/drive/MyDrive/datasets/requirements2.txt (line 1)) (1.4.0)\n",
            "Requirement already satisfied: chex>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from optax->flax>=0.3.0->-r /content/drive/MyDrive/datasets/requirements2.txt (line 1)) (0.1.7)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.10/dist-packages (from optax->flax>=0.3.0->-r /content/drive/MyDrive/datasets/requirements2.txt (line 1)) (0.4.20+cuda11.cudnn86)\n",
            "Requirement already satisfied: etils[epath,epy] in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax>=0.3.0->-r /content/drive/MyDrive/datasets/requirements2.txt (line 1)) (1.5.2)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax>=0.3.0->-r /content/drive/MyDrive/datasets/requirements2.txt (line 1)) (1.5.8)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax>=0.3.0->-r /content/drive/MyDrive/datasets/requirements2.txt (line 1)) (3.20.3)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.5->optax->flax>=0.3.0->-r /content/drive/MyDrive/datasets/requirements2.txt (line 1)) (0.1.8)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.5->optax->flax>=0.3.0->-r /content/drive/MyDrive/datasets/requirements2.txt (line 1)) (0.12.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax>=0.3.0->-r /content/drive/MyDrive/datasets/requirements2.txt (line 1)) (0.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax>=0.3.0->-r /content/drive/MyDrive/datasets/requirements2.txt (line 1)) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax>=0.3.0->-r /content/drive/MyDrive/datasets/requirements2.txt (line 1)) (6.1.1)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax>=0.3.0->-r /content/drive/MyDrive/datasets/requirements2.txt (line 1)) (3.17.0)\n",
            "Building wheels for collected packages: gpustat\n",
            "  Building wheel for gpustat (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpustat: filename=gpustat-1.1.1-py3-none-any.whl size=26535 sha256=2472dd9dd3b6cb9ca99b6bb00b31504b04c1e7c4acb71f31f1bb747f2bfb83de\n",
            "  Stored in directory: /root/.cache/pip/wheels/ec/d7/80/a71ba3540900e1f276bcae685efd8e590c810d2108b95f1e47\n",
            "Successfully built gpustat\n",
            "Installing collected packages: nvidia-ml-py, blessed, gpustat\n",
            "Successfully installed blessed-1.20.0 gpustat-1.1.1 nvidia-ml-py-12.535.133\n"
          ]
        }
      ],
      "source": [
        "! pip3 install -r \"/content/drive/MyDrive/datasets/requirements2.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IB6o-W75BWj-"
      },
      "outputs": [],
      "source": [
        "#import jax.tools.colab_tpu\n",
        "#jax.tools.colab_tpu.setup_tpu()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T13kMZLI-Vr3"
      },
      "source": [
        "# MobileNeRF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_qfsxLT-Vr6",
        "outputId": "9e588b89-10e7-402c-dc81-5668024bda5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[cuda(id=0)]\n",
            "ERROR: need 8 v100 GPUs\n"
          ]
        }
      ],
      "source": [
        "#Copyright 2023 The jax3d Authors.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\n",
        "scene_type = \"synthetic\"\n",
        "object_name = \"chair\"\n",
        "scene_dir = \"/content/drive/MyDrive/datasets/\"+object_name\n",
        "\n",
        "# synthetic\n",
        "# chair drums ficus hotdog lego materials mic ship\n",
        "\n",
        "# forwardfacing\n",
        "# fern flower fortress horns leaves orchids room trex\n",
        "\n",
        "# real360\n",
        "# bicycle flowerbed gardenvase stump treehill\n",
        "# fulllivingroom kitchencounter kitchenlego officebonsai\n",
        "\n",
        "#%% --------------------------------------------------------------------------------\n",
        "# ## General imports\n",
        "#%%\n",
        "import copy\n",
        "import gc\n",
        "import json\n",
        "import os\n",
        "import numpy\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "import jax\n",
        "import jax.numpy as np\n",
        "from jax import random\n",
        "import flax\n",
        "import flax.linen as nn\n",
        "import functools\n",
        "import math\n",
        "from typing import Sequence, Callable\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from multiprocessing.pool import ThreadPool\n",
        "\n",
        "print(jax.local_devices())\n",
        "if len(jax.local_devices())!=8:\n",
        "  print(\"ERROR: need 8 v100 GPUs\")\n",
        "  #1/0\n",
        "weights_dir = \"/content/drive/MyDrive/datasets/weights_100000\"\n",
        "samples_dir = \"/content/drive/MyDrive/datasets/samples_100000\"\n",
        "if not os.path.exists(weights_dir):\n",
        "  os.makedirs(weights_dir)\n",
        "if not os.path.exists(samples_dir):\n",
        "  os.makedirs(samples_dir)\n",
        "def write_floatpoint_image(name,img):\n",
        "  img = numpy.clip(numpy.array(img)*255,0,255).astype(numpy.uint8)\n",
        "  cv2.imwrite(name,img[:,:,::-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqdOgtGq-Vr8"
      },
      "source": [
        "## Load Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "H4mNiNs0-Vr8",
        "outputId": "ca54d8f3-e455-4943-af8d-6ca6ed5fc1f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train\n",
            "  images: (100, 800, 800, 3)\n",
            "  c2w: (100, 4, 4)\n",
            "  hwf: (3,)\n",
            "test\n",
            "  images: (200, 800, 800, 3)\n",
            "  c2w: (200, 4, 4)\n",
            "  hwf: (3,)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA02klEQVR4nO3df3RU9Z3/8dckCwlQMgICiRIU0NbGSBEU5MdasFCxlqrb1VO/uhXWw25ZtCr9dgFXD19Oq5Gvflt3xUWlXeQcpLRbqxS30qqo1C4INaY1RVAilhQIYtAZjGWgmfn+kb2RJDOZOzP3x+feeT7OyTlNuJn7mWl77jvvz/v9/kRSqVRKAAAAPinxewEAAKC4EYwAAABfEYwAAABfEYwAAABfEYwAAABfEYwAAABfEYwAAABfEYwAAABf/ZXfC+hNMpnUwYMHNXDgQEUiEb+XAwAAbEilUjp27JjOOOMMlZRkz3sYHYwcPHhQ1dXVfi8DAADkobm5WSNGjMh6ndHByMCBAyV1vJmKigqfVwMAAOyIx+Oqrq7ufI5nY3QwYm3NVFRUEIwAABAwdkssKGAFAAC+IhgBAAC+IhgBAAC+IhgBAAC+8iwYue+++xSJRHT77bd7dUsAABAAngQjO3fu1KOPPqqxY8d6cTsAABAgrgcjH330kW644QatXr1agwYNcvt2AAAgYFwPRhYuXKgrr7xSM2fOzHptIpFQPB7v8gUAAMLN1aFnGzZsUH19vXbu3Gnr+rq6Oi1fvtzNJQGB055Mace+o3rv2HENG1iuiaMGq7SEs5oAhIdrwUhzc7Nuu+02PffccyovL7f1O0uXLtWiRYs6v7fGyQLFanPjIS3ftEuHYsc7f1YVLdeyOTWaXVvl48oAwDmRVCqVcuOFn376aV1zzTUqLS3t/Fl7e7sikYhKSkqUSCS6/Fs68Xhc0WhUsViMcfAoOpsbD2nBunp1/z+olRNZdeN4AhIARsr1+e1aZuQLX/iC3njjjS4/mzdvns477zwtXrw4ayACFLP2ZErLN+3qEYhIUkodAcnyTbs0q6aSLRsAgedaMDJw4EDV1tZ2+dmAAQM0ZMiQHj8H0NWOfUe7bM10l5J0KHZcO/Yd1eQxQ7xbGAC4wOhTe4GgKrTo9L1jmQORfK4DAJN5Goy89NJLXt4O8IUTRafDBtor+rZ7HQCYjLNpAAdZRafdt1haYse1YF29NjcesvU6E0cNVlW0XJlyKRF1BDgTRw0ubMEAYACCEcAh2YpOpY6i0/Zk9ga20pKIls2pkaQeAYn1/bI5NRSvAggFghHAIbkUndoxu7ZKq24cr8po162Yymg5bb0AQoUCVsAhbhSdzq6t0qyaSiawAgg1ghHAIW4VnZaWRGjfBRBqbNMADqHoFADyQzACOMSUotP2ZErbmlq1seGAtjW12iqYBQA/sU0DOMgqOu0+Z6TSo8PtOFgPQBC5dlCeEzgoD0FV6ATWfHCwHgBTGHNQHlDMvC465WA9AEFGzQgQAk7POAEALxGMACHAwXoAgoxgBAgBDtYDEGQEI0AIMOMEQJARjAAu8HrWhykzTgAgH3TTAA7za9aH3zNOACBfzBkBHGTCrI98Z5z4MRsFQDgxZwTwiSmzPvKZccLkVgB+omYEcEhQZ31Y2Zzua2+JHdeCdfXa3HjIp5UBKBYEI4BDgjjrI1s2R+rI5nDYHgA3EYwADgnirI+gZnMAhAvBCOCQIM76CGI2B0D4EIwADgnirI8gZnMAhA/BCOAga9ZHZbTrw7syWu5JW286vQ1gC2I2B0D40NoLOGx2bZVm1VQaMbMjW8uulc1ZsK5eEalLIaup2RwA4cPQMyCkchnAxpwRAE5i6BmAnAewmZTNAVB8CEaAEMqlZdea1prP5FYAcAIFrEAI0bILIEgIRoAQomUXQJAQjAAhRMsugCAhGAFCyLQBbL3NOgEAV4ORVatWaezYsaqoqFBFRYUmT56sZ5991s1bAvgfpgxg29x4SNNWbNH1q7frtg0Nun71dk1bsYXTgAF0cnXOyKZNm1RaWqpzzz1XqVRKa9eu1f3336/XX39d559/ftbfZ84IULj2ZMq3lt1cZp0ACI9cn9+eDz0bPHiw7r//ft18881ZryUYAYKrPZnStBVbMrYYR9SRpXll8WXMMwFCxtihZ+3t7frP//xPtbW1afLkyWmvSSQSSiQSnd/H43GvlgfAYfnMOgFQnFwvYH3jjTf0qU99SmVlZfrGN76hp556SjU1NWmvraurUzQa7fyqrq52e3kAXMKsEwB2uR6MfOYzn1FDQ4NeffVVLViwQDfddJN27dqV9tqlS5cqFot1fjU3N7u9PAAuYdYJALtc36bp27evzjnnHEnShAkTtHPnTv3rv/6rHn300R7XlpWVqayszO0lAejGjSJXa9ZJS+x42jNyrJoRZp0A8PxsmmQy2aUuBIC/3Dqx15p1smBdvSJSl4DEqVknfnYKAXCOq8HI0qVLdcUVV2jkyJE6duyY1q9fr5deekm//OUv3bwtAJsytd62xI5rwbr6gltvrVkn3YOdSgeCHbeCKADeczUYee+99/T1r39dhw4dUjQa1dixY/XLX/5Ss2bNcvO2AGxoT6a0fNOutFsoKXVkL5Zv2qVZNZUFZRtm11ZpVk2loxmMXIIosieA+VwNRn74wx+6+fIACuBl621pScSx9t1cgqjndrWQPQECgLNpgCKVS+utSWfL2A2iVm7ZqwXr6ntca2VPGEcPmMPzAlYAZrDbUvvu+x/3mKTqVXYh3RaL3SBqzW/2ub4FBcAZBCNAkbLTehvt30cPPv+WawWuvclUoPq1i+0NQ/zwzycz/hvTXwGzsE0DFCmr9Vb6pNXWcmorbqbsgtSRXXBjy8YqUE23xfL959/Waf379FizJSLptH59bN2H6a+AGQhGgCJmtd5WRrtu2VRGy3XHzHP14cf2sgtOslOgakkXREnSvKln27oX018BM7BNAxS5TK23z/z+oK3fdzq7YKdA9cOPT+qOmZ/Whp37084vmVVTqQ07m5n+CgQEwQiAtK23fp0tYze4Ofv0/npl8WUZZ4i4Pf0VgHPYpgGQllXg2lttRpUL2YVcgiAriLpq3JmaPGZIl+City0oNwtvAeSOzAiAtLw4WyYdJw/Yc2P6KwDnkRkBkJEf2YVsXT5SbkFQb9kTAGaIpFIp/0YpZhGPxxWNRhWLxVRRUeH3coCi5cf5LhyEBwRXrs9vghEAxuKQOyCYcn1+UzMCwFhOHrAHwFzUjAAAAF8RjAAAAF8RjAAAAF8RjAAAAF8RjAAAAF8RjAAAAF8RjAAAAF8xZwSAaxhaBsAOghEArrA7zp2ABQDBCBBSfj7kNzce0oJ19T1O3W2JHdeCdfWdh+xx/gwAiWAECCU/H/LtyZSWb9rVIxCRpJQ6Tt5dvmmXkklp4frsAQuA8KOAFQgZKytxaiAiffKQ39x4qOB7tCdT2tbUqo0NB7StqVXtyU9Cih37jva496lSkg7FjuuujY0ZAxapI2BpT6Z6vReAcCAzAoSI3azErJrKvLdssmVd3juWORA51dG2Exn/zQpYVm55Wxt2NrONA4QcmREgROxmJXbsO5rX69vJugwbWJ7Xa6fz/effdjXDA8AMBCNAiNjNSti97lTZsi5SR9ZlwlmDVBUtV6a8S0TS4AF9cr5/unuxZQOEA8EIECJ2sxL5ZC/sZl1e++MHWjanRpJ6BCTW99+9qrbXgCWbQjM8AMxCMAKEyMRRg7NmJaqiHW2+ucol6zK7tkqrbhyvymjXoKcyWq5VN47Xl8aekTVgyWdNFLsCwUQBKxAipSURLZtTowXr6hWRumypWA/5ZXNq8ipezTXrMru2SrNqKjPOOrEClu7FsJXRcn3t4pH6/vNv5bQmZpYAwRVJpVLG/ukQj8cVjUYVi8VUUVHh93KAwHDjwdyeTGnaii1qiR1PWzcSUUcg8criy3IKdtINZ5OU070yDVmzVsHMEsBbuT6/XQ1G6urq9LOf/Uy7d+9Wv379NGXKFK1YsUKf+cxnbP0+wQiQPzcmsFoPfSl91sXJh77de1lBUqZ6lnyDJAD5y/X57WrNyMsvv6yFCxdq+/bteu6553Ty5El98YtfVFtbm5u3BaCOLZvJY4boqnFnavKYIY48iLPVgjiZfbB7L7fbmQG4z9Wakc2bN3f5/vHHH9ewYcP02muv6dJLL3Xz1gBckq0WxOt7udnODMAbnhawxmIxSdLgwekr+ROJhBKJROf38Xjck3UByI2VdTHhXm62MwPwhmetvclkUrfffrumTp2q2tratNfU1dUpGo12flVXV3u1PAAB5WY7MwBveBaMLFy4UI2NjdqwYUPGa5YuXapYLNb51dzc7NXyAKMxPyMzq51ZyjyzJN92ZgDe8GSb5pZbbtEzzzyjrVu3asSIERmvKysrU1lZmRdLAoyTqfuF+RnZ9TazhM8JMJ+rrb2pVEq33nqrnnrqKb300ks699xzc/p9WntRLDIFHF/5XJUe27qP+Rk2udHODCB3Rs0Z+ad/+ietX79eGzdu7DJbJBqNql+/fll/n2AExSDTwK5smJ9hFgIh4BNGBSORSPr/I65Zs0Zz587N+vsEIwi7bAO77PjR/Es862xBemylAV3l+vx2tWbE4EnzgBGyDeyyg/kZ/sqU2WqJHdeCdfVspQE2cGov4CMnAgnmZ/inPZnS8k270m6xWT9bvmkX3U9AFgQjgI8KCSSYn+E/RtEDziAYAXyUbWCXhfkZZmIUPeAMghHAR9kGdkUk/eOlozw5mA65YxQ94AxPz6YB0JOdgV3/PPuztI0ayMpstcSOp60bsdqv2UoDeudqa2+haO1FMWFORTBZ3TSSugQkDKZDMTNqzkihCEYAZxHwuIM5I0BXRs0ZAWAOkx+YQQ+SZtdWaVZNZaDfA+AnMiNAEcg0mMuErQSTgyQA+cn1+U03DRByJg/msoKk7rM6rOmlmxsPeb4mAN4jGAFCztTBXCYHSQC8RTAChJypg7lMDZIAeI9gBAg5UwdzmRokAfAewQgQctlGzvtxxk17MqX3jyVsXcv0UiD8CEaAkMs2cl7y9oybzY2HNG3FFn3nv97s9ToOAgSKB8EIUASskfN+n3GTqXumOw4CBIoLQ8+AIuH3YK7eume6q2TOCFBUCEaAIlJaEtHkMUN6vcataajZumcsd1/5Wc2dOoqMCFBECEYAdHJzGqrdrpjTB5YRiABFhpoRAJLcn4ZqaosxAP8RjADwZBqqiS3GAMxAMALAk2moprUYAzAHwQhgkPZkStuaWrWx4YC2NbV6di6LV9NQvWox9utzBJAfClgBQ7hZPJqNl/UcbrcY+/k5AsgPmRHAAG4Xj2bjdT2H1WJ81bgzNXnMEEcDET8/RwD5IRgBfHbiL0nd+dQbrhaPZuNkPYdfWyReFOECcAfbNICPNjce0p1PNepo28mM15xaPJptYFkhrHqO7lscuUxD9XOLJJciXDc/RwC5IxgBfGJtKdj9O73Q4lE7CqnnyPR+rC0St8/A8aoIF4DzCEYAH+RyTovFq2FgdkbGd5dtiySiji2SWTWVrrXuMlQNCC5qRgAf2D2nRQrGMDAv5pRkE9SharQhA2RGAF/kulVg+jAwE7ZIrCLcBevqFZG6ZGlMHapGGzLQgcwI4AO7WwWDB/RxvdbCCaZskWQaqhbt10e3zzxXs2oqXb1/LmhDBj7hajCydetWzZkzR2eccYYikYiefvppN28HBEa2LQVJGjKgr7YvnWl8ICKZtUUyu7ZKryy+THfM/LRO69dHkvThn0/q+8+/rWkrthjxkKcNGejK1WCkra1Nn/vc5/Twww+7eRsgcLLN9YhIuueaWvX9q2AkL007d+a5XS168Pm39OGfu7ZMe5F1sFMDYkKNDWASV2tGrrjiCl1xxRVu3gIILCfmepjElPfjZ2eP3RqQltifbb0ebcgoFkYVsCYSCSUSic7v4/G4j6sB3Of2OS1eM+H9+DX8zO6clc2Nh/Sd/3rT1mvShoxiYVQwUldXp+XLl/u9DMBT+cz1MJnf78ePzh672ZhkUlq4Pvugu4g6MkqmtSEDbjFqQ3rp0qWKxWKdX83NzX4vCUDA+NHZYzcbc9fGRtuD7kxrQwbcZFRmpKysTGVlZX4vA0CAWZ09LbHjaR/8bmQd7GZZjradyHrN4AF9dO81FwSuZggohFGZEQAolB+dPU5mWe7+8vkEIig6rgYjH330kRoaGtTQ0CBJ2rdvnxoaGrR//343bwugyGUaflYZLXdliJydOSuDB/Sx9VqVFRStovhEUqmUa1N1XnrpJc2YMaPHz2+66SY9/vjjWX8/Ho8rGo0qFoupoqLChRUCCLP2ZMqzzh6rm0ZKP4r+4f91ob7zX29m3T56ZfFl1Iog8HJ9frtaMzJ9+nS5GOsAQK+87OyxM2elpCTSGbB0l5L0lc9VEYigKBlVwAoAQWZnzkq/vqX6+ER72t9/bOs+XThyEDUjKDoEIwDgoEzZmM2Nh/SNDFmRU7k1HRYwGd00AALLzjkwJrCGomXDmTQoVmRGAASS3XNgTJBtKFp3nEmDYkNmBEDgWJ0r3R/wXpzKm49cgwvOpEGxIRgBECjZzoGROuouTNqyySW4qOJMGhQhghEAgZLLqbymyDYUzRIRZ9KgOBGMAAgUP07lLVRvI+otg/r3cWU6LBAEBCMAAsWPU3mdYA1Fi/bvORZ+QFmp7rm6lkAERYtgBECg2DkHxuS6iw8/PtnjZx8n2rVw/evGFd4CXiEYARwUlLkXQebHqbxO6G3WiKmFt4BXmDMCOCRIcy+Czs45MKbJpfDWq/N0AFMQjAAOsOZedP+b1pp7QWGi8+ycA+OGfE8CDmLhLeAVghGgQNnmXkTEeSNu8fJUXqmw7Feuhbf5Bj1AEBGMAAUi/V4cCs1+WYW3LbHjaQPXiDq2mSaOGsyWH4oOBaxAgUi/h5dVkPxU/Z9051ONBU19tVt4+9yulkCNugecQGYEKFBQ517kqti2DdJlJzKxm/3KVng7q6ZS01ZsYcsPRYdgBChQLun3oCq2bYNMWzLZ2Ml+9VZ4u62plS0/FCW2aYACBXXuhV1BOyG3UL0VJGdjN/tlFd5eNe5MTR4zpPN/G2z5oVgRjAAOsNLvldGuD6PKaHmg23pNPCHX7cFy2QqS03Fq6uu777fZui7oW35Ad2zTAA7xa+6Fm0zrFPJiuyjXrINT2a/2ZEo/2rE/63Umj7oH8kUwAjjI67kXbjNp28CrwXK5Zh2cmvq6Y99RtcQTWa8787TyQAe4QDoEIwAyMqVTyMvBctkKkiVp8IA+uvvL56uywrnsl92A7rd//FC/+P1BfWnsGQXfEzAFNSMAMvL6hNxM9SC5bBcVKltBckTSvddcoGsu7Fp8WqhcArq7NjZyoB5ChcwIgIysB/OCdfWKSF0yBU53CvVWD5L4S9LWazi1XeTHQXwTRw3Waf366MM/n8x67dG2k7T3IlQIRgD0yosHc7Z6kNtnftrW6zi5XeR1QXJpSUTzpo7S959/y9b1tPciTAhGAGTl5oPZTj3Ihp37VVlRpsPxhKeD5bwuSL7lsnO0+tfv6KPEX7JeS3svwoSaEQC2ZBrUVSi79SDXTxwpKZyD5SylJRH936+OzXod7b0IG4IRAL6yu91w9ukDQjlYrrsvja3SP146qtdrwhB4AadimwaAr3JpH548ZojrdRwmHAh44chBkvZ5ek/ATwQjAHyV60GDbtZxmHAgoFVD0xtO7kXYsE0DwFdOHjRYyLk1phwIaOdsHKdmqgCm8CQYefjhh3X22WervLxckyZN0o4dO7y4LQAPFRIIOHHQ4ObGQ5q2YouuX71dt21o0PWrt2vaii22gggvDwTM9jm1xO3V0Ni9DggC17dpfvzjH2vRokV65JFHNGnSJD344IO6/PLLtWfPHg0bNszt2wPwgBPbG4W0Dxd6bo1TBwJmqzex8zm9b7Og1+51QBC4nhn53ve+p/nz52vevHmqqanRI488ov79++s//uM/3L41AA84ub2RT/uwE1kNJw4EzJaZsfs5ffhx9gmsuVwHBIGrwciJEyf02muvaebMmZ/csKREM2fO1LZt23pcn0gkFI/Hu3wBMJeX2xuZOHFuTaEHAmYLNH7x+0O2P6dIxF5Rqt3rgCBwNRh5//331d7eruHDh3f5+fDhw9XS0tLj+rq6OkWj0c6v6upqN5cHoEBeHmCXiRNZjUIOBLQTkN29sdGRbaBTcS4NwsSobpqlS5cqFot1fjU3N/u9JAC9cCIQKFShWQ2psI4eOwFZa9sJW2t879hxXTJ6iE7r36fX6wb176NLRhOMIDxcDUZOP/10lZaW6vDhw11+fvjwYVVWVva4vqysTBUVFV2+AJjLiUCgUIVkNU6Vb0ePk4HWsIHlKi2J6L6/uaDX6+r+5gJmjCBUXO2m6du3ryZMmKAXXnhBV199tSQpmUzqhRde0C233OLmrQF4INeBZW6wshoL1tUrInVZR65zSvLp6LEbaA0e0EcftJ209TnNru0YCb/61/t0arlNSUSa/9ejQjP6HrC4vk2zaNEirV69WmvXrtWbb76pBQsWqK2tTfPmzXP71gBc5uTAskI4MadEym8UvN3MzHevqu38vvu/S10/p82Nh/TY1q6BiCQlU9JjW/d5NoAN8EoklUq5V+b+P1auXKn7779fLS0tGjdunP7t3/5NkyZNyvp78Xhc0WhUsViMLRvAYCaMUZcKO1emkPdgddNI6TMzVkD0i98f1F0bG3W07ZO23O73aE+mNG3Flox1KFYW5ZXFl7FVA2Pl+vz2JBjJF8EIEBwmHDCXr0xD07oHE9leo7dgJt2/Dx7QV9+9qlZfGvvJa29ratX1q7dnXfOP5l9CRw2Mlevzm4PyADjCzQPs3JStNTciewfT9VZvkinY+aDthBaur9eqkk+CHRM6lACvEYwAKGpOjYKX0gdkuQY7JnQoAV4jGAECKtu2SJC3TbzkdiYi12DHhA4lwGsEI0AA5VOf4EdBaRC4nYnINdhxslUZCAqjJrACyC7bOSh1v9jl2MF1xcCpoWmZ5BPsONWqDAQFmREgQOzUH6z+9b6CizGLiduZiHy3XfIZwAYEFZkRIEDs1B/0dkCuFwfXBZGbmYhCBsNZBbFXjTtTk8cMIRBBaJEZAQLEqXZO2kJ7cjMTYQU73et4KqnjASQRjACB4lQ7J22h6bk5K4VtFyAzghEgQOzUH0QimbdqaAv1V1AHwwFuo2YECBA79Qfz/3pUR1CS4d9pCwVgGoIRIGCyFVsu/VINbaEB1p5MaVtTqzY2HNC2pla191aRDIQEB+UBAcUE1vBhWB3CglN7ASCAnDg5GDBFrs9vtmkAwGfZhtlJHcPq2LJBWBGMAIDPcjlMDwgjghEA8JnbJwcDpiMYAQCfuX1yMGA6ghEA8JnbJwcDpiMYAQzErIniUshhekAYMA4eMAyzJooTh+mhmDFnBDAIsyaKR6ahdAyrQxjk+vwmMwIYItusiYg6Zk3Mqqnk4RRw2bJfHKaHYkPNCGAIZk0UByv71f2/65bYcS1YV6/NjYd8WhngHzIjgCHCPmsiLNsPhbwPsl9AegQjgCHCPGsiLEW5hb6PXLJfbNWgmLBNAxgirLMmwrIt4cT7CHv2C8gXwQhgiDDOmgjLAXBOvY8wZ7+AQhCMAAaxZk1URrs+jCqj5YFs67W7LbG9qdW7ReXBqeLisGa/gEJRMwIYZnZtlWbVVIai2NPudsPC9fW676sXGBts2X0fv9n7fq//nVnZrwXr6hWRumRagpr9ApxAMAIYqLQkEooCRrvbDR/++aQWrKs3Nvtj932sfHFv53/OVNjKpFWgJyawAnBNezKlaSu2qCV2PG29xaki6nggv7L4MuMyA7m8D0u2qbntyZS2N7Vq2zvvS+oIPi8ZPcS49w7kI9fnt2s1I/fcc4+mTJmi/v3767TTTnPrNgB81tuhfqcW5WZj8lC33oqLM8lW2Prcrhb975/+TitfbNLKF/fqhh+8qmkrtgSmuwhwkmvByIkTJ3TttddqwYIFbt0CgM82Nx7StBVbdP3q7bptQ4OuX729xwPV2pY4rV8fW6/pZFurk6cfZyou7k2mACss7c6AU1yrGVm+fLkk6fHHH3frFgB8lOlQP+uBeur2xOzaKg0s76MbfvBq1td1qq3VjUFr3YuL3z58TCtfbMr6e6cGWExhBXoyqrU3kUgoHo93+QJgnnzmblwyeohnba1uZh6s4uKrxp2pqecMtfU7pwZYnEEE9GRUMFJXV6doNNr5VV1d7feSAKSRzwPVq6FuXg5ay2duCFNYgZ5yCkaWLFmiSCTS69fu3bvzXszSpUsVi8U6v5qbm/N+LQDuyfeB6sVQNy8zD/kEWExhBXrKqWbkW9/6lubOndvrNaNHj857MWVlZSorK8v79wF4o5AHqttD3bzOPOQ6N8TKpmRqE7ZanJnCimKSUzAydOhQDR1qb48UQHgV+kB1c6ibH5mHXAIsprACPblWM7J//341NDRo//79am9vV0NDgxoaGvTRRx+5dUsAHjH5UD+/zn85tbB18pjeh5eF7QwioFCuTWCdO3eu1q5d2+PnL774oqZPn27rNZjACpjNjfZZp9a1YF29pPSZB1Me+O3JVCjOIAK6y/X5zTh4AAUx9YFqaqAEFAOCEQD4H6YGSkDY5fr85tReAKEVltOPgbAzaugZAAAoPgQjAADAVwQjAADAVwQjAADAVwQjAADAVwQjAADAVwQjAADAVwQjAADAVww9A1CUvJrOyhRYIDuCEQBFx6tzazgfB7CHbRoARcU60ffUAEGSWmLHtWBdvTY3HgrUfYAwIBgB0Kk9mdK2plZtbDigbU2tak8ae45mXtqTKS3ftEvp3pX1s+WbdhX8vr26DxAWbNMAkGT2loJTdRc79h3tkak4VUrSodhx7dh3tKAD9ry6DxAWBCMAOrcUuv+dbm0prLpxvG8BiZNB0nvHMgcI+Vzn932AsGCbBihyJm8pOF13MWxguaPX+X0fICwIRoAil8uWgpfcCJImjhqsqmi5Mm3wRNSRdZk4anCOq/XnPkBYEIwARc7ULQU3gqTSkoiWzamRpB6BgvX9sjk1tupReiv2dfI+QDGgZgQocqZuKbgVJM2urdKqG8f3qEOpzKEOxU4dixP3AYoFwQhQ5KwthZbY8bRbIpI0eEAftcSPa1tTq2cTRN0MkmbXVmlWTWWXDp0JZw3Sa3/8QBsbDvTasZNLsW+6+zCBFegpkkqljG10j8fjikajisViqqio8Hs5QGhZD1hJGQMSi1ftvu3JlKat2JIxSIqoI8vwyuLLCn642+3YsdaUafvIyTUBQZbr85uaEQCdWwqV0exZBq8miHpVd5FLx46pxb5A0BGMAJDUEZC8svgy/Wj+Jfr+dZ/T4AF9017nZbtvpiCpMlruyOyTXDt2TC32BYKOmhEAnUpLIpo8Zoi2NbXqaNuJjNd5OUHUzbqLXCelmlrsCwQdwQiAHkzLAFhBktNyfZ/Zin2tmhHmhwC5YZsGMIRJh9QVSwYg1/fJ/BDAHWRGAAOYdkhdsWQA8nmfzA8BnEdrL+CzTHMrrL+t/TqkLlO7r9/rclq+79Opk4SBMMr1+U0wAvjIz7kVdh6mpmVs3FIs7xPwSq7Pb7ZpAB/l2s3hFLsP32KZIFos7xMwFcEI4CM/ulZyGWcuudfJYppieZ+AiVzrpnn33Xd18803a9SoUerXr5/GjBmjZcuW6cSJzLMLgGLjdddKrkO+AMALrmVGdu/erWQyqUcffVTnnHOOGhsbNX/+fLW1temBBx5w67ZAoHjdteLXthAA9Ma1YGT27NmaPXt25/ejR4/Wnj17tGrVKoIRFL1Ti0e/dvFIPfj8W4oofTeHk3MrTBtmBgCSxzUjsVhMgwdn/gsvkUgokUh0fh+Px71YFuCpdMWjp/XvI0n68OOTnT9zY25FsQwzAxAsngUje/fu1UMPPdRrVqSurk7Lly/3akmA5zIVj8Y+PqmUpDtmnquzTx/gWjdH2IeZMfsDCKac54wsWbJEK1as6PWaN998U+edd17n9wcOHNDnP/95TZ8+XT/4wQ8y/l66zEh1dTVzRhAKfs4UOVVYh5kxKwQwh+tDz44cOaLW1tZerxk9erT69u04fvzgwYOaPn26LrnkEj3++OMqKbHfwMPQM4TJtqZWXb96e9brfjT/EteLR918cPuRnTB1ii1QrFwfejZ06FANHTrU1rUHDhzQjBkzNGHCBK1ZsyanQAQIG5OKR90a8uVHdiJbu3JEHe3Ks2oq2bIBDOVazciBAwc0ffp0nXXWWXrggQd05MiRzn+rrKx067aAsUwrHnV6yFeuw9Sc4mW7MjUpgDtcC0aee+457d27V3v37tWIESO6/JvBx+EArglz8aif2QmvMk7UpADucW3fZO7cuUqlUmm/gGJUWhLRsjk1kj6pZbCkmynSnkxpW1OrNjYc0LamVqOnouaSnXCaFxknK+vT/T1aWZ/NjYfyfm0AnE0DeGp2bZVW3Ti+x1/Y3WeKBO2vcD/rYdzOOFGTAriPYATwWLbiUb9qLwrhZz2MlXFasK7elSm2jNAH3Ed7C+ADq3j0qnFnavKYIV22ZoJ4kJ2Vncj0uI+oI7PjVj2MlXGqjHYNdiqj5QUHbyZ1QQFhRWYEMEhQ/wp3Ozthh1vtyqZ1QQFhRGYEMEiQ/wp3MzthV6aMUyH8zvoAxYDMCGCQoP8V7lZ2wk8mZH2AsCMYAQzyQVtCJREpU0lIEGaROD1MzQR2u6AA5IdgBDDE5sZDWrj+9bTFq6fir3B/hDHrA5iCYAQwQG9dNJaSiLTyevPaeotJGLM+gAkoYAUMkK2LRurYuhk0oK9HKwIA7xCMAAYIchcNABSKYAQwQNC7aACgENSMAAYI4om+7ckUxZwAHEEwAhggaLMsgnaQHwCzsU0DGMKECaZ2WAf5dS+4tQ7y29x4yKeVAQgqMiOAQUyfZZHtIL+IOg7ym1VTacyaAZiPYAQwjMmzLIJ6kB8AsxGMAIYysUCUFmQAbiAYAQxkaoEoLcgA3EABK2AYkwtErRbkTPmZiDqCJpNakAGYj2AEMEi2AlGpo0C0PdOxvi6zWpAl9QhITGxBBhAMBCOAQewWiH7/uT3a1tTqS1ASlBZkAMFBzQhgELuFnytfbNLKF5t8qyMxvQUZQLAQjAAGybXw06oj8SMjYXILMoBgYZsGMEi2AtHuTKgj8Vt7MqVtTa3a2HDAt60rAIUhMwIYpLczajIp5kFjprZAA8gNmRHAMJkKRLMptkFjJrdAA8gNwQhgoNm1VXpl8WX60fxLdMuMc2z9TjENGjO9BRpAbghGAENZBaJ3zPq0a4PGglpvkcsZOQDMR80IYLje6kgKGTQW5HoLzsgBwoXMCBAATg8aM73eIlvGhjNygHAhMwIEhFODxrLVW0TUUW8xq6bSlyFmdjI2E0cN1mn9++jDj09mfJ3T+vfhjBwgIFzNjHzlK1/RyJEjVV5erqqqKv3d3/2dDh486OYtgVCz6kiuGnemJo8ZklewYHK9hZMZG2bBAsHhajAyY8YM/eQnP9GePXv05JNPqqmpSX/7t3/r5i0BZGFqvUUuHTI79h3tNSsiSR98fJICViAgXN2mueOOOzr/81lnnaUlS5bo6quv1smTJ9WnTx83bw0gA1PrLXLJ2JgaUAHIj2c1I0ePHtUTTzyhKVOmZAxEEomEEolE5/fxeNyr5QFFwxo53xI7njYLEVFHYazX9Ra5BBimBlQA8uN6N83ixYs1YMAADRkyRPv379fGjRszXltXV6doNNr5VV1d7fbygKJjtQpLPesqCmkVLlQuAUa2M3wKmb0CwHs5ByNLlixRJBLp9Wv37t2d13/729/W66+/rl/96lcqLS3V17/+daVS6QcrLV26VLFYrPOrubk5/3cGICOnW4WdkEuAYWpABSA/kVSmyCCDI0eOqLW1tddrRo8erb59+/b4+Z/+9CdVV1frv//7vzV58uSs94rH44pGo4rFYqqoqMhlmQBssIpBC2kVdpLVTSOlH+7WPVAK8uA2IMxyfX7nXDMydOhQDR06NK/FJZNJSepSFwLAP1arsCmsjE33AKMyQ4Dh1OwVAP7KOTNi16uvvqqdO3dq2rRpGjRokJqamnT33Xfr8OHD+sMf/qCysrKsr0FmBChOpmVsAOTG9cyIXf3799fPfvYzLVu2TG1tbaqqqtLs2bN111132QpEAIRXtmDDtIwNAHe5FoxccMEF2rJli1svDyCgqPMA0B0H5QHwjOkH9AHwBwflAXDNqdsxpw8o0//5ubkH9AHwD8EIAFek247pzanj3qkXAYoLwQgAx1nbMfm06nGeDFB8qBkB4KjeTt+1g/NkgOJDZgSAo7KdvpuJXwf0AfAfmREAjspnm4XzZIDiRmYEgKPy2WbJNO4dQHEgGAHgKOv03ZbY8bR1IxFJwyvK9P+uG6f3P0ow7h0AwQgAZ5WWRLRsTo0WrKtXROlP3/0/XzlfU8853YfVATARNSMAHGedvlsZ7bplUxkt16obx7MdA6ALMiOAgcJwau3s2irNqqkM/PsA4D6CEcAwYTpIjtN3AdjBNg1gEA6SA1CMCEYAQ/Q2udT62fJNu9SezHe2KQCYiWAEMES2yaWnHiQHAGFCMAIYwu7kUg6SAxA2BCOAIexOLuUgOQBhQzACGMKaXJqp8TWijq4aDpIDEDYEI4AhrMmlknoEJBwkByDMCEYAgzC5FEAxYugZ4LBCp6cyuRRAsSEYARzk1PRUJpcCKCZs0wAO8WN6ansypW1NrdrYcEDbmloZiAYgkMiMAA7INj01oo7pqbNqKnPabultyydMZ9gAKG4EI4ADcpmemm77JV3Q8dyulozBhiQtWFffI/ixsjAUuwIIEoIRwAGFTE9Nl+E4rX8fffjxyR7XWsFGtH8fx7MwAOAXakYAB+Q7PTVTnUm6QETqCDZSvfy7dQ1n2AAIEjIjgAOs6aktseNpMxYRdcwKmThqcOeWTEv8uL7zzB/SXu8EzrABEBQEI4ADrOmpC9bVKyJ1CTBOnZ6arg7ELZxhAyAo2KYBHJJteqqktFsyTuMMGwBBQ2YEcFCm6amSNG3FFke2ZCLqKHD94OOTvWZhKF4FEBSeZEYSiYTGjRunSCSihoYGL24J+MaannrVuDM1ecwQlZZEsrb+2mWFF3V/c4Ee4QwbACHhSWbkn//5n3XGGWfod7/7nRe3A4yTazGplfHo3uJb2W2oGWfYAAgD14ORZ599Vr/61a/05JNP6tlnn3X7doCRci0mtYKObMEGZ9gACANXg5HDhw9r/vz5evrpp9W/f/+s1ycSCSUSic7v4/G4m8sDPGOn9XfwgL6668rPqjLar0vQQbABIOxcqxlJpVKaO3euvvGNb+iiiy6y9Tt1dXWKRqOdX9XV1W4tD/CU1forfVL3YbG+v+eaWl0zfkRnnQkAFIucg5ElS5YoEon0+rV792499NBDOnbsmJYuXWr7tZcuXapYLNb51dzcnOvyAGNla/2l6BRAsYqkUqmcug2PHDmi1tbWXq8ZPXq0rrvuOm3atEmRyCd/4bW3t6u0tFQ33HCD1q5dm/Ve8Xhc0WhUsVhMFRUVuSwTMFZvJ/ECQBjk+vzOORixa//+/V1qPg4ePKjLL79cP/3pTzVp0iSNGDEi62sQjAAAEDy5Pr9dK2AdOXJkl+8/9alPSZLGjBljKxABAADFgXHwAADAV56Ngz/77LPl0o4QAAAIMDIjAADAVwQjAADAVwQjAADAVwQjAADAVwQjAADAVwQjAADAV5619ubDagXm9F4AAILDem7bHelhdDBy7NgxSeL0XgAAAujYsWOKRqNZr3PtbBonJJNJHTx4UAMHDuxy4F4xiMfjqq6uVnNzM+fyOIjP1R18ru7gc3UHn6s7Tv1cBw4cqGPHjumMM85QSUn2ihCjMyMlJSVFf45NRUUF/2dxAZ+rO/hc3cHn6g4+V3dYn6udjIiFAlYAAOArghEAAOArghFDlZWVadmyZSorK/N7KaHC5+oOPld38Lm6g8/VHYV8rkYXsAIAgPAjMwIAAHxFMAIAAHxFMAIAAHxFMAIAAHxFMBIA7777rm6++WaNGjVK/fr105gxY7Rs2TKdOHHC76UFzsMPP6yzzz5b5eXlmjRpknbs2OH3kgKtrq5OF198sQYOHKhhw4bp6quv1p49e/xeVqjcd999ikQiuv322/1eSuAdOHBAN954o4YMGaJ+/frpggsu0G9/+1u/lxVo7e3tuvvuu7s8n77zne/YPpPGYvQEVnTYvXu3ksmkHn30UZ1zzjlqbGzU/Pnz1dbWpgceeMDv5QXGj3/8Yy1atEiPPPKIJk2apAcffFCXX3659uzZo2HDhvm9vEB6+eWXtXDhQl188cX6y1/+ojvvvFNf/OIXtWvXLg0YMMDv5QXezp079eijj2rs2LF+LyXwPvjgA02dOlUzZszQs88+q6FDh+rtt9/WoEGD/F5aoK1YsUKrVq3S2rVrdf755+u3v/2t5s2bp2g0qm9+85u2X4fW3oC6//77tWrVKr3zzjt+LyUwJk2apIsvvlgrV66U1HH2UXV1tW699VYtWbLE59WFw5EjRzRs2DC9/PLLuvTSS/1eTqB99NFHGj9+vP793/9d3/3udzVu3Dg9+OCDfi8rsJYsWaLf/OY3+vWvf+33UkLly1/+soYPH64f/vCHnT/76le/qn79+mndunW2X4dtmoCKxWIaPHiw38sIjBMnTui1117TzJkzO39WUlKimTNnatu2bT6uLFxisZgk8b9NByxcuFBXXnlll//NIn8///nPddFFF+naa6/VsGHDdOGFF2r16tV+LyvwpkyZohdeeEFvvfWWJOl3v/udXnnlFV1xxRU5vQ7bNAG0d+9ePfTQQ2zR5OD9999Xe3u7hg8f3uXnw4cP1+7du31aVbgkk0ndfvvtmjp1qmpra/1eTqBt2LBB9fX12rlzp99LCY133nlHq1at0qJFi3TnnXdq586d+uY3v6m+ffvqpptu8nt5gbVkyRLF43Gdd955Ki0tVXt7u+655x7dcMMNOb0OmREfLVmyRJFIpNev7g/KAwcOaPbs2br22ms1f/58n1YO9LRw4UI1NjZqw4YNfi8l0Jqbm3XbbbfpiSeeUHl5ud/LCY1kMqnx48fr3nvv1YUXXqh/+Id/0Pz58/XII4/4vbRA+8lPfqInnnhC69evV319vdauXasHHnhAa9euzel1yIz46Fvf+pbmzp3b6zWjR4/u/M8HDx7UjBkzNGXKFD322GMury5cTj/9dJWWlurw4cNdfn748GFVVlb6tKrwuOWWW/TMM89o69atGjFihN/LCbTXXntN7733nsaPH9/5s/b2dm3dulUrV65UIpFQaWmpjysMpqqqKtXU1HT52Wc/+1k9+eSTPq0oHL797W9ryZIl+trXviZJuuCCC/THP/5RdXV1OWWcCEZ8NHToUA0dOtTWtQcOHNCMGTM0YcIErVmzRiUlJLVy0bdvX02YMEEvvPCCrr76akkdfym98MILuuWWW/xdXIClUindeuuteuqpp/TSSy9p1KhRfi8p8L7whS/ojTfe6PKzefPm6bzzztPixYsJRPI0derUHm3nb731ls466yyfVhQOH3/8cY/nUWlpqZLJZE6vQzASAAcOHND06dN11lln6YEHHtCRI0c6/42/6u1btGiRbrrpJl100UWaOHGiHnzwQbW1tWnevHl+Ly2wFi5cqPXr12vjxo0aOHCgWlpaJEnRaFT9+vXzeXXBNHDgwB41NwMGDNCQIUOoxSnAHXfcoSlTpujee+/Vddddpx07duixxx4jy1ygOXPm6J577tHIkSN1/vnn6/XXX9f3vvc9/f3f/31uL5SC8dasWZOSlPYLuXnooYdSI0eOTPXt2zc1ceLE1Pbt2/1eUqBl+t/lmjVr/F5aqHz+859P3XbbbX4vI/A2bdqUqq2tTZWVlaXOO++81GOPPeb3kgIvHo+nbrvtttTIkSNT5eXlqdGjR6f+5V/+JZVIJHJ6HeaMAAAAX1F4AAAAfEUwAgAAfEUwAgAAfEUwAgAAfEUwAgAAfEUwAgAAfEUwAgAAfEUwAgAAfEUwAgAAfEUwAgAAfEUwAgAAfEUwAgAAfPX/AS/wCD6IWH3FAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#% --------------------------------------------------------------------------------\n",
        "# ## Load the dataset.\n",
        "#%%\n",
        "# \"\"\" Load dataset \"\"\"\n",
        "\n",
        "if scene_type==\"synthetic\":\n",
        "  white_bkgd = True\n",
        "elif scene_type==\"forwardfacing\":\n",
        "  white_bkgd = False\n",
        "elif scene_type==\"real360\":\n",
        "  white_bkgd = False\n",
        "\n",
        "\n",
        "#https://github.com/google-research/google-research/blob/master/snerg/nerf/datasets.py\n",
        "\n",
        "\n",
        "if scene_type==\"synthetic\":\n",
        "\n",
        "  def load_blender(data_dir, split):\n",
        "    with open(\n",
        "        os.path.join(data_dir, \"transforms_{}.json\".format(split)), \"r\") as fp:\n",
        "      meta = json.load(fp)\n",
        "\n",
        "    cams = []\n",
        "    paths = []\n",
        "    for i in range(len(meta[\"frames\"])):\n",
        "      frame = meta[\"frames\"][i]\n",
        "      cams.append(np.array(frame[\"transform_matrix\"], dtype=np.float32))\n",
        "\n",
        "      fname = os.path.join(data_dir, frame[\"file_path\"] + \".png\")\n",
        "      paths.append(fname)\n",
        "\n",
        "    def image_read_fn(fname):\n",
        "      with open(fname, \"rb\") as imgin:\n",
        "        image = np.array(Image.open(imgin), dtype=np.float32) / 255.\n",
        "      return image\n",
        "    with ThreadPool() as pool:\n",
        "      images = pool.map(image_read_fn, paths)\n",
        "      pool.close()\n",
        "      pool.join()\n",
        "\n",
        "    images = np.stack(images, axis=0)\n",
        "    if white_bkgd:\n",
        "      images = (images[..., :3] * images[..., -1:] + (1. - images[..., -1:]))\n",
        "    else:\n",
        "      images = images[..., :3] * images[..., -1:]\n",
        "\n",
        "    h, w = images.shape[1:3]\n",
        "    camera_angle_x = float(meta[\"camera_angle_x\"])\n",
        "    focal = .5 * w / np.tan(.5 * camera_angle_x)\n",
        "\n",
        "    hwf = np.array([h, w, focal], dtype=np.float32)\n",
        "    poses = np.stack(cams, axis=0)\n",
        "    return {'images' : images, 'c2w' : poses, 'hwf' : hwf}\n",
        "\n",
        "  data = {'train' : load_blender(scene_dir, 'train'),\n",
        "          'test' : load_blender(scene_dir, 'test')}\n",
        "\n",
        "  splits = ['train', 'test']\n",
        "  for s in splits:\n",
        "    print(s)\n",
        "    for k in data[s]:\n",
        "      print(f'  {k}: {data[s][k].shape}')\n",
        "\n",
        "  images, poses, hwf = data['train']['images'], data['train']['c2w'], data['train']['hwf']\n",
        "  write_floatpoint_image(samples_dir+\"/training_image_sample.png\",images[0])\n",
        "\n",
        "  for i in range(3):\n",
        "    plt.figure()\n",
        "    plt.scatter(poses[:,i,3], poses[:,(i+1)%3,3])\n",
        "    plt.axis('equal')\n",
        "    plt.savefig(samples_dir+\"/training_camera\"+str(i)+\".png\")\n",
        "\n",
        "elif scene_type==\"forwardfacing\" or scene_type==\"real360\":\n",
        "\n",
        "  import numpy as np #temporarily use numpy as np, then switch back to jax.numpy\n",
        "  import jax.numpy as jnp\n",
        "\n",
        "  def _viewmatrix(z, up, pos):\n",
        "    \"\"\"Construct lookat view matrix.\"\"\"\n",
        "    vec2 = _normalize(z)\n",
        "    vec1_avg = up\n",
        "    vec0 = _normalize(np.cross(vec1_avg, vec2))\n",
        "    vec1 = _normalize(np.cross(vec2, vec0))\n",
        "    m = np.stack([vec0, vec1, vec2, pos], 1)\n",
        "    return m\n",
        "\n",
        "  def _normalize(x):\n",
        "    \"\"\"Normalization helper function.\"\"\"\n",
        "    return x / np.linalg.norm(x)\n",
        "\n",
        "  def _poses_avg(poses):\n",
        "    \"\"\"Average poses according to the original NeRF code.\"\"\"\n",
        "    hwf = poses[0, :3, -1:]\n",
        "    center = poses[:, :3, 3].mean(0)\n",
        "    vec2 = _normalize(poses[:, :3, 2].sum(0))\n",
        "    up = poses[:, :3, 1].sum(0)\n",
        "    c2w = np.concatenate([_viewmatrix(vec2, up, center), hwf], 1)\n",
        "    return c2w\n",
        "\n",
        "  def _recenter_poses(poses):\n",
        "    \"\"\"Recenter poses according to the original NeRF code.\"\"\"\n",
        "    poses_ = poses.copy()\n",
        "    bottom = np.reshape([0, 0, 0, 1.], [1, 4])\n",
        "    c2w = _poses_avg(poses)\n",
        "    c2w = np.concatenate([c2w[:3, :4], bottom], -2)\n",
        "    bottom = np.tile(np.reshape(bottom, [1, 1, 4]), [poses.shape[0], 1, 1])\n",
        "    poses = np.concatenate([poses[:, :3, :4], bottom], -2)\n",
        "    poses = np.linalg.inv(c2w) @ poses\n",
        "    poses_[:, :3, :4] = poses[:, :3, :4]\n",
        "    poses = poses_\n",
        "    return poses\n",
        "\n",
        "  def _transform_poses_pca(poses):\n",
        "    \"\"\"Transforms poses so principal components lie on XYZ axes.\"\"\"\n",
        "    poses_ = poses.copy()\n",
        "    t = poses[:, :3, 3]\n",
        "    t_mean = t.mean(axis=0)\n",
        "    t = t - t_mean\n",
        "\n",
        "    eigval, eigvec = np.linalg.eig(t.T @ t)\n",
        "    # Sort eigenvectors in order of largest to smallest eigenvalue.\n",
        "    inds = np.argsort(eigval)[::-1]\n",
        "    eigvec = eigvec[:, inds]\n",
        "    rot = eigvec.T\n",
        "    if np.linalg.det(rot) < 0:\n",
        "      rot = np.diag(np.array([1, 1, -1])) @ rot\n",
        "\n",
        "    transform = np.concatenate([rot, rot @ -t_mean[:, None]], -1)\n",
        "    bottom = np.broadcast_to([0, 0, 0, 1.], poses[..., :1, :4].shape)\n",
        "    pad_poses = np.concatenate([poses[..., :3, :4], bottom], axis=-2)\n",
        "    poses_recentered = transform @ pad_poses\n",
        "    poses_recentered = poses_recentered[..., :3, :4]\n",
        "    transform = np.concatenate([transform, np.eye(4)[3:]], axis=0)\n",
        "\n",
        "    # Flip coordinate system if z component of y-axis is negative\n",
        "    if poses_recentered.mean(axis=0)[2, 1] < 0:\n",
        "      poses_recentered = np.diag(np.array([1, -1, -1])) @ poses_recentered\n",
        "      transform = np.diag(np.array([1, -1, -1, 1])) @ transform\n",
        "\n",
        "    # Just make sure it's it in the [-1, 1]^3 cube\n",
        "    scale_factor = 1. / np.max(np.abs(poses_recentered[:, :3, 3]))\n",
        "    poses_recentered[:, :3, 3] *= scale_factor\n",
        "    transform = np.diag(np.array([scale_factor] * 3 + [1])) @ transform\n",
        "\n",
        "    poses_[:, :3, :4] = poses_recentered[:, :3, :4]\n",
        "    poses_recentered = poses_\n",
        "    return poses_recentered, transform\n",
        "\n",
        "  def load_LLFF(data_dir, split, factor = 4, llffhold = 8):\n",
        "    # Load images.\n",
        "    imgdir_suffix = \"\"\n",
        "    if factor > 0:\n",
        "      imgdir_suffix = \"_{}\".format(factor)\n",
        "    imgdir = os.path.join(data_dir, \"images\" + imgdir_suffix)\n",
        "    if not os.path.exists(imgdir):\n",
        "      raise ValueError(\"Image folder {} doesn't exist.\".format(imgdir))\n",
        "    imgfiles = [\n",
        "        os.path.join(imgdir, f)\n",
        "        for f in sorted(os.listdir(imgdir))\n",
        "        if f.endswith(\"JPG\") or f.endswith(\"jpg\") or f.endswith(\"png\")\n",
        "    ]\n",
        "    def image_read_fn(fname):\n",
        "      with open(fname, \"rb\") as imgin:\n",
        "        image = np.array(Image.open(imgin), dtype=np.float32) / 255.\n",
        "      return image\n",
        "    with ThreadPool() as pool:\n",
        "      images = pool.map(image_read_fn, imgfiles)\n",
        "      pool.close()\n",
        "      pool.join()\n",
        "    images = np.stack(images, axis=-1)\n",
        "\n",
        "    # Load poses and bds.\n",
        "    with open(os.path.join(data_dir, \"poses_bounds.npy\"),\n",
        "                          \"rb\") as fp:\n",
        "      poses_arr = np.load(fp)\n",
        "    poses = poses_arr[:, :-2].reshape([-1, 3, 5]).transpose([1, 2, 0])\n",
        "    bds = poses_arr[:, -2:].transpose([1, 0])\n",
        "    if poses.shape[-1] != images.shape[-1]:\n",
        "      raise RuntimeError(\"Mismatch between imgs {} and poses {}\".format(\n",
        "          images.shape[-1], poses.shape[-1]))\n",
        "\n",
        "    # Update poses according to downsampling.\n",
        "    poses[:2, 4, :] = np.array(images.shape[:2]).reshape([2, 1])\n",
        "    poses[2, 4, :] = poses[2, 4, :] * 1. / factor\n",
        "\n",
        "    # Correct rotation matrix ordering and move variable dim to axis 0.\n",
        "    poses = np.concatenate(\n",
        "        [poses[:, 1:2, :], -poses[:, 0:1, :], poses[:, 2:, :]], 1)\n",
        "    poses = np.moveaxis(poses, -1, 0).astype(np.float32)\n",
        "    images = np.moveaxis(images, -1, 0)\n",
        "    bds = np.moveaxis(bds, -1, 0).astype(np.float32)\n",
        "\n",
        "\n",
        "    if scene_type==\"real360\":\n",
        "      # Rotate/scale poses to align ground with xy plane and fit to unit cube.\n",
        "      poses, _ = _transform_poses_pca(poses)\n",
        "    else:\n",
        "      # Rescale according to a default bd factor.\n",
        "      scale = 1. / (bds.min() * .75)\n",
        "      poses[:, :3, 3] *= scale\n",
        "      bds *= scale\n",
        "      # Recenter poses\n",
        "      poses = _recenter_poses(poses)\n",
        "\n",
        "    # Select the split.\n",
        "    i_test = np.arange(images.shape[0])[::llffhold]\n",
        "    i_train = np.array(\n",
        "        [i for i in np.arange(int(images.shape[0])) if i not in i_test])\n",
        "    if split == \"train\":\n",
        "      indices = i_train\n",
        "    else:\n",
        "      indices = i_test\n",
        "    images = images[indices]\n",
        "    poses = poses[indices]\n",
        "\n",
        "    camtoworlds = poses[:, :3, :4]\n",
        "    focal = poses[0, -1, -1]\n",
        "    h, w = images.shape[1:3]\n",
        "\n",
        "    hwf = np.array([h, w, focal], dtype=np.float32)\n",
        "\n",
        "    return {'images' : jnp.array(images), 'c2w' : jnp.array(camtoworlds), 'hwf' : jnp.array(hwf)}\n",
        "\n",
        "  data = {'train' : load_LLFF(scene_dir, 'train'),\n",
        "          'test' : load_LLFF(scene_dir, 'test')}\n",
        "\n",
        "  splits = ['train', 'test']\n",
        "  for s in splits:\n",
        "    print(s)\n",
        "    for k in data[s]:\n",
        "      print(f'  {k}: {data[s][k].shape}')\n",
        "\n",
        "  images, poses, hwf = data['train']['images'], data['train']['c2w'], data['train']['hwf']\n",
        "  write_floatpoint_image(samples_dir+\"/training_image_sample.png\",images[0])\n",
        "\n",
        "  for i in range(3):\n",
        "    plt.figure()\n",
        "    plt.scatter(poses[:,i,3], poses[:,(i+1)%3,3])\n",
        "    plt.axis('equal')\n",
        "    plt.savefig(samples_dir+\"/training_camera\"+str(i)+\".png\")\n",
        "\n",
        "  bg_color = jnp.mean(images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDS6XyMR-Vr9"
      },
      "source": [
        "## Define helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ng0yhdgK-Vr9"
      },
      "outputs": [],
      "source": [
        "import jax.numpy as np\n",
        "#%% --------------------------------------------------------------------------------\n",
        "# ## Helper functions\n",
        "#%%\n",
        "adam_kwargs = {\n",
        "    'b1': 0.9,\n",
        "    'b2': 0.999,\n",
        "    'eps': 1e-15,\n",
        "}\n",
        "\n",
        "n_device = jax.local_device_count()\n",
        "\n",
        "rng = random.PRNGKey(1)\n",
        "\n",
        "\n",
        "\n",
        "# General math functions.\n",
        "\n",
        "def matmul(a, b):\n",
        "  \"\"\"jnp.matmul defaults to bfloat16, but this helper function doesn't.\"\"\"\n",
        "  return np.matmul(a, b, precision=jax.lax.Precision.HIGHEST)\n",
        "\n",
        "def normalize(x):\n",
        "  \"\"\"Normalization helper function.\"\"\"\n",
        "  return x / np.linalg.norm(x, axis=-1, keepdims=True)\n",
        "\n",
        "def sinusoidal_encoding(position, minimum_frequency_power,\n",
        "    maximum_frequency_power,include_identity = False):\n",
        "  # Compute the sinusoidal encoding components\n",
        "  frequency = 2.0**np.arange(minimum_frequency_power, maximum_frequency_power)\n",
        "  angle = position[..., None, :] * frequency[:, None]\n",
        "  encoding = np.sin(np.stack([angle, angle + 0.5 * np.pi], axis=-2))\n",
        "  # Flatten encoding dimensions\n",
        "  encoding = encoding.reshape(*position.shape[:-1], -1)\n",
        "  # Add identity component\n",
        "  if include_identity:\n",
        "    encoding = np.concatenate([position, encoding], axis=-1)\n",
        "  return encoding\n",
        "\n",
        "# Pose/ray math.\n",
        "\n",
        "def generate_rays(pixel_coords, pix2cam, cam2world):\n",
        "  \"\"\"Generate camera rays from pixel coordinates and poses.\"\"\"\n",
        "  homog = np.ones_like(pixel_coords[..., :1])\n",
        "  pixel_dirs = np.concatenate([pixel_coords + .5, homog], axis=-1)[..., None]\n",
        "  cam_dirs = matmul(pix2cam, pixel_dirs)\n",
        "  ray_dirs = matmul(cam2world[..., :3, :3], cam_dirs)[..., 0]\n",
        "  ray_origins = np.broadcast_to(cam2world[..., :3, 3], ray_dirs.shape)\n",
        "\n",
        "  #f = 1./pix2cam[0,0]\n",
        "  #w = -2. * f * pix2cam[0,2]\n",
        "  #h =  2. * f * pix2cam[1,2]\n",
        "\n",
        "  return ray_origins, ray_dirs\n",
        "\n",
        "def pix2cam_matrix(height, width, focal):\n",
        "  \"\"\"Inverse intrinsic matrix for a pinhole camera.\"\"\"\n",
        "  return  np.array([\n",
        "      [1./focal, 0, -.5 * width / focal],\n",
        "      [0, -1./focal, .5 * height / focal],\n",
        "      [0, 0, -1.],\n",
        "  ])\n",
        "\n",
        "def camera_ray_batch_xxxxx_original(cam2world, hwf):\n",
        "  \"\"\"Generate rays for a pinhole camera with given extrinsic and intrinsic.\"\"\"\n",
        "  height, width = int(hwf[0]), int(hwf[1])\n",
        "  pix2cam = pix2cam_matrix(*hwf)\n",
        "  pixel_coords = np.stack(np.meshgrid(np.arange(width), np.arange(height)), axis=-1)\n",
        "  return generate_rays(pixel_coords, pix2cam, cam2world)\n",
        "\n",
        "def camera_ray_batch(cam2world, hwf): ### antialiasing by supersampling\n",
        "  \"\"\"Generate rays for a pinhole camera with given extrinsic and intrinsic.\"\"\"\n",
        "  height, width = int(hwf[0]), int(hwf[1])\n",
        "  pix2cam = pix2cam_matrix(*hwf)\n",
        "  x_ind, y_ind = np.meshgrid(np.arange(width), np.arange(height))\n",
        "  pixel_coords = np.stack([x_ind-0.25, y_ind-0.25, x_ind+0.25, y_ind-0.25,\n",
        "                  x_ind-0.25, y_ind+0.25, x_ind+0.25, y_ind+0.25], axis=-1)\n",
        "  pixel_coords = np.reshape(pixel_coords, [height,width,4,2])\n",
        "\n",
        "  return generate_rays(pixel_coords, pix2cam, cam2world)\n",
        "\n",
        "def random_ray_batch_xxxxx_original(rng, batch_size, data):\n",
        "  \"\"\"Generate a random batch of ray data.\"\"\"\n",
        "  keys = random.split(rng, 3)\n",
        "  cam_ind = random.randint(keys[0], [batch_size], 0, data['c2w'].shape[0])\n",
        "  y_ind = random.randint(keys[1], [batch_size], 0, data['images'].shape[1])\n",
        "  x_ind = random.randint(keys[2], [batch_size], 0, data['images'].shape[2])\n",
        "  pixel_coords = np.stack([x_ind, y_ind], axis=-1)\n",
        "  pix2cam = pix2cam_matrix(*data['hwf'])\n",
        "  cam2world = data['c2w'][cam_ind, :3, :4]\n",
        "  rays = generate_rays(pixel_coords, pix2cam, cam2world)\n",
        "  pixels = data['images'][cam_ind, y_ind, x_ind]\n",
        "  return rays, pixels\n",
        "\n",
        "def random_ray_batch(rng, batch_size, data): ### antialiasing by supersampling\n",
        "  \"\"\"Generate a random batch of ray data.\"\"\"\n",
        "  keys = random.split(rng, 3)\n",
        "  cam_ind = random.randint(keys[0], [batch_size], 0, data['c2w'].shape[0])\n",
        "  y_ind = random.randint(keys[1], [batch_size], 0, data['images'].shape[1])\n",
        "  y_ind_f = y_ind.astype(np.float32)\n",
        "  x_ind = random.randint(keys[2], [batch_size], 0, data['images'].shape[2])\n",
        "  x_ind_f = x_ind.astype(np.float32)\n",
        "  pixel_coords = np.stack([x_ind_f-0.25, y_ind_f-0.25, x_ind_f+0.25, y_ind_f-0.25,\n",
        "                  x_ind_f-0.25, y_ind_f+0.25, x_ind_f+0.25, y_ind_f+0.25], axis=-1)\n",
        "  pixel_coords = np.reshape(pixel_coords, [batch_size,4,2])\n",
        "  pix2cam = pix2cam_matrix(*data['hwf'])\n",
        "  cam_ind_x4 = np.tile(cam_ind[..., None], [1,4])\n",
        "  cam_ind_x4 = np.reshape(cam_ind_x4, [-1])\n",
        "  cam2world = data['c2w'][cam_ind_x4, :3, :4]\n",
        "  cam2world = np.reshape(cam2world, [batch_size,4,3,4])\n",
        "  rays = generate_rays(pixel_coords, pix2cam, cam2world)\n",
        "  pixels = data['images'][cam_ind, y_ind, x_ind]\n",
        "  return rays, pixels\n",
        "\n",
        "\n",
        "# Learning rate helpers.\n",
        "\n",
        "def log_lerp(t, v0, v1):\n",
        "  \"\"\"Interpolate log-linearly from `v0` (t=0) to `v1` (t=1).\"\"\"\n",
        "  if v0 <= 0 or v1 <= 0:\n",
        "    raise ValueError(f'Interpolants {v0} and {v1} must be positive.')\n",
        "  lv0 = np.log(v0)\n",
        "  lv1 = np.log(v1)\n",
        "  return np.exp(np.clip(t, 0, 1) * (lv1 - lv0) + lv0)\n",
        "\n",
        "def lr_fn(step, max_steps, lr0, lr1, lr_delay_steps=20000, lr_delay_mult=0.1):\n",
        "  if lr_delay_steps > 0:\n",
        "    # A kind of reverse cosine decay.\n",
        "    delay_rate = lr_delay_mult + (1 - lr_delay_mult) * np.sin(\n",
        "        0.5 * np.pi * np.clip(step / lr_delay_steps, 0, 1))\n",
        "  else:\n",
        "    delay_rate = 1.\n",
        "  return delay_rate * log_lerp(step / max_steps, lr0, lr1)\n",
        "\n",
        "#%% --------------------------------------------------------------------------------\n",
        "# ## Plane parameters and setup\n",
        "#%%\n",
        "#scene scales\n",
        "\n",
        "if scene_type==\"synthetic\":\n",
        "  scene_grid_scale = 1.2\n",
        "  if \"hotdog\" in scene_dir or \"mic\" in scene_dir or \"ship\" in scene_dir:\n",
        "    scene_grid_scale = 1.5\n",
        "  grid_min = np.array([-1, -1, -1]) * scene_grid_scale\n",
        "  grid_max = np.array([ 1,  1,  1]) * scene_grid_scale\n",
        "  point_grid_size = 128\n",
        "\n",
        "  def get_taper_coord(p):\n",
        "    return p\n",
        "  def inverse_taper_coord(p):\n",
        "    return p\n",
        "\n",
        "elif scene_type==\"forwardfacing\":\n",
        "  scene_grid_taper = 1.25\n",
        "  scene_grid_zstart = 25.0\n",
        "  scene_grid_zend = 1.0\n",
        "  scene_grid_scale = 0.7\n",
        "  grid_min = np.array([-scene_grid_scale, -scene_grid_scale,  0])\n",
        "  grid_max = np.array([ scene_grid_scale,  scene_grid_scale,  1])\n",
        "  point_grid_size = 128\n",
        "\n",
        "  def get_taper_coord(p):\n",
        "    pz = np.maximum(-p[..., 2:3],1e-10)\n",
        "    px = p[..., 0:1]/(pz*scene_grid_taper)\n",
        "    py = p[..., 1:2]/(pz*scene_grid_taper)\n",
        "    pz = (np.log(pz) - np.log(scene_grid_zend))/(np.log(scene_grid_zstart) - np.log(scene_grid_zend))\n",
        "    return np.concatenate([px,py,pz],axis=-1)\n",
        "  def inverse_taper_coord(p):\n",
        "    pz = np.exp( p[..., 2:3] * \\\n",
        "          (np.log(scene_grid_zstart) - np.log(scene_grid_zend)) + \\\n",
        "          np.log(scene_grid_zend) )\n",
        "    px = p[..., 0:1]*(pz*scene_grid_taper)\n",
        "    py = p[..., 1:2]*(pz*scene_grid_taper)\n",
        "    pz = -pz\n",
        "    return np.concatenate([px,py,pz],axis=-1)\n",
        "\n",
        "elif scene_type==\"real360\":\n",
        "  scene_grid_zmax = 16.0\n",
        "  if object_name == \"gardenvase\":\n",
        "    scene_grid_zmax = 9.0\n",
        "  grid_min = np.array([-1, -1, -1])\n",
        "  grid_max = np.array([ 1,  1,  1])\n",
        "  point_grid_size = 128\n",
        "\n",
        "  def get_taper_coord(p):\n",
        "    return p\n",
        "  def inverse_taper_coord(p):\n",
        "    return p\n",
        "\n",
        "  #approximate solution of e^x = ax+b\n",
        "  #(np.exp( x ) + (x-1)) / x = scene_grid_zmax\n",
        "  #np.exp( x ) - scene_grid_zmax*x + (x-1) = 0\n",
        "  scene_grid_zcc = -1\n",
        "  for i in range(10000):\n",
        "    j = numpy.log(scene_grid_zmax)+i/1000.0\n",
        "    if numpy.exp(j) - scene_grid_zmax*j + (j-1) >0:\n",
        "      scene_grid_zcc = j\n",
        "      break\n",
        "  if scene_grid_zcc<0:\n",
        "    print(\"ERROR: approximate solution of e^x = ax+b failed\")\n",
        "    1/0\n",
        "\n",
        "\n",
        "\n",
        "grid_dtype = np.float32\n",
        "\n",
        "#plane parameter grid\n",
        "point_grid = np.zeros(\n",
        "      (point_grid_size, point_grid_size, point_grid_size, 3),\n",
        "      dtype=grid_dtype)\n",
        "acc_grid = np.zeros(\n",
        "      (point_grid_size, point_grid_size, point_grid_size),\n",
        "      dtype=grid_dtype)\n",
        "point_grid_diff_lr_scale = 16.0/point_grid_size\n",
        "\n",
        "\n",
        "\n",
        "def get_acc_grid_masks(taper_positions, acc_grid):\n",
        "  grid_positions = (taper_positions - grid_min) * \\\n",
        "                    (point_grid_size / (grid_max - grid_min) )\n",
        "  grid_masks = (grid_positions[..., 0]>=1) & (grid_positions[..., 0]<point_grid_size-1) \\\n",
        "              & (grid_positions[..., 1]>=1) & (grid_positions[..., 1]<point_grid_size-1) \\\n",
        "              & (grid_positions[..., 2]>=1) & (grid_positions[..., 2]<point_grid_size-1)\n",
        "  grid_positions = grid_positions*grid_masks[..., None]\n",
        "  grid_indices = grid_positions.astype(np.int32)\n",
        "\n",
        "  acc_grid_masks = acc_grid[grid_indices[...,0],grid_indices[...,1],grid_indices[...,2]]\n",
        "  acc_grid_masks = acc_grid_masks*grid_masks\n",
        "\n",
        "  return acc_grid_masks\n",
        "\n",
        "\n",
        "#%% --------------------------------------------------------------------------------\n",
        "# ## MLP setup\n",
        "#%%\n",
        "num_bottleneck_features = 8\n",
        "\n",
        "\n",
        "def dense_layer(width):\n",
        "  return nn.Dense(\n",
        "      width, kernel_init=jax.nn.initializers.glorot_uniform())\n",
        "def dense_layer_zero(width):\n",
        "  return nn.Dense(\n",
        "      width, kernel_init=jax.nn.initializers.zeros)\n",
        "\n",
        "class RadianceField(nn.Module):\n",
        "  \"\"\"TODO(drebain) docstring.\"\"\"\n",
        "  out_dim: int\n",
        "  trunk_width: int = 384\n",
        "  trunk_depth: int = 8\n",
        "  trunk_skip_length: int = 4\n",
        "  network_activation: Callable = nn.relu\n",
        "  position_encoding_max_frequency_power: int = 10\n",
        "  @nn.compact\n",
        "  def __call__(self, positions):\n",
        "    inputs = sinusoidal_encoding(\n",
        "        positions, 0, self.position_encoding_max_frequency_power)\n",
        "    net = inputs\n",
        "    for i in range(self.trunk_depth):\n",
        "      net = dense_layer(self.trunk_width)(net)\n",
        "      net = self.network_activation(net)\n",
        "      if i % self.trunk_skip_length == 0 and i > 0:\n",
        "        net = np.concatenate([net, inputs], axis=-1)\n",
        "\n",
        "    net = dense_layer(self.out_dim)(net)\n",
        "\n",
        "    return net\n",
        "\n",
        "# Set up the MLPs for color and density.\n",
        "class MLP(nn.Module):\n",
        "  features: Sequence[int]\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    for feat in self.features[:-1]:\n",
        "      x = nn.relu(nn.Dense(feat)(x))\n",
        "    x = nn.Dense(self.features[-1])(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "density_model = RadianceField(1)\n",
        "feature_model = RadianceField(num_bottleneck_features)\n",
        "color_model = MLP([16,16,3])\n",
        "\n",
        "# These are the variables we will be optimizing during trianing.\n",
        "model_vars = [point_grid, acc_grid,\n",
        "              density_model.init(\n",
        "                  jax.random.PRNGKey(0),\n",
        "                  np.zeros([1, 3])),\n",
        "              feature_model.init(\n",
        "                  jax.random.PRNGKey(0),\n",
        "                  np.zeros([1, 3])),\n",
        "              color_model.init(\n",
        "                  jax.random.PRNGKey(0),\n",
        "                  np.zeros([1, 3+num_bottleneck_features])),\n",
        "              ]\n",
        "\n",
        "#avoid bugs\n",
        "point_grid = None\n",
        "acc_grid = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1Hqe26n-VsA"
      },
      "source": [
        "## Mesh Rendering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aib9AhkEXR_U"
      },
      "outputs": [],
      "source": [
        "#%% --------------------------------------------------------------------------------\n",
        "# ## Load weights\n",
        "#%%\n",
        "vars = pickle.load(open(weights_dir+\"/\"+\"weights_stage2_1.pkl\", \"rb\"))\n",
        "model_vars = vars\n",
        "#%% --------------------------------------------------------------------------------\n",
        "# ## Get mesh\n",
        "#%%"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gpustat\n",
        "\n",
        "\n",
        "# List to store GPU memory consumption\n",
        "gpu_memory_consumption = []\n",
        "\n",
        "# Time taken for the entire training\n",
        "total_training_start= time.time()\n",
        "\n",
        "step_gpu=0"
      ],
      "metadata": {
        "id": "k9P2NA1kwoWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jY7rwWGFXWd6"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "#%%\n",
        "#extract mesh vertices\n",
        "layer_num = point_grid_size\n",
        "\n",
        "v_grid = numpy.zeros([layer_num+1,layer_num+1,layer_num+1,3], numpy.float32)\n",
        "v_grid[:-1,:-1,:-1] = numpy.array(vars[0])*point_grid_diff_lr_scale\n",
        "#%%\n",
        "#get UV coordinates\n",
        "\n",
        "if scene_type==\"synthetic\":\n",
        "  texture_size = 1024*2\n",
        "  batch_num = 8*8*8\n",
        "elif scene_type==\"forwardfacing\":\n",
        "  texture_size = 1024*2\n",
        "  batch_num = 8*8*8\n",
        "elif scene_type==\"real360\":\n",
        "  texture_size = 1024*2\n",
        "  batch_num = 8*8*8\n",
        "\n",
        "test_threshold = 0.1 #edit 0.1\n",
        "\n",
        "\n",
        "out_feat_num = num_bottleneck_features//4\n",
        "\n",
        "quad_size = texture_size//layer_num\n",
        "assert quad_size*layer_num == texture_size\n",
        "#pre-compute weights for each quad\n",
        "# 0 - 1 x\n",
        "# | \\ |\n",
        "# 2 - 3\n",
        "# y\n",
        "quad_weights = numpy.zeros([quad_size,quad_size,4],numpy.float32)\n",
        "for i in range(quad_size):\n",
        "  for j in range(quad_size):\n",
        "    x = (i)/quad_size\n",
        "    y = (j)/quad_size\n",
        "    if x>y:\n",
        "      quad_weights[i,j,0] = 1-x\n",
        "      quad_weights[i,j,1] = x-y\n",
        "      quad_weights[i,j,2] = 0\n",
        "      quad_weights[i,j,3] = y\n",
        "    else:\n",
        "      quad_weights[i,j,0] = 1-y\n",
        "      quad_weights[i,j,1] = 0\n",
        "      quad_weights[i,j,2] = y-x\n",
        "      quad_weights[i,j,3] = x\n",
        "quad_weights = numpy.reshape(quad_weights,[quad_size*quad_size,4])\n",
        "quad_weights = numpy.transpose(quad_weights, (1,0)) #[4,quad_size*quad_size]\n",
        "\n",
        "grid_max_numpy = numpy.array(grid_max,numpy.float32)\n",
        "grid_min_numpy = numpy.array(grid_min,numpy.float32)\n",
        "\n",
        "i_grid = numpy.zeros([layer_num,layer_num,layer_num],numpy.int32)\n",
        "j_grid = numpy.zeros([layer_num,layer_num,layer_num],numpy.int32)\n",
        "k_grid = numpy.zeros([layer_num,layer_num,layer_num],numpy.int32)\n",
        "\n",
        "i_grid[:,:,:] = numpy.reshape(numpy.arange(layer_num),[-1,1,1])\n",
        "j_grid[:,:,:] = numpy.reshape(numpy.arange(layer_num),[1,-1,1])\n",
        "k_grid[:,:,:] = numpy.reshape(numpy.arange(layer_num),[1,1,-1])\n",
        "\n",
        "\n",
        "\n",
        "def get_density_color(pts, vars):\n",
        "  #redefine net\n",
        "\n",
        "  acc_grid_masks = get_acc_grid_masks(pts, vars[1])\n",
        "\n",
        "  # Now use the MLP to compute density and features\n",
        "  mlp_alpha = density_model.apply(vars[-3], pts)\n",
        "  mlp_alpha = jax.nn.sigmoid(mlp_alpha[..., 0]-8)\n",
        "  mlp_alpha = mlp_alpha * (acc_grid_masks>=test_threshold)\n",
        "  mlp_alpha = (mlp_alpha>0.5).astype(np.uint8)#EDIT (mlp_alpha>0.5).astype(np.uint8)\n",
        "\n",
        "  #previous: (features+dirs)->MLP->(RGB)\n",
        "  mlp_features = jax.nn.sigmoid(feature_model.apply(vars[-2], pts))\n",
        "  #discretize\n",
        "  mlp_features_ = np.round(mlp_features*255).astype(np.uint8)\n",
        "  mlp_features_0 = np.clip(mlp_features_[...,0:1],1,255)*mlp_alpha[..., None]\n",
        "  mlp_features_1 = mlp_features_[...,1:]*mlp_alpha[..., None]\n",
        "  mlp_features_ = np.concatenate([mlp_features_0,mlp_features_1],axis=-1)\n",
        "\n",
        "  return mlp_features_\n",
        "\n",
        "get_density_color_p = jax.pmap(lambda pts, vars: get_density_color(pts,vars),\n",
        "    in_axes=(0, None))\n",
        "\n",
        "\n",
        "\n",
        "def get_feature_png(feat):\n",
        "  h,w,c = feat.shape\n",
        "  #deal with opencv BGR->RGB\n",
        "  if c%4!=0:\n",
        "    print(\"ERROR: c%4!=0\")\n",
        "    1/0\n",
        "  out = []\n",
        "  for i in range(out_feat_num):\n",
        "    ff = numpy.zeros([h,w,4],numpy.uint8)\n",
        "    ff[...,0] = feat[..., i*4+2]\n",
        "    ff[...,1] = feat[..., i*4+1]\n",
        "    ff[...,2] = feat[..., i*4+0]\n",
        "    ff[...,3] = feat[..., i*4+3]\n",
        "    out.append(ff)\n",
        "  return out\n",
        "\n",
        "gpu_stats = gpustat.new_query().jsonify() #EDIT\n",
        "gpu_memory_consumption.append({\n",
        "            \"iteration\": step_gpu,\n",
        "            \"gpu_stats\": gpu_stats\n",
        "   })\n",
        "\n",
        "##### z planes\n",
        "\n",
        "x,y,z = j_grid,k_grid,i_grid\n",
        "p0 = v_grid[x,y,z] + (numpy.stack([x,y,z],axis=-1).astype(numpy.float32)+0.5)*((grid_max_numpy - grid_min_numpy)/point_grid_size) + grid_min_numpy\n",
        "x,y,z = j_grid+1,k_grid,i_grid\n",
        "p1 = v_grid[x,y,z] + (numpy.stack([x,y,z],axis=-1).astype(numpy.float32)+0.5)*((grid_max_numpy - grid_min_numpy)/point_grid_size) + grid_min_numpy\n",
        "x,y,z = j_grid,k_grid+1,i_grid\n",
        "p2 = v_grid[x,y,z] + (numpy.stack([x,y,z],axis=-1).astype(numpy.float32)+0.5)*((grid_max_numpy - grid_min_numpy)/point_grid_size) + grid_min_numpy\n",
        "x,y,z = j_grid+1,k_grid+1,i_grid\n",
        "p3 = v_grid[x,y,z] + (numpy.stack([x,y,z],axis=-1).astype(numpy.float32)+0.5)*((grid_max_numpy - grid_min_numpy)/point_grid_size) + grid_min_numpy\n",
        "p0123 = numpy.stack([p0,p1,p2,p3],axis=-1) #[M,N,K,3,4]\n",
        "p0123 = p0123 @ quad_weights #[M,N,K,3,quad_size*quad_size]\n",
        "p0123 = numpy.reshape(p0123, [layer_num,layer_num,layer_num,3,quad_size,quad_size]) #[M,N,K,3,quad_size,quad_size]\n",
        "p0123 = numpy.transpose(p0123, (0,1,4,2,5,3)) #[M,N,quad_size,K,quad_size,3]\n",
        "#positions_z = numpy.reshape(numpy.ascontiguousarray(p0123), [layer_num,layer_num*quad_size,layer_num*quad_size,3])\n",
        "positions_z = numpy.reshape(numpy.ascontiguousarray(p0123), [-1,3])\n",
        "\n",
        "p0 = None\n",
        "p1 = None\n",
        "p2 = None\n",
        "p3 = None\n",
        "p0123 = None\n",
        "\n",
        "total_len = len(positions_z)\n",
        "batch_len = total_len//batch_num\n",
        "coarse_feature_z = numpy.zeros([total_len,num_bottleneck_features],numpy.uint8)\n",
        "for i in range(batch_num):\n",
        "  t0 = numpy.reshape(positions_z[i*batch_len:(i+1)*batch_len], [n_device,-1,3])\n",
        "  t0 = get_density_color_p(t0,vars)\n",
        "  coarse_feature_z[i*batch_len:(i+1)*batch_len] = numpy.reshape(t0,[-1,num_bottleneck_features])\n",
        "coarse_feature_z = numpy.reshape(coarse_feature_z,[layer_num,texture_size,texture_size,num_bottleneck_features])\n",
        "coarse_feature_z[:,-quad_size:,:] = 0\n",
        "coarse_feature_z[:,:,-quad_size:] = 0\n",
        "\n",
        "positions_z = None\n",
        "\n",
        "\n",
        "buffer_z = []\n",
        "for i in range(layer_num):\n",
        "  if not numpy.any(coarse_feature_z[i,:,:,0]>0):\n",
        "    buffer_z.append(None)\n",
        "    continue\n",
        "  feats = get_feature_png(coarse_feature_z[i])\n",
        "  buffer_z.append(feats)\n",
        "\n",
        "coarse_feature_z = None\n",
        "\n",
        "\n",
        "\n",
        "step_gpu=step_gpu+1\n",
        "gpu_stats = gpustat.new_query().jsonify() #EDIT\n",
        "gpu_memory_consumption.append({\n",
        "            \"iteration\": step_gpu,\n",
        "            \"gpu_stats\": gpu_stats\n",
        "   })\n",
        "\n",
        "##### x planes\n",
        "\n",
        "x,y,z = i_grid,j_grid,k_grid\n",
        "p0 = v_grid[x,y,z] + (numpy.stack([x,y,z],axis=-1).astype(numpy.float32)+0.5)*((grid_max_numpy - grid_min_numpy)/point_grid_size) + grid_min_numpy\n",
        "x,y,z = i_grid,j_grid+1,k_grid\n",
        "p1 = v_grid[x,y,z] + (numpy.stack([x,y,z],axis=-1).astype(numpy.float32)+0.5)*((grid_max_numpy - grid_min_numpy)/point_grid_size) + grid_min_numpy\n",
        "x,y,z = i_grid,j_grid,k_grid+1\n",
        "p2 = v_grid[x,y,z] + (numpy.stack([x,y,z],axis=-1).astype(numpy.float32)+0.5)*((grid_max_numpy - grid_min_numpy)/point_grid_size) + grid_min_numpy\n",
        "x,y,z = i_grid,j_grid+1,k_grid+1\n",
        "p3 = v_grid[x,y,z] + (numpy.stack([x,y,z],axis=-1).astype(numpy.float32)+0.5)*((grid_max_numpy - grid_min_numpy)/point_grid_size) + grid_min_numpy\n",
        "p0123 = numpy.stack([p0,p1,p2,p3],axis=-1) #[M,N,K,3,4]\n",
        "p0123 = p0123 @ quad_weights #[M,N,K,3,quad_size*quad_size]\n",
        "p0123 = numpy.reshape(p0123, [layer_num,layer_num,layer_num,3,quad_size,quad_size]) #[M,N,K,3,quad_size,quad_size]\n",
        "p0123 = numpy.transpose(p0123, (0,1,4,2,5,3)) #[M,N,quad_size,K,quad_size,3]\n",
        "#positions_x = numpy.reshape(numpy.ascontiguousarray(p0123), [layer_num,layer_num*quad_size,layer_num*quad_size,3])\n",
        "positions_x = numpy.reshape(numpy.ascontiguousarray(p0123), [-1,3])\n",
        "\n",
        "p0 = None\n",
        "p1 = None\n",
        "p2 = None\n",
        "p3 = None\n",
        "p0123 = None\n",
        "\n",
        "total_len = len(positions_x)\n",
        "batch_len = total_len//batch_num\n",
        "coarse_feature_x = numpy.zeros([total_len,num_bottleneck_features],numpy.uint8)\n",
        "for i in range(batch_num):\n",
        "  t0 = numpy.reshape(positions_x[i*batch_len:(i+1)*batch_len], [n_device,-1,3])\n",
        "  t0 = get_density_color_p(t0,vars)\n",
        "  coarse_feature_x[i*batch_len:(i+1)*batch_len] = numpy.reshape(t0,[-1,num_bottleneck_features])\n",
        "coarse_feature_x = numpy.reshape(coarse_feature_x,[layer_num,texture_size,texture_size,num_bottleneck_features])\n",
        "coarse_feature_x[:,-quad_size:,:] = 0\n",
        "coarse_feature_x[:,:,-quad_size:] = 0\n",
        "\n",
        "positions_x = None\n",
        "\n",
        "buffer_x = []\n",
        "for i in range(layer_num):\n",
        "  if not numpy.any(coarse_feature_x[i,:,:,0]>0):\n",
        "    buffer_x.append(None)\n",
        "    continue\n",
        "  feats = get_feature_png(coarse_feature_x[i])\n",
        "  buffer_x.append(feats)\n",
        "\n",
        "coarse_feature_x = None\n",
        "\n",
        "\n",
        "step_gpu=step_gpu+1\n",
        "gpu_stats = gpustat.new_query().jsonify() #EDIT\n",
        "gpu_memory_consumption.append({\n",
        "            \"iteration\": step_gpu,\n",
        "            \"gpu_stats\": gpu_stats\n",
        "   })\n",
        "\n",
        "##### y planes\n",
        "\n",
        "x,y,z = j_grid,i_grid,k_grid\n",
        "p0 = v_grid[x,y,z] + (numpy.stack([x,y,z],axis=-1).astype(numpy.float32)+0.5)*((grid_max_numpy - grid_min_numpy)/point_grid_size) + grid_min_numpy\n",
        "x,y,z = j_grid+1,i_grid,k_grid\n",
        "p1 = v_grid[x,y,z] + (numpy.stack([x,y,z],axis=-1).astype(numpy.float32)+0.5)*((grid_max_numpy - grid_min_numpy)/point_grid_size) + grid_min_numpy\n",
        "x,y,z = j_grid,i_grid,k_grid+1\n",
        "p2 = v_grid[x,y,z] + (numpy.stack([x,y,z],axis=-1).astype(numpy.float32)+0.5)*((grid_max_numpy - grid_min_numpy)/point_grid_size) + grid_min_numpy\n",
        "x,y,z = j_grid+1,i_grid,k_grid+1\n",
        "p3 = v_grid[x,y,z] + (numpy.stack([x,y,z],axis=-1).astype(numpy.float32)+0.5)*((grid_max_numpy - grid_min_numpy)/point_grid_size) + grid_min_numpy\n",
        "p0123 = numpy.stack([p0,p1,p2,p3],axis=-1) #[M,N,K,3,4]\n",
        "p0123 = p0123 @ quad_weights #[M,N,K,3,quad_size*quad_size]\n",
        "p0123 = numpy.reshape(p0123, [layer_num,layer_num,layer_num,3,quad_size,quad_size]) #[M,N,K,3,quad_size,quad_size]\n",
        "p0123 = numpy.transpose(p0123, (0,1,4,2,5,3)) #[M,N,quad_size,K,quad_size,3]\n",
        "#positions_y = numpy.reshape(numpy.ascontiguousarray(p0123), [layer_num,layer_num*quad_size,layer_num*quad_size,3])\n",
        "positions_y = numpy.reshape(numpy.ascontiguousarray(p0123), [-1,3])\n",
        "\n",
        "p0 = None\n",
        "p1 = None\n",
        "p2 = None\n",
        "p3 = None\n",
        "p0123 = None\n",
        "\n",
        "total_len = len(positions_y)\n",
        "batch_len = total_len//batch_num\n",
        "coarse_feature_y = numpy.zeros([total_len,num_bottleneck_features],numpy.uint8)\n",
        "for i in range(batch_num):\n",
        "  t0 = numpy.reshape(positions_y[i*batch_len:(i+1)*batch_len], [n_device,-1,3])\n",
        "  t0 = get_density_color_p(t0,vars)\n",
        "  coarse_feature_y[i*batch_len:(i+1)*batch_len] = numpy.reshape(t0,[-1,num_bottleneck_features])\n",
        "coarse_feature_y = numpy.reshape(coarse_feature_y,[layer_num,texture_size,texture_size,num_bottleneck_features])\n",
        "coarse_feature_y[:,-quad_size:,:] = 0\n",
        "coarse_feature_y[:,:,-quad_size:] = 0\n",
        "\n",
        "positions_y = None\n",
        "\n",
        "buffer_y = []\n",
        "for i in range(layer_num):\n",
        "  if not numpy.any(coarse_feature_y[i,:,:,0]>0):\n",
        "    buffer_y.append(None)\n",
        "    continue\n",
        "  feats = get_feature_png(coarse_feature_y[i])\n",
        "  buffer_y.append(feats)\n",
        "\n",
        "coarse_feature_y = None\n",
        "\n",
        "\n",
        "step_gpu=step_gpu+1\n",
        "gpu_stats = gpustat.new_query().jsonify() #EDIT\n",
        "gpu_memory_consumption.append({\n",
        "            \"iteration\": step_gpu,\n",
        "            \"gpu_stats\": gpu_stats\n",
        "   })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UklThZb5HUMw",
        "outputId": "edac5483-160c-4b46-e102-6b3b02b16cb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of None values in buffer_z: 18\n",
            "Percentage of None values: 14.06%\n"
          ]
        }
      ],
      "source": [
        "# Count the number of None values in buffer_z\n",
        "none_count = sum(feature is None for feature in buffer_z)\n",
        "\n",
        "# Calculate the percentage\n",
        "percentage_none = (none_count / len(buffer_z)) * 100\n",
        "\n",
        "print(f\"Number of None values in buffer_z: {none_count}\")\n",
        "print(f\"Percentage of None values: {percentage_none:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dE3i3vZg9pFB"
      },
      "outputs": [],
      "source": [
        "write_floatpoint_image(samples_dir+\"/s3_slice_sample.png\",buffer_z[layer_num//2][0]/255.0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-EPOzFl9fCQ",
        "outputId": "1b42b30c-bd95-47e8-f06b-4cdf6ff80320"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of quad faces: 135146\n"
          ]
        }
      ],
      "source": [
        "out_img_size = 1024*20\n",
        "out_img = []\n",
        "for i in range(out_feat_num):\n",
        "  out_img.append(numpy.zeros([out_img_size,out_img_size,4], numpy.uint8))\n",
        "out_cell_num = 0\n",
        "out_cell_size = quad_size+1\n",
        "out_img_h = out_img_size//out_cell_size\n",
        "out_img_w = out_img_size//out_cell_size\n",
        "\n",
        "\n",
        "\n",
        "if scene_type==\"synthetic\":\n",
        "  def inverse_taper_coord_numpy(p):\n",
        "    return p\n",
        "\n",
        "elif scene_type==\"forwardfacing\":\n",
        "  def inverse_taper_coord_numpy(p):\n",
        "    pz = numpy.exp( p[..., 2:3] * \\\n",
        "          (numpy.log(scene_grid_zstart) - numpy.log(scene_grid_zend)) + \\\n",
        "          numpy.log(scene_grid_zend) )\n",
        "    px = p[..., 0:1]*(pz*scene_grid_taper)\n",
        "    py = p[..., 1:2]*(pz*scene_grid_taper)\n",
        "    pz = -pz\n",
        "    return numpy.concatenate([px,py,pz],axis=-1)\n",
        "\n",
        "elif scene_type==\"real360\":\n",
        "  def inverse_taper_coord_numpy(p):\n",
        "    return p\n",
        "\n",
        "\n",
        "\n",
        "def write_patch_to_png(out_img,out_cell_num,out_img_w,j,k,feats):\n",
        "  py = out_cell_num//out_img_w\n",
        "  px = out_cell_num%out_img_w\n",
        "\n",
        "  osy = j*quad_size\n",
        "  oey = j*quad_size+out_cell_size\n",
        "  tsy = py*out_cell_size\n",
        "  tey = py*out_cell_size+out_cell_size\n",
        "  osx = k*quad_size\n",
        "  oex = k*quad_size+out_cell_size\n",
        "  tsx = px*out_cell_size\n",
        "  tex = px*out_cell_size+out_cell_size\n",
        "\n",
        "  for i in range(out_feat_num):\n",
        "    out_img[i][tsy:tey,tsx:tex] = feats[i][osy:oey,osx:oex]\n",
        "\n",
        "def get_png_uv(out_cell_num,out_img_w,out_img_size):\n",
        "  py = out_cell_num//out_img_w\n",
        "  px = out_cell_num%out_img_w\n",
        "\n",
        "  uv0 = numpy.array([py*out_cell_size+0.5,     px*out_cell_size+0.5],numpy.float32)/out_img_size\n",
        "  uv1 = numpy.array([(py+1)*out_cell_size-0.5, px*out_cell_size+0.5],numpy.float32)/out_img_size\n",
        "  uv2 = numpy.array([py*out_cell_size+0.5,     (px+1)*out_cell_size-0.5],numpy.float32)/out_img_size\n",
        "  uv3 = numpy.array([(py+1)*out_cell_size-0.5, (px+1)*out_cell_size-0.5],numpy.float32)/out_img_size\n",
        "\n",
        "  return uv0,uv1,uv2,uv3\n",
        "\n",
        "\n",
        "#for eval\n",
        "point_UV_grid = numpy.zeros([point_grid_size,point_grid_size,point_grid_size,3,4,2], numpy.float32)\n",
        "\n",
        "#mesh vertices\n",
        "bag_of_v = []\n",
        "\n",
        "\n",
        "#synthetic and real360\n",
        "#up is z-\n",
        "#order: z-,x+,y+\n",
        "if scene_type==\"synthetic\" or scene_type==\"real360\":\n",
        "  for k in range(layer_num-1,-1,-1):\n",
        "    for i in range(layer_num):\n",
        "      for j in range(layer_num):\n",
        "\n",
        "        # z plane\n",
        "        if not(k==0 or k==layer_num-1 or i==layer_num-1 or j==layer_num-1):\n",
        "          feats = buffer_z[k]\n",
        "          if feats is not None and numpy.max(feats[0][i*quad_size:(i+1)*quad_size+1,j*quad_size:(j+1)*quad_size+1,2])>0:\n",
        "\n",
        "            write_patch_to_png(out_img,out_cell_num,out_img_w,i,j,feats)\n",
        "            uv0,uv1,uv2,uv3 = get_png_uv(out_cell_num,out_img_w,out_img_size)\n",
        "            out_cell_num += 1\n",
        "\n",
        "            p0 = v_grid[i,j,k] + (numpy.array([i,j,k],numpy.float32)+0.5)*((grid_max_numpy - grid_min_numpy)/point_grid_size) + grid_min_numpy\n",
        "            p1 = v_grid[i+1,j,k] + (numpy.array([i+1,j,k],numpy.float32)+0.5)*((grid_max_numpy - grid_min_numpy)/point_grid_size) + grid_min_numpy\n",
        "            p2 = v_grid[i,j+1,k] + (numpy.array([i,j+1,k],numpy.float32)+0.5)*((grid_max_numpy - grid_min_numpy)/point_grid_size) + grid_min_numpy\n",
        "            p3 = v_grid[i+1,j+1,k] + (numpy.array([i+1,j+1,k],numpy.float32)+0.5)*((grid_max_numpy - grid_min_numpy)/point_grid_size) + grid_min_numpy\n",
        "\n",
        "            p0 = inverse_taper_coord_numpy(p0)\n",
        "            p1 = inverse_taper_coord_numpy(p1)\n",
        "            p2 = inverse_taper_coord_numpy(p2)\n",
        "            p3 = inverse_taper_coord_numpy(p3)\n",
        "\n",
        "            point_UV_grid[i,j,k,2,0] = uv0\n",
        "            point_UV_grid[i,j,k,2,1] = uv1\n",
        "            point_UV_grid[i,j,k,2,2] = uv2\n",
        "            point_UV_grid[i,j,k,2,3] = uv3\n",
        "\n",
        "            bag_of_v.append([p0,p1,p2,p3])\n",
        "\n",
        "        # x plane\n",
        "        if not(i==0 or i==layer_num-1 or j==layer_num-1 or k==layer_num-1):\n",
        "          feats = buffer_x[i]\n",
        "          if feats is not None and numpy.max(feats[0][j*quad_size:(j+1)*quad_size+1,k*quad_size:(k+1)*quad_size+1,2])>0:\n",
        "\n",
        "            write_patch_to_png(out_img,out_cell_num,out_img_w,j,k,feats)\n",
        "            uv0,uv1,uv2,uv3 = get_png_uv(out_cell_num,out_img_w,out_img_size)\n",
        "            out_cell_num += 1\n",
        "\n",
        "            p0 = v_grid[i,j,k] + (numpy.array([i,j,k],numpy.float32)+0.5)*((grid_max_numpy - grid_min_numpy)/point_grid_size) + grid_min_numpy\n",
        "            p1 = v_grid[i,j+1,k] + (numpy.array([i,j+1,k],numpy.float32)+0.5)*((grid_max_numpy - grid_min_numpy)/point_grid_size) + grid_min_numpy\n",
        "            p2 = v_grid[i,j,k+1] + (numpy.array([i,j,k+1],numpy.float32)+0.5)*((grid_max_numpy - grid_min_numpy)/point_grid_size) + grid_min_numpy\n",
        "            p3 = v_grid[i,j+1,k+1] + (numpy.array([i,j+1,k+1],numpy.float32)+0.5)*((grid_max_numpy - grid_min_numpy)/point_grid_size) + grid_min_numpy\n",
        "\n",
        "            p0 = inverse_taper_coord_numpy(p0)\n",
        "            p1 = inverse_taper_coord_numpy(p1)\n",
        "            p2 = inverse_taper_coord_numpy(p2)\n",
        "            p3 = inverse_taper_coord_numpy(p3)\n",
        "\n",
        "            point_UV_grid[i,j,k,0,0] = uv0\n",
        "            point_UV_grid[i,j,k,0,1] = uv1\n",
        "            point_UV_grid[i,j,k,0,2] = uv2\n",
        "            point_UV_grid[i,j,k,0,3] = uv3\n",
        "\n",
        "            bag_of_v.append([p0,p1,p2,p3])\n",
        "\n",
        "        # y plane\n",
        "        if not(j==0 or j==layer_num-1 or i==layer_num-1 or k==layer_num-1):\n",
        "          feats = buffer_y[j]\n",
        "          if feats is not None and numpy.max(feats[0][i*quad_size:(i+1)*quad_size+1,k*quad_size:(k+1)*quad_size+1,2])>0:\n",
        "\n",
        "            write_patch_to_png(out_img,out_cell_num,out_img_w,i,k,feats)\n",
        "            uv0,uv1,uv2,uv3 = get_png_uv(out_cell_num,out_img_w,out_img_size)\n",
        "            out_cell_num += 1\n",
        "\n",
        "            p0 = v_grid[i,j,k] + (numpy.array([i,j,k],numpy.float32)+0.5)*((grid_max_numpy - grid_min_numpy)/point_grid_size) + grid_min_numpy\n",
        "            p1 = v_grid[i+1,j,k] + (numpy.array([i+1,j,k],numpy.float32)+0.5)*((grid_max_numpy - grid_min_numpy)/point_grid_size) + grid_min_numpy\n",
        "            p2 = v_grid[i,j,k+1] + (numpy.array([i,j,k+1],numpy.float32)+0.5)*((grid_max_numpy - grid_min_numpy)/point_grid_size) + grid_min_numpy\n",
        "            p3 = v_grid[i+1,j,k+1] + (numpy.array([i+1,j,k+1],numpy.float32)+0.5)*((grid_max_numpy - grid_min_numpy)/point_grid_size) + grid_min_numpy\n",
        "\n",
        "            p0 = inverse_taper_coord_numpy(p0)\n",
        "            p1 = inverse_taper_coord_numpy(p1)\n",
        "            p2 = inverse_taper_coord_numpy(p2)\n",
        "            p3 = inverse_taper_coord_numpy(p3)\n",
        "\n",
        "            point_UV_grid[i,j,k,1,0] = uv0\n",
        "            point_UV_grid[i,j,k,1,1] = uv1\n",
        "            point_UV_grid[i,j,k,1,2] = uv2\n",
        "            point_UV_grid[i,j,k,1,3] = uv3\n",
        "\n",
        "            bag_of_v.append([p0,p1,p2,p3])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#forwardfacing\n",
        "#front is z-\n",
        "#order: z+,x+,y+\n",
        "elif scene_type==\"forwardfacing\":\n",
        "  for k in range(layer_num):\n",
        "    for i in range(layer_num):\n",
        "      for j in range(layer_num):\n",
        "\n",
        "        # z plane\n",
        "        if not(k==0 or k==layer_num-1 or i==layer_num-1 or j==layer_num-1):\n",
        "          feats = buffer_z[k]\n",
        "          if feats is not None and numpy.max(feats[0][i*quad_size:(i+1)*quad_size+1,j*quad_size:(j+1)*quad_size+1,2])>0:\n",
        "\n",
        "            write_patch_to_png(out_img,out_cell_num,out_img_w,i,j,feats)\n",
        "            uv0,uv1,uv2,uv3 = get_png_uv(out_cell_num,out_img_w,out_img_size)\n",
        "            out_cell_num += 1\n",
        "\n",
        "            p0 = v_grid[i,j,k] + (numpy.array([i,j,k],numpy.float32)+0.5)*((grid_max_numpy - grid_min_numpy)/point_grid_size) + grid_min_numpy\n",
        "            p1 = v_grid[i+1,j,k] + (numpy.array([i+1,j,k],numpy.float32)+0.5)*((grid_max_numpy - grid_min_numpy)/point_grid_size) + grid_min_numpy\n",
        "            p2 = v_grid[i,j+1,k] + (numpy.array([i,j+1,k],numpy.float32)+0.5)*((grid_max_numpy - grid_min_numpy)/point_grid_size) + grid_min_numpy\n",
        "            p3 = v_grid[i+1,j+1,k] + (numpy.array([i+1,j+1,k],numpy.float32)+0.5)*((grid_max_numpy - grid_min_numpy)/point_grid_size) + grid_min_numpy\n",
        "\n",
        "            p0 = inverse_taper_coord_numpy(p0)\n",
        "            p1 = inverse_taper_coord_numpy(p1)\n",
        "            p2 = inverse_taper_coord_numpy(p2)\n",
        "            p3 = inverse_taper_coord_numpy(p3)\n",
        "\n",
        "            point_UV_grid[i,j,k,2,0] = uv0\n",
        "            point_UV_grid[i,j,k,2,1] = uv1\n",
        "            point_UV_grid[i,j,k,2,2] = uv2\n",
        "            point_UV_grid[i,j,k,2,3] = uv3\n",
        "\n",
        "            bag_of_v.append([p0,p1,p2,p3])\n",
        "\n",
        "        # x plane\n",
        "        if not(i==0 or i==layer_num-1 or j==layer_num-1 or k==layer_num-1):\n",
        "          feats = buffer_x[i]\n",
        "          if feats is not None and numpy.max(feats[0][j*quad_size:(j+1)*quad_size+1,k*quad_size:(k+1)*quad_size+1,2])>0:\n",
        "\n",
        "            write_patch_to_png(out_img,out_cell_num,out_img_w,j,k,feats)\n",
        "            uv0,uv1,uv2,uv3 = get_png_uv(out_cell_num,out_img_w,out_img_size)\n",
        "            out_cell_num += 1\n",
        "\n",
        "            p0 = v_grid[i,j,k] + (numpy.array([i,j,k],numpy.float32)+0.5)*((grid_max_numpy - grid_min_numpy)/point_grid_size) + grid_min_numpy\n",
        "            p1 = v_grid[i,j+1,k] + (numpy.array([i,j+1,k],numpy.float32)+0.5)*((grid_max_numpy - grid_min_numpy)/point_grid_size) + grid_min_numpy\n",
        "            p2 = v_grid[i,j,k+1] + (numpy.array([i,j,k+1],numpy.float32)+0.5)*((grid_max_numpy - grid_min_numpy)/point_grid_size) + grid_min_numpy\n",
        "            p3 = v_grid[i,j+1,k+1] + (numpy.array([i,j+1,k+1],numpy.float32)+0.5)*((grid_max_numpy - grid_min_numpy)/point_grid_size) + grid_min_numpy\n",
        "\n",
        "            p0 = inverse_taper_coord_numpy(p0)\n",
        "            p1 = inverse_taper_coord_numpy(p1)\n",
        "            p2 = inverse_taper_coord_numpy(p2)\n",
        "            p3 = inverse_taper_coord_numpy(p3)\n",
        "\n",
        "            point_UV_grid[i,j,k,0,0] = uv0\n",
        "            point_UV_grid[i,j,k,0,1] = uv1\n",
        "            point_UV_grid[i,j,k,0,2] = uv2\n",
        "            point_UV_grid[i,j,k,0,3] = uv3\n",
        "\n",
        "            bag_of_v.append([p0,p1,p2,p3])\n",
        "\n",
        "        # y plane\n",
        "        if not(j==0 or j==layer_num-1 or i==layer_num-1 or k==layer_num-1):\n",
        "          feats = buffer_y[j]\n",
        "          if feats is not None and numpy.max(feats[0][i*quad_size:(i+1)*quad_size+1,k*quad_size:(k+1)*quad_size+1,2])>0:\n",
        "\n",
        "            write_patch_to_png(out_img,out_cell_num,out_img_w,i,k,feats)\n",
        "            uv0,uv1,uv2,uv3 = get_png_uv(out_cell_num,out_img_w,out_img_size)\n",
        "            out_cell_num += 1\n",
        "\n",
        "            p0 = v_grid[i,j,k] + (numpy.array([i,j,k],numpy.float32)+0.5)*((grid_max_numpy - grid_min_numpy)/point_grid_size) + grid_min_numpy\n",
        "            p1 = v_grid[i+1,j,k] + (numpy.array([i+1,j,k],numpy.float32)+0.5)*((grid_max_numpy - grid_min_numpy)/point_grid_size) + grid_min_numpy\n",
        "            p2 = v_grid[i,j,k+1] + (numpy.array([i,j,k+1],numpy.float32)+0.5)*((grid_max_numpy - grid_min_numpy)/point_grid_size) + grid_min_numpy\n",
        "            p3 = v_grid[i+1,j,k+1] + (numpy.array([i+1,j,k+1],numpy.float32)+0.5)*((grid_max_numpy - grid_min_numpy)/point_grid_size) + grid_min_numpy\n",
        "\n",
        "            p0 = inverse_taper_coord_numpy(p0)\n",
        "            p1 = inverse_taper_coord_numpy(p1)\n",
        "            p2 = inverse_taper_coord_numpy(p2)\n",
        "            p3 = inverse_taper_coord_numpy(p3)\n",
        "\n",
        "            point_UV_grid[i,j,k,1,0] = uv0\n",
        "            point_UV_grid[i,j,k,1,1] = uv1\n",
        "            point_UV_grid[i,j,k,1,2] = uv2\n",
        "            point_UV_grid[i,j,k,1,3] = uv3\n",
        "\n",
        "            bag_of_v.append([p0,p1,p2,p3])\n",
        "\n",
        "\n",
        "\n",
        "print(\"Number of quad faces:\", out_cell_num)\n",
        "\n",
        "step_gpu=step_gpu+1\n",
        "gpu_stats = gpustat.new_query().jsonify() #EDIT\n",
        "gpu_memory_consumption.append({\n",
        "            \"iteration\": step_gpu,\n",
        "            \"gpu_stats\": gpu_stats\n",
        "   })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7zE5pFispYm",
        "outputId": "5668ef4f-6bed-42e3-cccd-2be53230baae"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing invisible triangles\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [1:02:35<00:00, 37.56s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing invisible triangles\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [3:08:24<00:00, 37.68s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of quad faces: 85279\n"
          ]
        }
      ],
      "source": [
        "buffer_x = None\n",
        "buffer_y = None\n",
        "buffer_z = None\n",
        "#%% --------------------------------------------------------------------------------\n",
        "# ## Main rendering functions\n",
        "#%%\n",
        "\n",
        "#compute ray-gridcell intersections\n",
        "\n",
        "if scene_type==\"synthetic\":\n",
        "\n",
        "  def gridcell_from_rays(rays):\n",
        "    ray_origins = rays[0]\n",
        "    ray_directions = rays[1]\n",
        "\n",
        "    dtype = ray_origins.dtype\n",
        "    batch_shape = ray_origins.shape[:-1]\n",
        "    small_step = 1e-5\n",
        "    epsilon = 1e-5\n",
        "\n",
        "    ox = ray_origins[..., 0:1]\n",
        "    oy = ray_origins[..., 1:2]\n",
        "    oz = ray_origins[..., 2:3]\n",
        "\n",
        "    dx = ray_directions[..., 0:1]\n",
        "    dy = ray_directions[..., 1:2]\n",
        "    dz = ray_directions[..., 2:3]\n",
        "\n",
        "    dxm = (np.abs(dx)<epsilon).astype(dtype)\n",
        "    dym = (np.abs(dy)<epsilon).astype(dtype)\n",
        "    dzm = (np.abs(dz)<epsilon).astype(dtype)\n",
        "\n",
        "    #avoid zero div\n",
        "    dx = dx+dxm\n",
        "    dy = dy+dym\n",
        "    dz = dz+dzm\n",
        "\n",
        "    layers = np.arange(point_grid_size+1,dtype=dtype)/point_grid_size #[0,1]\n",
        "    layers = np.reshape(layers, [1]*len(batch_shape)+[point_grid_size+1])\n",
        "    layers = np.broadcast_to(layers, list(batch_shape)+[point_grid_size+1])\n",
        "\n",
        "    tx = ((layers*(grid_max[0]-grid_min[0])+grid_min[0])-ox)/dx\n",
        "    ty = ((layers*(grid_max[1]-grid_min[1])+grid_min[1])-oy)/dy\n",
        "    tz = ((layers*(grid_max[2]-grid_min[2])+grid_min[2])-oz)/dz\n",
        "\n",
        "    tx = tx*(1-dxm) + 1000*dxm\n",
        "    ty = ty*(1-dym) + 1000*dym\n",
        "    tz = tz*(1-dzm) + 1000*dzm\n",
        "\n",
        "    txyz = np.concatenate([tx, ty, tz], axis=-1)\n",
        "    txyzm = (txyz<=0).astype(dtype)\n",
        "    txyz = txyz*(1-txyzm) + 1000*txyzm\n",
        "\n",
        "\n",
        "    # not using acc_grid\n",
        "    txyz = txyz + small_step\n",
        "\n",
        "\n",
        "    world_positions = ray_origins[..., None, :] + \\\n",
        "                      ray_directions[..., None, :] * txyz[..., None]\n",
        "\n",
        "\n",
        "    grid_positions = (world_positions - grid_min) * \\\n",
        "                      (point_grid_size / (grid_max - grid_min) )\n",
        "\n",
        "    grid_masks = (grid_positions[..., 0]>=1) & (grid_positions[..., 0]<point_grid_size-1) \\\n",
        "                & (grid_positions[..., 1]>=1) & (grid_positions[..., 1]<point_grid_size-1) \\\n",
        "                & (grid_positions[..., 2]>=1) & (grid_positions[..., 2]<point_grid_size-1)\n",
        "\n",
        "    grid_positions = grid_positions*grid_masks[..., None] \\\n",
        "              + np.logical_not(grid_masks[..., None]) #min=1,max=point_grid_size-2\n",
        "    grid_indices = grid_positions.astype(np.int32)\n",
        "\n",
        "    return grid_indices, grid_masks\n",
        "\n",
        "elif scene_type==\"forwardfacing\":\n",
        "\n",
        "  def gridcell_from_rays(rays):\n",
        "    ray_origins = rays[0]\n",
        "    ray_directions = rays[1]\n",
        "\n",
        "    dtype = ray_origins.dtype\n",
        "    batch_shape = ray_origins.shape[:-1]\n",
        "    small_step = 1e-5\n",
        "    epsilon = 1e-10\n",
        "\n",
        "    ox = ray_origins[..., 0:1]\n",
        "    oy = ray_origins[..., 1:2]\n",
        "    oz = ray_origins[..., 2:3]\n",
        "\n",
        "    dx = ray_directions[..., 0:1]\n",
        "    dy = ray_directions[..., 1:2]\n",
        "    dz = ray_directions[..., 2:3]\n",
        "\n",
        "\n",
        "    layers = np.arange(point_grid_size+1,dtype=dtype)/point_grid_size #[0,1]\n",
        "    layers = np.reshape(layers, [1]*len(batch_shape)+[point_grid_size+1])\n",
        "    layers = np.broadcast_to(layers, list(batch_shape)+[point_grid_size+1])\n",
        "\n",
        "\n",
        "    #z planes\n",
        "    #z = Zlayers\n",
        "    #dz*t + oz = Zlayers\n",
        "    Zlayers = -np.exp( layers * \\\n",
        "          (np.log(scene_grid_zstart) - np.log(scene_grid_zend)) + \\\n",
        "          np.log(scene_grid_zend) )\n",
        "    dzm = (np.abs(dz)<epsilon).astype(dtype)\n",
        "    dz = dz+dzm\n",
        "    tz = (Zlayers-oz)/dz\n",
        "    tz = tz*(1-dzm) + 1000*dzm\n",
        "\n",
        "    #x planes\n",
        "    #x/z = Xlayers*scene_grid_taper = Xlayers_\n",
        "    #(dx*t + ox)/(dz*t + oz) = Xlayers_\n",
        "    #t = (oz*Xlayers_ - ox)/(dx - Xlayers_*dz)\n",
        "    Xlayers_ = (layers*(grid_max[0]-grid_min[0])+grid_min[0])*scene_grid_taper\n",
        "    dxx = dx - Xlayers_*dz\n",
        "    dxm = (np.abs(dxx)<epsilon).astype(dtype)\n",
        "    dxx = dxx+dxm\n",
        "    tx = (oz*Xlayers_ - ox)/dxx\n",
        "    tx = tx*(1-dxm) + 1000*dxm\n",
        "\n",
        "    #y planes\n",
        "    Ylayers_ = (layers*(grid_max[1]-grid_min[1])+grid_min[1])*scene_grid_taper\n",
        "    dyy = dy - Ylayers_*dz\n",
        "    dym = (np.abs(dyy)<epsilon).astype(dtype)\n",
        "    dyy = dyy+dym\n",
        "    ty = (oz*Ylayers_ - oy)/dyy\n",
        "    ty = ty*(1-dym) + 1000*dym\n",
        "\n",
        "\n",
        "    txyz = np.concatenate([tx, ty, tz], axis=-1)\n",
        "    txyzm = (txyz<=0).astype(dtype)\n",
        "    txyz = txyz*(1-txyzm) + 1000*txyzm\n",
        "\n",
        "\n",
        "    #not using acc_grid\n",
        "    txyz = txyz + small_step\n",
        "\n",
        "\n",
        "    world_positions = ray_origins[..., None, :] + \\\n",
        "                      ray_directions[..., None, :] * txyz[..., None]\n",
        "    taper_positions = get_taper_coord(world_positions)\n",
        "\n",
        "\n",
        "    grid_positions = (taper_positions - grid_min) * \\\n",
        "                      (point_grid_size / (grid_max - grid_min) )\n",
        "\n",
        "    grid_masks = (grid_positions[..., 0]>=1) & (grid_positions[..., 0]<point_grid_size-1) \\\n",
        "                & (grid_positions[..., 1]>=1) & (grid_positions[..., 1]<point_grid_size-1) \\\n",
        "                & (grid_positions[..., 2]>=1) & (grid_positions[..., 2]<point_grid_size-1)\n",
        "\n",
        "    grid_positions = grid_positions*grid_masks[..., None] \\\n",
        "              + np.logical_not(grid_masks[..., None]) #min=1,max=point_grid_size-2\n",
        "    grid_indices = grid_positions.astype(np.int32)\n",
        "\n",
        "    return grid_indices, grid_masks\n",
        "\n",
        "elif scene_type==\"real360\":\n",
        "\n",
        "  def gridcell_from_rays(rays):\n",
        "    ray_origins = rays[0]\n",
        "    ray_directions = rays[1]\n",
        "\n",
        "    dtype = ray_origins.dtype\n",
        "    batch_shape = ray_origins.shape[:-1]\n",
        "    small_step = 1e-5\n",
        "    epsilon = 1e-5\n",
        "\n",
        "    ox = ray_origins[..., 0:1]\n",
        "    oy = ray_origins[..., 1:2]\n",
        "    oz = ray_origins[..., 2:3]\n",
        "\n",
        "    dx = ray_directions[..., 0:1]\n",
        "    dy = ray_directions[..., 1:2]\n",
        "    dz = ray_directions[..., 2:3]\n",
        "\n",
        "    dxm = (np.abs(dx)<epsilon).astype(dtype)\n",
        "    dym = (np.abs(dy)<epsilon).astype(dtype)\n",
        "    dzm = (np.abs(dz)<epsilon).astype(dtype)\n",
        "\n",
        "    #avoid zero div\n",
        "    dx = dx+dxm\n",
        "    dy = dy+dym\n",
        "    dz = dz+dzm\n",
        "\n",
        "    layers = np.arange(point_grid_size+1,dtype=dtype)/point_grid_size #[0,1]\n",
        "    layers = np.reshape(layers, [1]*len(batch_shape)+[point_grid_size+1])\n",
        "    layers = np.broadcast_to(layers, list(batch_shape)+[point_grid_size+1])\n",
        "\n",
        "    tx = ((layers*(grid_max[0]-grid_min[0])+grid_min[0])-ox)/dx\n",
        "    ty = ((layers*(grid_max[1]-grid_min[1])+grid_min[1])-oy)/dy\n",
        "    tz = ((layers*(grid_max[2]-grid_min[2])+grid_min[2])-oz)/dz\n",
        "\n",
        "    tx = tx*(1-dxm) + 1000*dxm\n",
        "    ty = ty*(1-dym) + 1000*dym\n",
        "    tz = tz*(1-dzm) + 1000*dzm\n",
        "\n",
        "    txyz = np.concatenate([tx, ty, tz], axis=-1)\n",
        "    txyzm = (txyz<=0.2).astype(dtype)\n",
        "    txyz = txyz*(1-txyzm) + 1000*txyzm\n",
        "\n",
        "\n",
        "    # not using acc_grid\n",
        "    txyz = txyz + small_step\n",
        "\n",
        "\n",
        "    world_positions = ray_origins[..., None, :] + \\\n",
        "                      ray_directions[..., None, :] * txyz[..., None]\n",
        "\n",
        "\n",
        "    grid_positions = (world_positions - grid_min) * \\\n",
        "                      (point_grid_size / (grid_max - grid_min) )\n",
        "\n",
        "    grid_masks = (grid_positions[..., 0]>=1) & (grid_positions[..., 0]<point_grid_size-1) \\\n",
        "                & (grid_positions[..., 1]>=1) & (grid_positions[..., 1]<point_grid_size-1) \\\n",
        "                & (grid_positions[..., 2]>=1) & (grid_positions[..., 2]<point_grid_size-1)\n",
        "\n",
        "    grid_positions = grid_positions*grid_masks[..., None] \\\n",
        "              + np.logical_not(grid_masks[..., None]) #min=1,max=point_grid_size-2\n",
        "    grid_indices = grid_positions.astype(np.int32)\n",
        "\n",
        "    return grid_indices, grid_masks\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#get barycentric coordinates\n",
        "#P = (p1-p3) * a + (p2-p3) * b + p3\n",
        "#P = d * t + o\n",
        "def get_barycentric(p1,p2,p3,O,d):\n",
        "  epsilon = 1e-10\n",
        "\n",
        "  r1x = p1[..., 0]-p3[..., 0]\n",
        "  r1y = p1[..., 1]-p3[..., 1]\n",
        "  r1z = p1[..., 2]-p3[..., 2]\n",
        "\n",
        "  r2x = p2[..., 0]-p3[..., 0]\n",
        "  r2y = p2[..., 1]-p3[..., 1]\n",
        "  r2z = p2[..., 2]-p3[..., 2]\n",
        "\n",
        "  p3x = p3[..., 0]\n",
        "  p3y = p3[..., 1]\n",
        "  p3z = p3[..., 2]\n",
        "\n",
        "  Ox = O[..., 0]\n",
        "  Oy = O[..., 1]\n",
        "  Oz = O[..., 2]\n",
        "\n",
        "  dx = d[..., 0]\n",
        "  dy = d[..., 1]\n",
        "  dz = d[..., 2]\n",
        "\n",
        "  denominator = - dx*r1y*r2z \\\n",
        "                + dx*r1z*r2y \\\n",
        "                + dy*r1x*r2z \\\n",
        "                - dy*r1z*r2x \\\n",
        "                - dz*r1x*r2y \\\n",
        "                + dz*r1y*r2x\n",
        "\n",
        "  denominator_mask = (np.abs(denominator)<epsilon)\n",
        "  #avoid zero div\n",
        "  denominator = denominator+denominator_mask\n",
        "\n",
        "  a_numerator =   (Ox-p3x)*dy*r2z \\\n",
        "                + (p3x-Ox)*dz*r2y \\\n",
        "                + (p3y-Oy)*dx*r2z \\\n",
        "                + (Oy-p3y)*dz*r2x \\\n",
        "                + (Oz-p3z)*dx*r2y \\\n",
        "                + (p3z-Oz)*dy*r2x\n",
        "\n",
        "  b_numerator =   (p3x-Ox)*dy*r1z \\\n",
        "                + (Ox-p3x)*dz*r1y \\\n",
        "                + (Oy-p3y)*dx*r1z \\\n",
        "                + (p3y-Oy)*dz*r1x \\\n",
        "                + (p3z-Oz)*dx*r1y \\\n",
        "                + (Oz-p3z)*dy*r1x \\\n",
        "\n",
        "  a = a_numerator/denominator\n",
        "  b = b_numerator/denominator\n",
        "  c = 1-(a+b)\n",
        "\n",
        "  mask = (a>=0) & (b>=0) & (c>=0) & np.logical_not(denominator_mask)\n",
        "  return a,b,c,mask\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "cell_size_x = (grid_max[0] - grid_min[0])/point_grid_size\n",
        "half_cell_size_x = cell_size_x/2\n",
        "neg_half_cell_size_x = -half_cell_size_x\n",
        "cell_size_y = (grid_max[1] - grid_min[1])/point_grid_size\n",
        "half_cell_size_y = cell_size_y/2\n",
        "neg_half_cell_size_y = -half_cell_size_y\n",
        "cell_size_z = (grid_max[2] - grid_min[2])/point_grid_size\n",
        "half_cell_size_z = cell_size_z/2\n",
        "neg_half_cell_size_z = -half_cell_size_z\n",
        "\n",
        "def get_inside_cell_mask(P,ooxyz):\n",
        "  P_ = get_taper_coord(P) - ooxyz\n",
        "  return (P_[..., 0]>=neg_half_cell_size_x) \\\n",
        "          & (P_[..., 0]<half_cell_size_x) \\\n",
        "          & (P_[..., 1]>=neg_half_cell_size_y) \\\n",
        "          & (P_[..., 1]<half_cell_size_y) \\\n",
        "          & (P_[..., 2]>=neg_half_cell_size_z) \\\n",
        "          & (P_[..., 2]<half_cell_size_z)\n",
        "\n",
        "\n",
        "\n",
        "#compute ray-undc intersections\n",
        "#point_grid [N,N,N,3]\n",
        "#point_UV_grid [N,N,N,3,4,2]\n",
        "#texture_alpha [M,M,1]\n",
        "def compute_undc_intersection_and_return_uv(\n",
        "              point_grid, point_UV_grid, texture_alpha, cell_xyz, masks, rays):\n",
        "  ray_origins = rays[0]\n",
        "  ray_directions = rays[1]\n",
        "\n",
        "  dtype = ray_origins.dtype\n",
        "  batch_shape = ray_origins.shape[:-1]\n",
        "\n",
        "  ooxyz = (cell_xyz.astype(dtype)+0.5)*((grid_max - grid_min)/point_grid_size) + grid_min\n",
        "\n",
        "  cell_x = cell_xyz[..., 0]\n",
        "  cell_y = cell_xyz[..., 1]\n",
        "  cell_z = cell_xyz[..., 2]\n",
        "  cell_x1 = cell_x+1\n",
        "  cell_y1 = cell_y+1\n",
        "  cell_z1 = cell_z+1\n",
        "  cell_x0 = cell_x-1\n",
        "  cell_y0 = cell_y-1\n",
        "  cell_z0 = cell_z-1\n",
        "\n",
        "  #origin\n",
        "  ooo_ = point_grid[cell_x,cell_y,cell_z]*point_grid_diff_lr_scale\n",
        "  ooo = inverse_taper_coord(ooo_ +ooxyz)\n",
        "\n",
        "  #x:\n",
        "  obb = inverse_taper_coord(point_grid[cell_x,cell_y0,cell_z0]*point_grid_diff_lr_scale + np.array([0,-cell_size_y,-cell_size_z], dtype) +ooxyz)\n",
        "  obd = inverse_taper_coord(point_grid[cell_x,cell_y0,cell_z1]*point_grid_diff_lr_scale + np.array([0,-cell_size_y,cell_size_z], dtype) +ooxyz)\n",
        "  odb = inverse_taper_coord(point_grid[cell_x,cell_y1,cell_z0]*point_grid_diff_lr_scale + np.array([0,cell_size_y,-cell_size_z], dtype) +ooxyz)\n",
        "  odd = inverse_taper_coord(point_grid[cell_x,cell_y1,cell_z1]*point_grid_diff_lr_scale + np.array([0,cell_size_y,cell_size_z], dtype) +ooxyz)\n",
        "  obo = inverse_taper_coord(point_grid[cell_x,cell_y0,cell_z]*point_grid_diff_lr_scale + np.array([0,-cell_size_y,0], dtype) +ooxyz)\n",
        "  oob = inverse_taper_coord(point_grid[cell_x,cell_y,cell_z0]*point_grid_diff_lr_scale + np.array([0,0,-cell_size_z], dtype) +ooxyz)\n",
        "  odo = inverse_taper_coord(point_grid[cell_x,cell_y1,cell_z]*point_grid_diff_lr_scale + np.array([0,cell_size_y,0], dtype) +ooxyz)\n",
        "  ood = inverse_taper_coord(point_grid[cell_x,cell_y,cell_z1]*point_grid_diff_lr_scale + np.array([0,0,cell_size_z], dtype) +ooxyz)\n",
        "\n",
        "  #y:\n",
        "  bob = inverse_taper_coord(point_grid[cell_x0,cell_y,cell_z0]*point_grid_diff_lr_scale + np.array([-cell_size_x,0,-cell_size_z], dtype) +ooxyz)\n",
        "  bod = inverse_taper_coord(point_grid[cell_x0,cell_y,cell_z1]*point_grid_diff_lr_scale + np.array([-cell_size_x,0,cell_size_z], dtype) +ooxyz)\n",
        "  dob = inverse_taper_coord(point_grid[cell_x1,cell_y,cell_z0]*point_grid_diff_lr_scale + np.array([cell_size_x,0,-cell_size_z], dtype) +ooxyz)\n",
        "  dod = inverse_taper_coord(point_grid[cell_x1,cell_y,cell_z1]*point_grid_diff_lr_scale + np.array([cell_size_x,0,cell_size_z], dtype) +ooxyz)\n",
        "  boo = inverse_taper_coord(point_grid[cell_x0,cell_y,cell_z]*point_grid_diff_lr_scale + np.array([-cell_size_x,0,0], dtype) +ooxyz)\n",
        "  doo = inverse_taper_coord(point_grid[cell_x1,cell_y,cell_z]*point_grid_diff_lr_scale + np.array([cell_size_x,0,0], dtype) +ooxyz)\n",
        "\n",
        "  #z:\n",
        "  bbo = inverse_taper_coord(point_grid[cell_x0,cell_y0,cell_z]*point_grid_diff_lr_scale + np.array([-cell_size_x,-cell_size_y,0], dtype) +ooxyz)\n",
        "  bdo = inverse_taper_coord(point_grid[cell_x0,cell_y1,cell_z]*point_grid_diff_lr_scale + np.array([-cell_size_x,cell_size_y,0], dtype) +ooxyz)\n",
        "  dbo = inverse_taper_coord(point_grid[cell_x1,cell_y0,cell_z]*point_grid_diff_lr_scale + np.array([cell_size_x,-cell_size_y,0], dtype) +ooxyz)\n",
        "  ddo = inverse_taper_coord(point_grid[cell_x1,cell_y1,cell_z]*point_grid_diff_lr_scale + np.array([cell_size_x,cell_size_y,0], dtype) +ooxyz)\n",
        "\n",
        "  #ray origin, direction\n",
        "  o = ray_origins[..., None,:]\n",
        "  d = ray_directions[..., None,:]\n",
        "\n",
        "  # ------x:\n",
        "\n",
        "  # P[x,y-1,z-1]  P[x,y-1,z]    P[x,y,z]\n",
        "  p1 = obb\n",
        "  p2 = obo\n",
        "  p3 = ooo\n",
        "  a,b,c,mask = get_barycentric(p1,p2,p3,o,d)\n",
        "  P_ = p1*a[...,None] + p2*b[...,None] + p3*c[...,None]\n",
        "  P_x_1m = get_inside_cell_mask(P_,ooxyz) & mask & masks\n",
        "  P_x_1 = P_\n",
        "  #uv\n",
        "  p1_uv = point_UV_grid[cell_x,cell_y0,cell_z0,0,0]\n",
        "  p2_uv = point_UV_grid[cell_x,cell_y0,cell_z0,0,2]\n",
        "  p3_uv = point_UV_grid[cell_x,cell_y0,cell_z0,0,3]\n",
        "  P_uv = p1_uv*a[...,None] + p2_uv*b[...,None] + p3_uv*c[...,None]\n",
        "  P_uv = np.clip( (P_uv*out_img_size).astype(np.int32), 0, out_img_size-1)\n",
        "  P_x_1c = texture_alpha[P_uv[...,0],P_uv[...,1]]\n",
        "  P_x_1uv = P_uv\n",
        "  #uv end\n",
        "\n",
        "  # P[x,y-1,z-1]  P[x,y,z-1]    P[x,y,z]\n",
        "  p1 = obb\n",
        "  p2 = oob\n",
        "  p3 = ooo\n",
        "  a,b,c,mask = get_barycentric(p1,p2,p3,o,d)\n",
        "  P_ = p1*a[...,None] + p2*b[...,None] + p3*c[...,None]\n",
        "  P_x_2m = get_inside_cell_mask(P_,ooxyz) & mask & masks\n",
        "  P_x_2 = P_\n",
        "  #uv\n",
        "  p1_uv = point_UV_grid[cell_x,cell_y0,cell_z0,0,0]\n",
        "  p2_uv = point_UV_grid[cell_x,cell_y0,cell_z0,0,1]\n",
        "  p3_uv = point_UV_grid[cell_x,cell_y0,cell_z0,0,3]\n",
        "  P_uv = p1_uv*a[...,None] + p2_uv*b[...,None] + p3_uv*c[...,None]\n",
        "  P_uv = np.clip( (P_uv*out_img_size).astype(np.int32), 0, out_img_size-1)\n",
        "  P_x_2c = texture_alpha[P_uv[...,0],P_uv[...,1]]\n",
        "  P_x_2uv = P_uv\n",
        "  #uv end\n",
        "\n",
        "  # P[x,y+1,z+1]  P[x,y+1,z]    P[x,y,z]\n",
        "  p1 = odd\n",
        "  p2 = odo\n",
        "  p3 = ooo\n",
        "  a,b,c,mask = get_barycentric(p1,p2,p3,o,d)\n",
        "  P_ = p1*a[...,None] + p2*b[...,None] + p3*c[...,None]\n",
        "  P_x_3m = get_inside_cell_mask(P_,ooxyz) & mask & masks\n",
        "  P_x_3 = P_\n",
        "  #uv\n",
        "  p1_uv = point_UV_grid[cell_x,cell_y,cell_z,0,3]\n",
        "  p2_uv = point_UV_grid[cell_x,cell_y,cell_z,0,1]\n",
        "  p3_uv = point_UV_grid[cell_x,cell_y,cell_z,0,0]\n",
        "  P_uv = p1_uv*a[...,None] + p2_uv*b[...,None] + p3_uv*c[...,None]\n",
        "  P_uv = np.clip( (P_uv*out_img_size).astype(np.int32), 0, out_img_size-1)\n",
        "  P_x_3c = texture_alpha[P_uv[...,0],P_uv[...,1]]\n",
        "  P_x_3uv = P_uv\n",
        "  #uv end\n",
        "\n",
        "  # P[x,y+1,z+1]  P[x,y,z+1]    P[x,y,z]\n",
        "  p1 = odd\n",
        "  p2 = ood\n",
        "  p3 = ooo\n",
        "  a,b,c,mask = get_barycentric(p1,p2,p3,o,d)\n",
        "  P_ = p1*a[...,None] + p2*b[...,None] + p3*c[...,None]\n",
        "  P_x_4m = get_inside_cell_mask(P_,ooxyz) & mask & masks\n",
        "  P_x_4 = P_\n",
        "  #uv\n",
        "  p1_uv = point_UV_grid[cell_x,cell_y,cell_z,0,3]\n",
        "  p2_uv = point_UV_grid[cell_x,cell_y,cell_z,0,2]\n",
        "  p3_uv = point_UV_grid[cell_x,cell_y,cell_z,0,0]\n",
        "  P_uv = p1_uv*a[...,None] + p2_uv*b[...,None] + p3_uv*c[...,None]\n",
        "  P_uv = np.clip( (P_uv*out_img_size).astype(np.int32), 0, out_img_size-1)\n",
        "  P_x_4c = texture_alpha[P_uv[...,0],P_uv[...,1]]\n",
        "  P_x_4uv = P_uv\n",
        "  #uv end\n",
        "\n",
        "  # P[x,y,z-1]    P[x,y+1,z]    P[x,y,z]\n",
        "  p1 = oob\n",
        "  p2 = odo\n",
        "  p3 = ooo\n",
        "  a,b,c,mask = get_barycentric(p1,p2,p3,o,d)\n",
        "  P_ = p1*a[...,None] + p2*b[...,None] + p3*c[...,None]\n",
        "  P_x_5m = get_inside_cell_mask(P_,ooxyz) & mask & masks\n",
        "  P_x_5 = P_\n",
        "  #uv\n",
        "  p1_uv = point_UV_grid[cell_x,cell_y,cell_z0,0,0]\n",
        "  p2_uv = point_UV_grid[cell_x,cell_y,cell_z0,0,3]\n",
        "  p3_uv = point_UV_grid[cell_x,cell_y,cell_z0,0,2]\n",
        "  P_uv = p1_uv*a[...,None] + p2_uv*b[...,None] + p3_uv*c[...,None]\n",
        "  P_uv = np.clip( (P_uv*out_img_size).astype(np.int32), 0, out_img_size-1)\n",
        "  P_x_5c = texture_alpha[P_uv[...,0],P_uv[...,1]]\n",
        "  P_x_5uv = P_uv\n",
        "  #uv end\n",
        "\n",
        "  # P[x,y,z-1]    P[x,y+1,z]    P[x,y+1,z-1]\n",
        "  p1 = oob\n",
        "  p2 = odo\n",
        "  p3 = odb\n",
        "  a,b,c,mask = get_barycentric(p1,p2,p3,o,d)\n",
        "  P_ = p1*a[...,None] + p2*b[...,None] + p3*c[...,None]\n",
        "  P_x_6m = get_inside_cell_mask(P_,ooxyz) & mask & masks\n",
        "  P_x_6 = P_\n",
        "  #uv\n",
        "  p1_uv = point_UV_grid[cell_x,cell_y,cell_z0,0,0]\n",
        "  p2_uv = point_UV_grid[cell_x,cell_y,cell_z0,0,3]\n",
        "  p3_uv = point_UV_grid[cell_x,cell_y,cell_z0,0,1]\n",
        "  P_uv = p1_uv*a[...,None] + p2_uv*b[...,None] + p3_uv*c[...,None]\n",
        "  P_uv = np.clip( (P_uv*out_img_size).astype(np.int32), 0, out_img_size-1)\n",
        "  P_x_6c = texture_alpha[P_uv[...,0],P_uv[...,1]]\n",
        "  P_x_6uv = P_uv\n",
        "  #uv end\n",
        "\n",
        "  # P[x,y-1,z]    P[x,y,z+1]    P[x,y,z]\n",
        "  p1 = obo\n",
        "  p2 = ood\n",
        "  p3 = ooo\n",
        "  a,b,c,mask = get_barycentric(p1,p2,p3,o,d)\n",
        "  P_ = p1*a[...,None] + p2*b[...,None] + p3*c[...,None]\n",
        "  P_x_7m = get_inside_cell_mask(P_,ooxyz) & mask & masks\n",
        "  P_x_7 = P_\n",
        "  #uv\n",
        "  p1_uv = point_UV_grid[cell_x,cell_y0,cell_z,0,0]\n",
        "  p2_uv = point_UV_grid[cell_x,cell_y0,cell_z,0,3]\n",
        "  p3_uv = point_UV_grid[cell_x,cell_y0,cell_z,0,1]\n",
        "  P_uv = p1_uv*a[...,None] + p2_uv*b[...,None] + p3_uv*c[...,None]\n",
        "  P_uv = np.clip( (P_uv*out_img_size).astype(np.int32), 0, out_img_size-1)\n",
        "  P_x_7c = texture_alpha[P_uv[...,0],P_uv[...,1]]\n",
        "  P_x_7uv = P_uv\n",
        "  #uv end\n",
        "\n",
        "  # P[x,y-1,z]    P[x,y,z+1]    P[x,y-1,z+1]\n",
        "  p1 = obo\n",
        "  p2 = ood\n",
        "  p3 = obd\n",
        "  a,b,c,mask = get_barycentric(p1,p2,p3,o,d)\n",
        "  P_ = p1*a[...,None] + p2*b[...,None] + p3*c[...,None]\n",
        "  P_x_8m = get_inside_cell_mask(P_,ooxyz) & mask & masks\n",
        "  P_x_8 = P_\n",
        "  #uv\n",
        "  p1_uv = point_UV_grid[cell_x,cell_y0,cell_z,0,0]\n",
        "  p2_uv = point_UV_grid[cell_x,cell_y0,cell_z,0,3]\n",
        "  p3_uv = point_UV_grid[cell_x,cell_y0,cell_z,0,2]\n",
        "  P_uv = p1_uv*a[...,None] + p2_uv*b[...,None] + p3_uv*c[...,None]\n",
        "  P_uv = np.clip( (P_uv*out_img_size).astype(np.int32), 0, out_img_size-1)\n",
        "  P_x_8c = texture_alpha[P_uv[...,0],P_uv[...,1]]\n",
        "  P_x_8uv = P_uv\n",
        "  #uv end\n",
        "\n",
        "  # ------y:\n",
        "\n",
        "  # P[x-1,y,z-1]  P[x-1,y,z]    P[x,y,z]\n",
        "  p1 = bob\n",
        "  p2 = boo\n",
        "  p3 = ooo\n",
        "  a,b,c,mask = get_barycentric(p1,p2,p3,o,d)\n",
        "  P_ = p1*a[...,None] + p2*b[...,None] + p3*c[...,None]\n",
        "  P_y_1m = get_inside_cell_mask(P_,ooxyz) & mask & masks\n",
        "  P_y_1 = P_\n",
        "  #uv\n",
        "  p1_uv = point_UV_grid[cell_x0,cell_y,cell_z0,1,0]\n",
        "  p2_uv = point_UV_grid[cell_x0,cell_y,cell_z0,1,2]\n",
        "  p3_uv = point_UV_grid[cell_x0,cell_y,cell_z0,1,3]\n",
        "  P_uv = p1_uv*a[...,None] + p2_uv*b[...,None] + p3_uv*c[...,None]\n",
        "  P_uv = np.clip( (P_uv*out_img_size).astype(np.int32), 0, out_img_size-1)\n",
        "  P_y_1c = texture_alpha[P_uv[...,0],P_uv[...,1]]\n",
        "  P_y_1uv = P_uv\n",
        "  #uv end\n",
        "\n",
        "  # P[x-1,y,z-1]  P[x,y,z-1]    P[x,y,z]\n",
        "  p1 = bob\n",
        "  p2 = oob\n",
        "  p3 = ooo\n",
        "  a,b,c,mask = get_barycentric(p1,p2,p3,o,d)\n",
        "  P_ = p1*a[...,None] + p2*b[...,None] + p3*c[...,None]\n",
        "  P_y_2m = get_inside_cell_mask(P_,ooxyz) & mask & masks\n",
        "  P_y_2 = P_\n",
        "  #uv\n",
        "  p1_uv = point_UV_grid[cell_x0,cell_y,cell_z0,1,0]\n",
        "  p2_uv = point_UV_grid[cell_x0,cell_y,cell_z0,1,1]\n",
        "  p3_uv = point_UV_grid[cell_x0,cell_y,cell_z0,1,3]\n",
        "  P_uv = p1_uv*a[...,None] + p2_uv*b[...,None] + p3_uv*c[...,None]\n",
        "  P_uv = np.clip( (P_uv*out_img_size).astype(np.int32), 0, out_img_size-1)\n",
        "  P_y_2c = texture_alpha[P_uv[...,0],P_uv[...,1]]\n",
        "  P_y_2uv = P_uv\n",
        "  #uv end\n",
        "\n",
        "  # P[x+1,y,z+1]  P[x+1,y,z]    P[x,y,z]\n",
        "  p1 = dod\n",
        "  p2 = doo\n",
        "  p3 = ooo\n",
        "  a,b,c,mask = get_barycentric(p1,p2,p3,o,d)\n",
        "  P_ = p1*a[...,None] + p2*b[...,None] + p3*c[...,None]\n",
        "  P_y_3m = get_inside_cell_mask(P_,ooxyz) & mask & masks\n",
        "  P_y_3 = P_\n",
        "  #uv\n",
        "  p1_uv = point_UV_grid[cell_x,cell_y,cell_z,1,3]\n",
        "  p2_uv = point_UV_grid[cell_x,cell_y,cell_z,1,1]\n",
        "  p3_uv = point_UV_grid[cell_x,cell_y,cell_z,1,0]\n",
        "  P_uv = p1_uv*a[...,None] + p2_uv*b[...,None] + p3_uv*c[...,None]\n",
        "  P_uv = np.clip( (P_uv*out_img_size).astype(np.int32), 0, out_img_size-1)\n",
        "  P_y_3c = texture_alpha[P_uv[...,0],P_uv[...,1]]\n",
        "  P_y_3uv = P_uv\n",
        "  #uv end\n",
        "\n",
        "  # P[x+1,y,z+1]  P[x,y,z+1]    P[x,y,z]\n",
        "  p1 = dod\n",
        "  p2 = ood\n",
        "  p3 = ooo\n",
        "  a,b,c,mask = get_barycentric(p1,p2,p3,o,d)\n",
        "  P_ = p1*a[...,None] + p2*b[...,None] + p3*c[...,None]\n",
        "  P_y_4m = get_inside_cell_mask(P_,ooxyz) & mask & masks\n",
        "  P_y_4 = P_\n",
        "  #uv\n",
        "  p1_uv = point_UV_grid[cell_x,cell_y,cell_z,1,3]\n",
        "  p2_uv = point_UV_grid[cell_x,cell_y,cell_z,1,2]\n",
        "  p3_uv = point_UV_grid[cell_x,cell_y,cell_z,1,0]\n",
        "  P_uv = p1_uv*a[...,None] + p2_uv*b[...,None] + p3_uv*c[...,None]\n",
        "  P_uv = np.clip( (P_uv*out_img_size).astype(np.int32), 0, out_img_size-1)\n",
        "  P_y_4c = texture_alpha[P_uv[...,0],P_uv[...,1]]\n",
        "  P_y_4uv = P_uv\n",
        "  #uv end\n",
        "\n",
        "  # P[x,y,z-1]    P[x+1,y,z]    P[x,y,z]\n",
        "  p1 = oob\n",
        "  p2 = doo\n",
        "  p3 = ooo\n",
        "  a,b,c,mask = get_barycentric(p1,p2,p3,o,d)\n",
        "  P_ = p1*a[...,None] + p2*b[...,None] + p3*c[...,None]\n",
        "  P_y_5m = get_inside_cell_mask(P_,ooxyz) & mask & masks\n",
        "  P_y_5 = P_\n",
        "  #uv\n",
        "  p1_uv = point_UV_grid[cell_x,cell_y,cell_z0,1,0]\n",
        "  p2_uv = point_UV_grid[cell_x,cell_y,cell_z0,1,3]\n",
        "  p3_uv = point_UV_grid[cell_x,cell_y,cell_z0,1,2]\n",
        "  P_uv = p1_uv*a[...,None] + p2_uv*b[...,None] + p3_uv*c[...,None]\n",
        "  P_uv = np.clip( (P_uv*out_img_size).astype(np.int32), 0, out_img_size-1)\n",
        "  P_y_5c = texture_alpha[P_uv[...,0],P_uv[...,1]]\n",
        "  P_y_5uv = P_uv\n",
        "  #uv end\n",
        "\n",
        "  # P[x,y,z-1]    P[x+1,y,z]    P[x+1,y,z-1]\n",
        "  p1 = oob\n",
        "  p2 = doo\n",
        "  p3 = dob\n",
        "  a,b,c,mask = get_barycentric(p1,p2,p3,o,d)\n",
        "  P_ = p1*a[...,None] + p2*b[...,None] + p3*c[...,None]\n",
        "  P_y_6m = get_inside_cell_mask(P_,ooxyz) & mask & masks\n",
        "  P_y_6 = P_\n",
        "  #uv\n",
        "  p1_uv = point_UV_grid[cell_x,cell_y,cell_z0,1,0]\n",
        "  p2_uv = point_UV_grid[cell_x,cell_y,cell_z0,1,3]\n",
        "  p3_uv = point_UV_grid[cell_x,cell_y,cell_z0,1,1]\n",
        "  P_uv = p1_uv*a[...,None] + p2_uv*b[...,None] + p3_uv*c[...,None]\n",
        "  P_uv = np.clip( (P_uv*out_img_size).astype(np.int32), 0, out_img_size-1)\n",
        "  P_y_6c = texture_alpha[P_uv[...,0],P_uv[...,1]]\n",
        "  P_y_6uv = P_uv\n",
        "  #uv end\n",
        "\n",
        "  # P[x-1,y,z]    P[x,y,z+1]    P[x,y,z]\n",
        "  p1 = boo\n",
        "  p2 = ood\n",
        "  p3 = ooo\n",
        "  a,b,c,mask = get_barycentric(p1,p2,p3,o,d)\n",
        "  P_ = p1*a[...,None] + p2*b[...,None] + p3*c[...,None]\n",
        "  P_y_7m = get_inside_cell_mask(P_,ooxyz) & mask & masks\n",
        "  P_y_7 = P_\n",
        "  #uv\n",
        "  p1_uv = point_UV_grid[cell_x0,cell_y,cell_z,1,0]\n",
        "  p2_uv = point_UV_grid[cell_x0,cell_y,cell_z,1,3]\n",
        "  p3_uv = point_UV_grid[cell_x0,cell_y,cell_z,1,1]\n",
        "  P_uv = p1_uv*a[...,None] + p2_uv*b[...,None] + p3_uv*c[...,None]\n",
        "  P_uv = np.clip( (P_uv*out_img_size).astype(np.int32), 0, out_img_size-1)\n",
        "  P_y_7c = texture_alpha[P_uv[...,0],P_uv[...,1]]\n",
        "  P_y_7uv = P_uv\n",
        "  #uv end\n",
        "\n",
        "  # P[x-1,y,z]    P[x,y,z+1]    P[x-1,y,z+1]\n",
        "  p1 = boo\n",
        "  p2 = ood\n",
        "  p3 = bod\n",
        "  a,b,c,mask = get_barycentric(p1,p2,p3,o,d)\n",
        "  P_ = p1*a[...,None] + p2*b[...,None] + p3*c[...,None]\n",
        "  P_y_8m = get_inside_cell_mask(P_,ooxyz) & mask & masks\n",
        "  P_y_8 = P_\n",
        "  #uv\n",
        "  p1_uv = point_UV_grid[cell_x0,cell_y,cell_z,1,0]\n",
        "  p2_uv = point_UV_grid[cell_x0,cell_y,cell_z,1,3]\n",
        "  p3_uv = point_UV_grid[cell_x0,cell_y,cell_z,1,2]\n",
        "  P_uv = p1_uv*a[...,None] + p2_uv*b[...,None] + p3_uv*c[...,None]\n",
        "  P_uv = np.clip( (P_uv*out_img_size).astype(np.int32), 0, out_img_size-1)\n",
        "  P_y_8c = texture_alpha[P_uv[...,0],P_uv[...,1]]\n",
        "  P_y_8uv = P_uv\n",
        "  #uv end\n",
        "\n",
        "  # ------z:\n",
        "\n",
        "  # P[x-1,y-1,z]  P[x-1,y,z]    P[x,y,z]\n",
        "  p1 = bbo\n",
        "  p2 = boo\n",
        "  p3 = ooo\n",
        "  a,b,c,mask = get_barycentric(p1,p2,p3,o,d)\n",
        "  P_ = p1*a[...,None] + p2*b[...,None] + p3*c[...,None]\n",
        "  P_z_1m = get_inside_cell_mask(P_,ooxyz) & mask & masks\n",
        "  P_z_1 = P_\n",
        "  #uv\n",
        "  p1_uv = point_UV_grid[cell_x0,cell_y0,cell_z,2,0]\n",
        "  p2_uv = point_UV_grid[cell_x0,cell_y0,cell_z,2,2]\n",
        "  p3_uv = point_UV_grid[cell_x0,cell_y0,cell_z,2,3]\n",
        "  P_uv = p1_uv*a[...,None] + p2_uv*b[...,None] + p3_uv*c[...,None]\n",
        "  P_uv = np.clip( (P_uv*out_img_size).astype(np.int32), 0, out_img_size-1)\n",
        "  P_z_1c = texture_alpha[P_uv[...,0],P_uv[...,1]]\n",
        "  P_z_1uv = P_uv\n",
        "  #uv end\n",
        "\n",
        "  # P[x-1,y-1,z]  P[x,y-1,z]    P[x,y,z]\n",
        "  p1 = bbo\n",
        "  p2 = obo\n",
        "  p3 = ooo\n",
        "  a,b,c,mask = get_barycentric(p1,p2,p3,o,d)\n",
        "  P_ = p1*a[...,None] + p2*b[...,None] + p3*c[...,None]\n",
        "  P_z_2m = get_inside_cell_mask(P_,ooxyz) & mask & masks\n",
        "  P_z_2 = P_\n",
        "  #uv\n",
        "  p1_uv = point_UV_grid[cell_x0,cell_y0,cell_z,2,0]\n",
        "  p2_uv = point_UV_grid[cell_x0,cell_y0,cell_z,2,1]\n",
        "  p3_uv = point_UV_grid[cell_x0,cell_y0,cell_z,2,3]\n",
        "  P_uv = p1_uv*a[...,None] + p2_uv*b[...,None] + p3_uv*c[...,None]\n",
        "  P_uv = np.clip( (P_uv*out_img_size).astype(np.int32), 0, out_img_size-1)\n",
        "  P_z_2c = texture_alpha[P_uv[...,0],P_uv[...,1]]\n",
        "  P_z_2uv = P_uv\n",
        "  #uv end\n",
        "\n",
        "  # P[x+1,y+1,z]  P[x+1,y,z]    P[x,y,z]\n",
        "  p1 = ddo\n",
        "  p2 = doo\n",
        "  p3 = ooo\n",
        "  a,b,c,mask = get_barycentric(p1,p2,p3,o,d)\n",
        "  P_ = p1*a[...,None] + p2*b[...,None] + p3*c[...,None]\n",
        "  P_z_3m = get_inside_cell_mask(P_,ooxyz) & mask & masks\n",
        "  P_z_3 = P_\n",
        "  #uv\n",
        "  p1_uv = point_UV_grid[cell_x,cell_y,cell_z,2,3]\n",
        "  p2_uv = point_UV_grid[cell_x,cell_y,cell_z,2,1]\n",
        "  p3_uv = point_UV_grid[cell_x,cell_y,cell_z,2,0]\n",
        "  P_uv = p1_uv*a[...,None] + p2_uv*b[...,None] + p3_uv*c[...,None]\n",
        "  P_uv = np.clip( (P_uv*out_img_size).astype(np.int32), 0, out_img_size-1)\n",
        "  P_z_3c = texture_alpha[P_uv[...,0],P_uv[...,1]]\n",
        "  P_z_3uv = P_uv\n",
        "  #uv end\n",
        "\n",
        "  # P[x+1,y+1,z]  P[x,y+1,z]    P[x,y,z]\n",
        "  p1 = ddo\n",
        "  p2 = odo\n",
        "  p3 = ooo\n",
        "  a,b,c,mask = get_barycentric(p1,p2,p3,o,d)\n",
        "  P_ = p1*a[...,None] + p2*b[...,None] + p3*c[...,None]\n",
        "  P_z_4m = get_inside_cell_mask(P_,ooxyz) & mask & masks\n",
        "  P_z_4 = P_\n",
        "  #uv\n",
        "  p1_uv = point_UV_grid[cell_x,cell_y,cell_z,2,3]\n",
        "  p2_uv = point_UV_grid[cell_x,cell_y,cell_z,2,2]\n",
        "  p3_uv = point_UV_grid[cell_x,cell_y,cell_z,2,0]\n",
        "  P_uv = p1_uv*a[...,None] + p2_uv*b[...,None] + p3_uv*c[...,None]\n",
        "  P_uv = np.clip( (P_uv*out_img_size).astype(np.int32), 0, out_img_size-1)\n",
        "  P_z_4c = texture_alpha[P_uv[...,0],P_uv[...,1]]\n",
        "  P_z_4uv = P_uv\n",
        "  #uv end\n",
        "\n",
        "  # P[x,y-1,z]    P[x+1,y,z]    P[x,y,z]\n",
        "  p1 = obo\n",
        "  p2 = doo\n",
        "  p3 = ooo\n",
        "  a,b,c,mask = get_barycentric(p1,p2,p3,o,d)\n",
        "  P_ = p1*a[...,None] + p2*b[...,None] + p3*c[...,None]\n",
        "  P_z_5m = get_inside_cell_mask(P_,ooxyz) & mask & masks\n",
        "  P_z_5 = P_\n",
        "  #uv\n",
        "  p1_uv = point_UV_grid[cell_x,cell_y0,cell_z,2,0]\n",
        "  p2_uv = point_UV_grid[cell_x,cell_y0,cell_z,2,3]\n",
        "  p3_uv = point_UV_grid[cell_x,cell_y0,cell_z,2,2]\n",
        "  P_uv = p1_uv*a[...,None] + p2_uv*b[...,None] + p3_uv*c[...,None]\n",
        "  P_uv = np.clip( (P_uv*out_img_size).astype(np.int32), 0, out_img_size-1)\n",
        "  P_z_5c = texture_alpha[P_uv[...,0],P_uv[...,1]]\n",
        "  P_z_5uv = P_uv\n",
        "  #uv end\n",
        "\n",
        "  # P[x,y-1,z]    P[x+1,y,z]    P[x+1,y-1,z]\n",
        "  p1 = obo\n",
        "  p2 = doo\n",
        "  p3 = dbo\n",
        "  a,b,c,mask = get_barycentric(p1,p2,p3,o,d)\n",
        "  P_ = p1*a[...,None] + p2*b[...,None] + p3*c[...,None]\n",
        "  P_z_6m = get_inside_cell_mask(P_,ooxyz) & mask & masks\n",
        "  P_z_6 = P_\n",
        "  #uv\n",
        "  p1_uv = point_UV_grid[cell_x,cell_y0,cell_z,2,0]\n",
        "  p2_uv = point_UV_grid[cell_x,cell_y0,cell_z,2,3]\n",
        "  p3_uv = point_UV_grid[cell_x,cell_y0,cell_z,2,1]\n",
        "  P_uv = p1_uv*a[...,None] + p2_uv*b[...,None] + p3_uv*c[...,None]\n",
        "  P_uv = np.clip( (P_uv*out_img_size).astype(np.int32), 0, out_img_size-1)\n",
        "  P_z_6c = texture_alpha[P_uv[...,0],P_uv[...,1]]\n",
        "  P_z_6uv = P_uv\n",
        "  #uv end\n",
        "\n",
        "  # P[x-1,y,z]    P[x,y+1,z]    P[x,y,z]\n",
        "  p1 = boo\n",
        "  p2 = odo\n",
        "  p3 = ooo\n",
        "  a,b,c,mask = get_barycentric(p1,p2,p3,o,d)\n",
        "  P_ = p1*a[...,None] + p2*b[...,None] + p3*c[...,None]\n",
        "  P_z_7m = get_inside_cell_mask(P_,ooxyz) & mask & masks\n",
        "  P_z_7 = P_\n",
        "  #uv\n",
        "  p1_uv = point_UV_grid[cell_x0,cell_y,cell_z,2,0]\n",
        "  p2_uv = point_UV_grid[cell_x0,cell_y,cell_z,2,3]\n",
        "  p3_uv = point_UV_grid[cell_x0,cell_y,cell_z,2,1]\n",
        "  P_uv = p1_uv*a[...,None] + p2_uv*b[...,None] + p3_uv*c[...,None]\n",
        "  P_uv = np.clip( (P_uv*out_img_size).astype(np.int32), 0, out_img_size-1)\n",
        "  P_z_7c = texture_alpha[P_uv[...,0],P_uv[...,1]]\n",
        "  P_z_7uv = P_uv\n",
        "  #uv end\n",
        "\n",
        "  # P[x-1,y,z]    P[x,y+1,z]    P[x-1,y+1,z]\n",
        "  p1 = boo\n",
        "  p2 = odo\n",
        "  p3 = bdo\n",
        "  a,b,c,mask = get_barycentric(p1,p2,p3,o,d)\n",
        "  P_ = p1*a[...,None] + p2*b[...,None] + p3*c[...,None]\n",
        "  P_z_8m = get_inside_cell_mask(P_,ooxyz) & mask & masks\n",
        "  P_z_8 = P_\n",
        "  #uv\n",
        "  p1_uv = point_UV_grid[cell_x0,cell_y,cell_z,2,0]\n",
        "  p2_uv = point_UV_grid[cell_x0,cell_y,cell_z,2,3]\n",
        "  p3_uv = point_UV_grid[cell_x0,cell_y,cell_z,2,2]\n",
        "  P_uv = p1_uv*a[...,None] + p2_uv*b[...,None] + p3_uv*c[...,None]\n",
        "  P_uv = np.clip( (P_uv*out_img_size).astype(np.int32), 0, out_img_size-1)\n",
        "  P_z_8c = texture_alpha[P_uv[...,0],P_uv[...,1]]\n",
        "  P_z_8uv = P_uv\n",
        "  #uv end\n",
        "\n",
        "\n",
        "\n",
        "  world_masks = np.concatenate([\n",
        "                          P_x_1m, P_x_2m, P_x_3m, P_x_4m,\n",
        "                          P_x_5m, P_x_6m, P_x_7m, P_x_8m,\n",
        "                          P_y_1m, P_y_2m, P_y_3m, P_y_4m,\n",
        "                          P_y_5m, P_y_6m, P_y_7m, P_y_8m,\n",
        "                          P_z_1m, P_z_2m, P_z_3m, P_z_4m,\n",
        "                          P_z_5m, P_z_6m, P_z_7m, P_z_8m,\n",
        "                          ], axis=-1) #[..., SN*24]\n",
        "\n",
        "  world_positions = np.concatenate([\n",
        "                          P_x_1, P_x_2, P_x_3, P_x_4,\n",
        "                          P_x_5, P_x_6, P_x_7, P_x_8,\n",
        "                          P_y_1, P_y_2, P_y_3, P_y_4,\n",
        "                          P_y_5, P_y_6, P_y_7, P_y_8,\n",
        "                          P_z_1, P_z_2, P_z_3, P_z_4,\n",
        "                          P_z_5, P_z_6, P_z_7, P_z_8,\n",
        "                          ], axis=-2) #[..., SN*24, 3]\n",
        "\n",
        "  world_alpha = np.concatenate([\n",
        "                          P_x_1c, P_x_2c, P_x_3c, P_x_4c,\n",
        "                          P_x_5c, P_x_6c, P_x_7c, P_x_8c,\n",
        "                          P_y_1c, P_y_2c, P_y_3c, P_y_4c,\n",
        "                          P_y_5c, P_y_6c, P_y_7c, P_y_8c,\n",
        "                          P_z_1c, P_z_2c, P_z_3c, P_z_4c,\n",
        "                          P_z_5c, P_z_6c, P_z_7c, P_z_8c,\n",
        "                          ], axis=-2) #[..., SN*24, 1]\n",
        "\n",
        "  world_uv = np.concatenate([\n",
        "                          P_x_1uv, P_x_2uv, P_x_3uv, P_x_4uv,\n",
        "                          P_x_5uv, P_x_6uv, P_x_7uv, P_x_8uv,\n",
        "                          P_y_1uv, P_y_2uv, P_y_3uv, P_y_4uv,\n",
        "                          P_y_5uv, P_y_6uv, P_y_7uv, P_y_8uv,\n",
        "                          P_z_1uv, P_z_2uv, P_z_3uv, P_z_4uv,\n",
        "                          P_z_5uv, P_z_6uv, P_z_7uv, P_z_8uv,\n",
        "                          ], axis=-2) #[..., SN*24,2]\n",
        "\n",
        "  world_tx = world_positions*ray_directions[..., None,:]\n",
        "  world_tx = np.sum(world_tx, -1) #[..., SN*24]\n",
        "  world_tx = world_tx*world_masks + 1000*np.logical_not(world_masks).astype(dtype)\n",
        "\n",
        "  ind = np.argsort(world_tx, axis=-1)\n",
        "  ind = ind[..., :point_grid_size*3]\n",
        "\n",
        "  world_masks = np.take_along_axis(world_masks, ind, axis=-1)\n",
        "  world_positions = np.take_along_axis(world_positions, ind[..., None], axis=-2)\n",
        "  world_alpha = np.take_along_axis(world_alpha, ind[..., None], axis=-2)\n",
        "  world_uv = np.take_along_axis(world_uv, ind[..., None], axis=-2)\n",
        "\n",
        "  return world_alpha*world_masks[..., None], world_uv\n",
        "\n",
        "\n",
        "#%%\n",
        "def compute_volumetric_rendering_weights_with_alpha(alpha):\n",
        "  density_exp = 1. - alpha\n",
        "  density_exp_shifted = np.concatenate([np.ones_like(density_exp[..., :1]),\n",
        "                                          density_exp[..., :-1]], axis=-1)\n",
        "  trans = np.cumprod(density_exp_shifted, axis=-1)\n",
        "  weights = alpha * trans\n",
        "  return weights\n",
        "\n",
        "def render_rays_get_uv(rays, vars, uv, alp):\n",
        "\n",
        "  #---------- ray-plane intersection points\n",
        "  grid_indices, grid_masks = gridcell_from_rays(rays)\n",
        "\n",
        "  world_alpha, world_uv = compute_undc_intersection_and_return_uv(\n",
        "                        vars[0], uv, alp, grid_indices, grid_masks, rays)\n",
        "  world_alpha = world_alpha.astype(np.float32)\n",
        "\n",
        "  # Now use the MLP to compute density and features\n",
        "  mlp_alpha_b = world_alpha[..., 0] #[N,4,P]\n",
        "  weights_b = compute_volumetric_rendering_weights_with_alpha(mlp_alpha_b) #[N,4,P]\n",
        "  acc_b = (np.sum(weights_b, axis=-1) > 0.5) #[N,4]\n",
        "\n",
        "  ind = np.argmax(weights_b, axis=-1, keepdims=True) #[N,4,1]\n",
        "  selected_uv = np.take_along_axis(world_uv, ind[..., None], axis=-2) #[N,4,1,2]\n",
        "  selected_uv = selected_uv[..., 0,:] * acc_b[..., None] #[N,4,2]\n",
        "\n",
        "  return acc_b, selected_uv\n",
        "\n",
        "def render_rays_get_color(rays, vars, mlp_features_b, acc_b):\n",
        "\n",
        "  mlp_features_b = mlp_features_b.astype(np.float32)/255 #[N,4,C]\n",
        "  mlp_features_b = mlp_features_b  * acc_b[..., None] #[N,4,C]\n",
        "  mlp_features_b = np.mean(mlp_features_b, axis=-2) #[N,C]\n",
        "\n",
        "  acc_b = np.mean(acc_b.astype(np.float32), axis=-1) #[N]\n",
        "\n",
        "  # ... as well as view-dependent colors.\n",
        "  dirs = normalize(rays[1]) #[N,4,3]\n",
        "  dirs = np.mean(dirs, axis=-2) #[N,3]\n",
        "  features_dirs_enc_b = np.concatenate([mlp_features_b, dirs], axis=-1) #[N,C+3]\n",
        "  rgb_b = jax.nn.sigmoid(color_model.apply(vars[-1], features_dirs_enc_b))\n",
        "\n",
        "  # Composite onto the background color.\n",
        "  if white_bkgd:\n",
        "    rgb_b = rgb_b * acc_b[..., None] + (1. - acc_b[..., None])\n",
        "  else:\n",
        "    bgc = bg_color\n",
        "    rgb_b = rgb_b * acc_b[..., None] + (1. - acc_b[..., None]) * bgc\n",
        "\n",
        "  return rgb_b, acc_b\n",
        "\n",
        "#%% --------------------------------------------------------------------------------\n",
        "# ## Set up pmap'd rendering for test time evaluation.\n",
        "#%%\n",
        "#for eval\n",
        "texture_alpha = numpy.zeros([out_img_size,out_img_size,1], numpy.uint8)\n",
        "texture_features = numpy.zeros([out_img_size,out_img_size,8], numpy.uint8)\n",
        "\n",
        "texture_alpha[:,:,0] = (out_img[0][:,:,2]>0)\n",
        "\n",
        "texture_features[:,:,0:3] = out_img[0][:,:,2::-1]\n",
        "texture_features[:,:,3] = out_img[0][:,:,3]\n",
        "texture_features[:,:,4:7] = out_img[1][:,:,2::-1]\n",
        "texture_features[:,:,7] = out_img[1][:,:,3]\n",
        "#%%\n",
        "test_batch_size = 4096*n_device\n",
        "\n",
        "render_rays_get_uv_p = jax.pmap(lambda rays, vars, uv, alp: render_rays_get_uv(\n",
        "    rays, vars, uv, alp),\n",
        "    in_axes=(0, None, None, None))\n",
        "\n",
        "render_rays_get_color_p = jax.pmap(lambda rays, vars, mlp_features_b, acc_b: render_rays_get_color(\n",
        "    rays, vars, mlp_features_b, acc_b),\n",
        "    in_axes=(0, None, 0, 0))\n",
        "\n",
        "\n",
        "def render_test(rays, vars, uv, alp, feat):\n",
        "  sh = rays[0].shape\n",
        "  rays = [x.reshape((jax.local_device_count(), -1) + sh[1:]) for x in rays]\n",
        "  acc_b, selected_uv = render_rays_get_uv_p(rays, vars, uv, alp)\n",
        "\n",
        "  #deferred features\n",
        "  selected_uv = numpy.array(selected_uv)\n",
        "  mlp_features_b = feat[selected_uv[...,0],selected_uv[...,1]]\n",
        "\n",
        "  rgb_b, acc_b = render_rays_get_color_p(rays, vars, mlp_features_b, acc_b)\n",
        "\n",
        "  out = [rgb_b, acc_b, selected_uv]\n",
        "  out = [numpy.reshape(numpy.array(out[i]),sh[:-2]+(-1,)) for i in range(3)]\n",
        "  return out\n",
        "\n",
        "def render_loop(rays, vars, uv, alp, feat, chunk):\n",
        "  sh = list(rays[0].shape[:-2])\n",
        "  rays = [x.reshape([-1, 4, 3]) for x in rays]\n",
        "  l = rays[0].shape[0]\n",
        "  n = jax.local_device_count()\n",
        "  p = ((l - 1) // n + 1) * n - l\n",
        "  rays = [np.pad(x, ((0,p),(0,0),(0,0))) for x in rays]\n",
        "  outs = [render_test([x[i:i+chunk] for x in rays], vars, uv, alp, feat)\n",
        "          for i in range(0, rays[0].shape[0], chunk)]\n",
        "  outs = [np.reshape(\n",
        "      np.concatenate([z[i] for z in outs])[:l], sh + [-1]) for i in range(3)]\n",
        "  return outs\n",
        "\n",
        "# Make sure that everything works, by rendering an image from the test set\n",
        "\n",
        "if scene_type==\"synthetic\":\n",
        "  selected_test_index = 97\n",
        "  preview_image_height = 800\n",
        "\n",
        "elif scene_type==\"forwardfacing\":\n",
        "  selected_test_index = 0\n",
        "  preview_image_height = 756//2\n",
        "\n",
        "elif scene_type==\"real360\":\n",
        "  selected_test_index = 0\n",
        "  preview_image_height = 840//2\n",
        "\n",
        "rays = camera_ray_batch(\n",
        "    data['test']['c2w'][selected_test_index], data['test']['hwf'])\n",
        "gt = data['test']['images'][selected_test_index]\n",
        "out = render_loop(rays, model_vars, point_UV_grid, texture_alpha, texture_features, test_batch_size)\n",
        "rgb = out[0]\n",
        "acc = out[1]\n",
        "write_floatpoint_image(samples_dir+\"/s3_\"+str(0)+\"_rgb_discretized.png\",rgb)\n",
        "write_floatpoint_image(samples_dir+\"/s3_\"+str(0)+\"_gt.png\",gt)\n",
        "write_floatpoint_image(samples_dir+\"/s3_\"+str(0)+\"_acc_discretized.png\",acc)\n",
        "#%% --------------------------------------------------------------------------------\n",
        "# ## Remove invisible triangles\n",
        "#%%\n",
        "gc.collect()\n",
        "\n",
        "render_poses = data['train']['c2w']\n",
        "texture_mask = numpy.zeros([out_img_size,out_img_size], numpy.uint8)\n",
        "print(\"Removing invisible triangles\")\n",
        "for p in tqdm(render_poses):\n",
        "  out = render_loop(camera_ray_batch(p, hwf), vars, point_UV_grid, texture_alpha, texture_features, test_batch_size)\n",
        "  uv = np.reshape(out[2],[-1,2])\n",
        "  texture_mask[uv[:,0],uv[:,1]] = 1\n",
        "#%%\n",
        "#additional views\n",
        "if scene_type==\"synthetic\":\n",
        "  def generate_spherical_poses(poses):\n",
        "    rad = np.sqrt(np.mean(np.sum(np.square(poses[:, :3, 3]), -1)))\n",
        "    centroid = np.mean(poses[:, :3, 3], 0)\n",
        "    pmax = np.max(poses[:, :3, 3], 0)\n",
        "    pmin = np.min(poses[:, :3, 3], 0)\n",
        "    zh0 = centroid[2]\n",
        "    zh1 = centroid[2]*0.6 + pmax[2]*0.4\n",
        "    zh2 = centroid[2]*0.2 + pmax[2]*0.8\n",
        "    zh3 = centroid[2]*0.6 + pmin[2]*0.4\n",
        "    zh4 = centroid[2]*0.2 + pmin[2]*0.8\n",
        "    new_poses = []\n",
        "\n",
        "    for zh in [zh0,zh1,zh2,zh3,zh4]:\n",
        "      radcircle = np.sqrt(rad**2 - zh**2)\n",
        "      for th in np.linspace(0., 2. * np.pi, 60):\n",
        "        camorigin = np.array([radcircle * np.cos(th), radcircle * np.sin(th), zh])\n",
        "        up = np.array([0, 0, -1.])\n",
        "        vec2 = normalize(camorigin)\n",
        "        vec0 = normalize(np.cross(vec2, up))\n",
        "        vec1 = normalize(np.cross(vec2, vec0))\n",
        "        pos = camorigin\n",
        "        p = np.stack([vec0, vec1, vec2, pos], 1)\n",
        "        new_poses.append(p)\n",
        "\n",
        "    render_poses = np.stack(new_poses, 0)[:, :3, :4]\n",
        "    return render_poses\n",
        "\n",
        "  poses = data['train']['c2w']\n",
        "  additional_poses = generate_spherical_poses(poses)\n",
        "\n",
        "  print(\"Removing invisible triangles\")\n",
        "  for p in tqdm(additional_poses):\n",
        "    out = render_loop(camera_ray_batch(p, hwf), vars, point_UV_grid, texture_alpha, texture_features, test_batch_size)\n",
        "    uv = np.reshape(out[2],[-1,2])\n",
        "    texture_mask[uv[:,0],uv[:,1]] = 1\n",
        "#%%\n",
        "#mask invisible triangles for eval\n",
        "\n",
        "#count visible quads\n",
        "num_visible_quads = 0\n",
        "\n",
        "quad_t1_mask = numpy.zeros([out_cell_size,out_cell_size],numpy.uint8)\n",
        "quad_t2_mask = numpy.zeros([out_cell_size,out_cell_size],numpy.uint8)\n",
        "for i in range(out_cell_size):\n",
        "  for j in range(out_cell_size):\n",
        "    if i>=j:\n",
        "      quad_t1_mask[i,j] = 1\n",
        "    if i<=j:\n",
        "      quad_t2_mask[i,j] = 1\n",
        "\n",
        "def check_triangle_visible(mask,out_cell_num):\n",
        "  py = out_cell_num//out_img_w\n",
        "  px = out_cell_num%out_img_w\n",
        "\n",
        "  tsy = py*out_cell_size\n",
        "  tey = py*out_cell_size+out_cell_size\n",
        "  tsx = px*out_cell_size\n",
        "  tex = px*out_cell_size+out_cell_size\n",
        "\n",
        "  quad_m = mask[tsy:tey,tsx:tex]\n",
        "  t1_visible = numpy.any(quad_m*quad_t1_mask)\n",
        "  t2_visible = numpy.any(quad_m*quad_t2_mask)\n",
        "\n",
        "  return (t1_visible or t2_visible), t1_visible, t2_visible\n",
        "\n",
        "def mask_triangle_invisible(mask,out_cell_num,imga):\n",
        "  py = out_cell_num//out_img_w\n",
        "  px = out_cell_num%out_img_w\n",
        "\n",
        "  tsy = py*out_cell_size\n",
        "  tey = py*out_cell_size+out_cell_size\n",
        "  tsx = px*out_cell_size\n",
        "  tex = px*out_cell_size+out_cell_size\n",
        "\n",
        "  quad_m = mask[tsy:tey,tsx:tex]\n",
        "  t1_visible = numpy.any(quad_m*quad_t1_mask)\n",
        "  t2_visible = numpy.any(quad_m*quad_t2_mask)\n",
        "\n",
        "  if not (t1_visible or t2_visible):\n",
        "    imga[tsy:tey,tsx:tex] = 0\n",
        "\n",
        "  elif not t1_visible:\n",
        "    imga[tsy:tey,tsx:tex] = imga[tsy:tey,tsx:tex]*quad_t2_mask[:,:,None]\n",
        "\n",
        "  elif not t2_visible:\n",
        "    imga[tsy:tey,tsx:tex] = imga[tsy:tey,tsx:tex]*quad_t1_mask[:,:,None]\n",
        "\n",
        "  return (t1_visible or t2_visible), t1_visible, t2_visible\n",
        "\n",
        "\n",
        "for i in range(out_cell_num):\n",
        "  quad_visible, t1_visible, t2_visible = mask_triangle_invisible(texture_mask, i, texture_alpha)\n",
        "  if quad_visible:\n",
        "    num_visible_quads += 1\n",
        "\n",
        "print(\"Number of quad faces:\", num_visible_quads)\n",
        "\n",
        "step_gpu=step_gpu+1\n",
        "gpu_stats = gpustat.new_query().jsonify() #EDIT\n",
        "gpu_memory_consumption.append({\n",
        "            \"iteration\": step_gpu,\n",
        "            \"gpu_stats\": gpu_stats\n",
        "   })\n",
        "\n",
        "total_training_end= time.time()\n",
        "\n",
        "# Save GPU memory consumption and total training time\n",
        "with open(weights_dir+\"/gpu_memory_consumption_training_s3.txt\", \"w\") as f:\n",
        "    f.write(str(gpu_memory_consumption))\n",
        "\n",
        "with open(weights_dir+\"/total_training_time_training_s3.txt\", \"w\") as f:\n",
        "    f.write(f\"Total Training Time: {total_training_end-total_training_start} seconds\\n\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhfleHsesxZh"
      },
      "outputs": [],
      "source": [
        "#%% --------------------------------------------------------------------------------\n",
        "# ## Eval\n",
        "#%%\n",
        "gc.collect()\n",
        "\n",
        "render_poses = data['test']['c2w'][:len(data['test']['images'])]\n",
        "frames = []\n",
        "framemasks = []\n",
        "print(\"Testing\")\n",
        "for p in tqdm(render_poses):\n",
        "  out = render_loop(camera_ray_batch(p, hwf), vars, point_UV_grid, texture_alpha, texture_features, test_batch_size)\n",
        "  frames.append(out[0])\n",
        "  framemasks.append(out[1])\n",
        "psnrs_test = [-10 * np.log10(np.mean(np.square(rgb - gt))) for (rgb, gt) in zip(frames, data['test']['images'])]\n",
        "print(\"Test set average PSNR: %f\" % np.array(psnrs_test).mean())\n",
        "\n",
        "#%%\n",
        "import jax.numpy as jnp\n",
        "import jax.scipy as jsp\n",
        "\n",
        "def compute_ssim(img0,\n",
        "                 img1,\n",
        "                 max_val,\n",
        "                 filter_size=11,\n",
        "                 filter_sigma=1.5,\n",
        "                 k1=0.01,\n",
        "                 k2=0.03,\n",
        "                 return_map=False):\n",
        "  \"\"\"Computes SSIM from two images.\n",
        "  This function was modeled after tf.image.ssim, and should produce comparable\n",
        "  output.\n",
        "  Args:\n",
        "    img0: array. An image of size [..., width, height, num_channels].\n",
        "    img1: array. An image of size [..., width, height, num_channels].\n",
        "    max_val: float > 0. The maximum magnitude that `img0` or `img1` can have.\n",
        "    filter_size: int >= 1. Window size.\n",
        "    filter_sigma: float > 0. The bandwidth of the Gaussian used for filtering.\n",
        "    k1: float > 0. One of the SSIM dampening parameters.\n",
        "    k2: float > 0. One of the SSIM dampening parameters.\n",
        "    return_map: Bool. If True, will cause the per-pixel SSIM \"map\" to returned\n",
        "  Returns:\n",
        "    Each image's mean SSIM, or a tensor of individual values if `return_map`.\n",
        "  \"\"\"\n",
        "  # Construct a 1D Gaussian blur filter.\n",
        "  hw = filter_size // 2\n",
        "  shift = (2 * hw - filter_size + 1) / 2\n",
        "  f_i = ((jnp.arange(filter_size) - hw + shift) / filter_sigma)**2\n",
        "  filt = jnp.exp(-0.5 * f_i)\n",
        "  filt /= jnp.sum(filt)\n",
        "\n",
        "  # Blur in x and y (faster than the 2D convolution).\n",
        "  filt_fn1 = lambda z: jsp.signal.convolve2d(z, filt[:, None], mode=\"valid\")\n",
        "  filt_fn2 = lambda z: jsp.signal.convolve2d(z, filt[None, :], mode=\"valid\")\n",
        "\n",
        "  # Vmap the blurs to the tensor size, and then compose them.\n",
        "  num_dims = len(img0.shape)\n",
        "  map_axes = tuple(list(range(num_dims - 3)) + [num_dims - 1])\n",
        "  for d in map_axes:\n",
        "    filt_fn1 = jax.vmap(filt_fn1, in_axes=d, out_axes=d)\n",
        "    filt_fn2 = jax.vmap(filt_fn2, in_axes=d, out_axes=d)\n",
        "  filt_fn = lambda z: filt_fn1(filt_fn2(z))\n",
        "\n",
        "  mu0 = filt_fn(img0)\n",
        "  mu1 = filt_fn(img1)\n",
        "  mu00 = mu0 * mu0\n",
        "  mu11 = mu1 * mu1\n",
        "  mu01 = mu0 * mu1\n",
        "  sigma00 = filt_fn(img0**2) - mu00\n",
        "  sigma11 = filt_fn(img1**2) - mu11\n",
        "  sigma01 = filt_fn(img0 * img1) - mu01\n",
        "\n",
        "  # Clip the variances and covariances to valid values.\n",
        "  # Variance must be non-negative:\n",
        "  sigma00 = jnp.maximum(0., sigma00)\n",
        "  sigma11 = jnp.maximum(0., sigma11)\n",
        "  sigma01 = jnp.sign(sigma01) * jnp.minimum(\n",
        "      jnp.sqrt(sigma00 * sigma11), jnp.abs(sigma01))\n",
        "\n",
        "  c1 = (k1 * max_val)**2\n",
        "  c2 = (k2 * max_val)**2\n",
        "  numer = (2 * mu01 + c1) * (2 * sigma01 + c2)\n",
        "  denom = (mu00 + mu11 + c1) * (sigma00 + sigma11 + c2)\n",
        "  ssim_map = numer / denom\n",
        "  ssim = jnp.mean(ssim_map, list(range(num_dims - 3, num_dims)))\n",
        "  return ssim_map if return_map else ssim\n",
        "\n",
        "# Compiling to the CPU because it's faster and more accurate.\n",
        "ssim_fn = jax.jit(\n",
        "    functools.partial(compute_ssim, max_val=1.))#, backend=\"cpu\")\n",
        "\n",
        "ssim_values = []\n",
        "for i in range(len(data['test']['images'])):\n",
        "  ssim = ssim_fn(frames[i], data['test']['images'][i])\n",
        "  ssim_values.append(float(ssim))\n",
        "\n",
        "print(\"Test set average SSIM: %f\" % np.array(ssim_values).mean())\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'psnrs_test': psnrs_test,\n",
        "    'ssim_values': ssim_values\n",
        "})\n",
        "\n",
        "df.to_csv(samples_dir+'/s3_test_results_test.csv', index=False)\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAJx06OS_9qf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a36ebe4-cddb-452c-b2e8-d02fd5f473ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texture image size: 8192 4096\n"
          ]
        }
      ],
      "source": [
        "#%% --------------------------------------------------------------------------------\n",
        "# ## Write mesh\n",
        "#%%\n",
        "\n",
        "#use texture_mask to decide keep or drop\n",
        "\n",
        "new_img_sizes = [\n",
        "  [1024,1024],\n",
        "  [2048,1024],\n",
        "  [2048,2048],\n",
        "  [4096,2048],\n",
        "  [4096,4096],\n",
        "  [8192,4096],\n",
        "  [8192,8192],\n",
        "  [16384,8192],\n",
        "  [16384,16384],\n",
        "]\n",
        "\n",
        "fit_flag = False\n",
        "for i in range(len(new_img_sizes)):\n",
        "  new_img_size_w,new_img_size_h = new_img_sizes[i]\n",
        "  new_img_size_ratio = new_img_size_w/new_img_size_h\n",
        "  new_img_h = new_img_size_h//out_cell_size\n",
        "  new_img_w = new_img_size_w//out_cell_size\n",
        "  if num_visible_quads<=new_img_h*new_img_w:\n",
        "    fit_flag = True\n",
        "    break\n",
        "\n",
        "if fit_flag:\n",
        "  print(\"Texture image size:\", new_img_size_w,new_img_size_h)\n",
        "else:\n",
        "  print(\"Texture image too small\", new_img_size_w,new_img_size_h)\n",
        "  1/0\n",
        "\n",
        "\n",
        "new_img = []\n",
        "for i in range(out_feat_num):\n",
        "  new_img.append(numpy.zeros([new_img_size_h,new_img_size_w,4], numpy.uint8))\n",
        "new_cell_num = 0\n",
        "\n",
        "\n",
        "def copy_patch_to_png(out_img,out_cell_num,new_img,new_cell_num):\n",
        "  py = out_cell_num//out_img_w\n",
        "  px = out_cell_num%out_img_w\n",
        "\n",
        "  ny = new_cell_num//new_img_w\n",
        "  nx = new_cell_num%new_img_w\n",
        "\n",
        "  tsy = py*out_cell_size\n",
        "  tey = py*out_cell_size+out_cell_size\n",
        "  tsx = px*out_cell_size\n",
        "  tex = px*out_cell_size+out_cell_size\n",
        "  nsy = ny*out_cell_size\n",
        "  ney = ny*out_cell_size+out_cell_size\n",
        "  nsx = nx*out_cell_size\n",
        "  nex = nx*out_cell_size+out_cell_size\n",
        "\n",
        "  for i in range(out_feat_num):\n",
        "    new_img[i][nsy:ney,nsx:nex] = out_img[i][tsy:tey,tsx:tex]\n",
        "\n",
        "  return True\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cF0AjCrOtEh3"
      },
      "source": [
        "Write mesh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEDPxpuItFlF"
      },
      "outputs": [],
      "source": [
        "\n",
        "#write mesh\n",
        "\n",
        "obj_save_dir = \"/content/drive/MyDrive/datasets/100000/obj_\"\n",
        "if not os.path.exists(obj_save_dir):\n",
        "  os.makedirs(obj_save_dir)\n",
        "\n",
        "obj_f = open(obj_save_dir+\"/shape.obj\",'w')\n",
        "\n",
        "vcount = 0\n",
        "\n",
        "for i in range(out_cell_num):\n",
        "  quad_visible, t1_visible, t2_visible = check_triangle_visible(texture_mask, i)\n",
        "  if quad_visible:\n",
        "    copy_patch_to_png(out_img,i,new_img,new_cell_num)\n",
        "    p0,p1,p2,p3 = bag_of_v[i]\n",
        "    uv0,uv1,uv2,uv3 = get_png_uv(new_cell_num,new_img_w,new_img_size_w)\n",
        "    new_cell_num += 1\n",
        "\n",
        "    if scene_type==\"synthetic\" or scene_type==\"real360\":\n",
        "      obj_f.write(\"v %.6f %.6f %.6f\\n\" % (p0[0],p0[2],-p0[1]))\n",
        "      obj_f.write(\"v %.6f %.6f %.6f\\n\" % (p1[0],p1[2],-p1[1]))\n",
        "      obj_f.write(\"v %.6f %.6f %.6f\\n\" % (p2[0],p2[2],-p2[1]))\n",
        "      obj_f.write(\"v %.6f %.6f %.6f\\n\" % (p3[0],p3[2],-p3[1]))\n",
        "    elif scene_type==\"forwardfacing\":\n",
        "      obj_f.write(\"v %.6f %.6f %.6f\\n\" % (p0[0],p0[1],p0[2]))\n",
        "      obj_f.write(\"v %.6f %.6f %.6f\\n\" % (p1[0],p1[1],p1[2]))\n",
        "      obj_f.write(\"v %.6f %.6f %.6f\\n\" % (p2[0],p2[1],p2[2]))\n",
        "      obj_f.write(\"v %.6f %.6f %.6f\\n\" % (p3[0],p3[1],p3[2]))\n",
        "\n",
        "    obj_f.write(\"vt %.6f %.6f\\n\" % (uv0[1],1-uv0[0]*new_img_size_ratio))\n",
        "    obj_f.write(\"vt %.6f %.6f\\n\" % (uv1[1],1-uv1[0]*new_img_size_ratio))\n",
        "    obj_f.write(\"vt %.6f %.6f\\n\" % (uv2[1],1-uv2[0]*new_img_size_ratio))\n",
        "    obj_f.write(\"vt %.6f %.6f\\n\" % (uv3[1],1-uv3[0]*new_img_size_ratio))\n",
        "    if t1_visible:\n",
        "      obj_f.write(\"f %d/%d %d/%d %d/%d\\n\" % (vcount+1,vcount+1,vcount+2,vcount+2,vcount+4,vcount+4))\n",
        "    if t2_visible:\n",
        "      obj_f.write(\"f %d/%d %d/%d %d/%d\\n\" % (vcount+1,vcount+1,vcount+4,vcount+4,vcount+3,vcount+3))\n",
        "    vcount += 4\n",
        "\n",
        "for j in range(out_feat_num):\n",
        "  cv2.imwrite(obj_save_dir+\"/shape.pngfeat\"+str(j)+\".png\", new_img[j], [cv2.IMWRITE_PNG_COMPRESSION, 9])\n",
        "obj_f.close()\n",
        "\n",
        "\n",
        "#%%\n",
        "#export weights for the MLP\n",
        "mlp_params = {}\n",
        "\n",
        "mlp_params['0_weights'] = vars[-1]['params']['Dense_0']['kernel'].tolist()\n",
        "mlp_params['1_weights'] = vars[-1]['params']['Dense_1']['kernel'].tolist()\n",
        "mlp_params['2_weights'] = vars[-1]['params']['Dense_2']['kernel'].tolist()\n",
        "mlp_params['0_bias'] = vars[-1]['params']['Dense_0']['bias'].tolist()\n",
        "mlp_params['1_bias'] = vars[-1]['params']['Dense_1']['bias'].tolist()\n",
        "mlp_params['2_bias'] = vars[-1]['params']['Dense_2']['bias'].tolist()\n",
        "\n",
        "scene_params_path = obj_save_dir+'/mlp.json'\n",
        "with open(scene_params_path, 'wb') as f:\n",
        "  f.write(json.dumps(mlp_params).encode('utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JaDxCcgJtIhE"
      },
      "outputs": [],
      "source": [
        "#%% --------------------------------------------------------------------------------\n",
        "# ## Split the large texture image into images of size 4096\n",
        "#%%\n",
        "import numpy as np\n",
        "\n",
        "target_dir = obj_save_dir+\"_phone\"\n",
        "\n",
        "texture_size = 4096\n",
        "patchsize = 17\n",
        "texture_patch_size = texture_size//patchsize\n",
        "\n",
        "if not os.path.exists(target_dir):\n",
        "  os.makedirs(target_dir)\n",
        "\n",
        "\n",
        "source_obj_dir = obj_save_dir+\"/shape.obj\"\n",
        "source_png0_dir = obj_save_dir+\"/shape.pngfeat0.png\"\n",
        "source_png1_dir = obj_save_dir+\"/shape.pngfeat1.png\"\n",
        "\n",
        "source_png0 = cv2.imread(source_png0_dir,cv2.IMREAD_UNCHANGED)\n",
        "source_png1 = cv2.imread(source_png1_dir,cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "img_h,img_w,_ = source_png0.shape\n",
        "\n",
        "\n",
        "\n",
        "num_splits = 0 #this is a counter\n",
        "\n",
        "\n",
        "fin = open(source_obj_dir,'r')\n",
        "lines = fin.readlines()\n",
        "fin.close()\n",
        "\n",
        "\n",
        "\n",
        "current_img_idx = 0\n",
        "current_img0 = np.zeros([texture_size,texture_size,4],np.uint8)\n",
        "current_img1 = np.zeros([texture_size,texture_size,4],np.uint8)\n",
        "current_quad_count = 0\n",
        "current_obj = open(target_dir+\"/shape\"+str(current_img_idx)+\".obj\",'w')\n",
        "current_v_count = 0\n",
        "current_v_offset = 0\n",
        "\n",
        "#v-vt-f cycle\n",
        "\n",
        "for i in range(len(lines)):\n",
        "  line = lines[i].split()\n",
        "  if len(line)==0:\n",
        "    continue\n",
        "\n",
        "  elif line[0] == 'v':\n",
        "    current_obj.write(lines[i])\n",
        "    current_v_count += 1\n",
        "\n",
        "  elif line[0] == 'vt':\n",
        "    if lines[i-1].split()[0] == \"v\":\n",
        "\n",
        "      line = lines[i].split()\n",
        "      x0 = float(line[1])\n",
        "      y0 = 1-float(line[2])\n",
        "\n",
        "      line = lines[i+1].split()\n",
        "      x1 = float(line[1])\n",
        "      y1 = 1-float(line[2])\n",
        "\n",
        "      line = lines[i+2].split()\n",
        "      x2 = float(line[1])\n",
        "      y2 = 1-float(line[2])\n",
        "\n",
        "      line = lines[i+3].split()\n",
        "      x3 = float(line[1])\n",
        "      y3 = 1-float(line[2])\n",
        "\n",
        "      xc = (x0+x1+x2+x3)*img_w/4\n",
        "      yc = (y0+y1+y2+y3)*img_h/4\n",
        "\n",
        "      old_cell_x = int(xc/patchsize)\n",
        "      old_cell_y = int(yc/patchsize)\n",
        "\n",
        "      new_cell_x = current_quad_count%texture_patch_size\n",
        "      new_cell_y = current_quad_count//texture_patch_size\n",
        "      current_quad_count += 1\n",
        "\n",
        "      #copy patch\n",
        "\n",
        "      tsy = old_cell_y*patchsize\n",
        "      tey = old_cell_y*patchsize+patchsize\n",
        "      tsx = old_cell_x*patchsize\n",
        "      tex = old_cell_x*patchsize+patchsize\n",
        "      nsy = new_cell_y*patchsize\n",
        "      ney = new_cell_y*patchsize+patchsize\n",
        "      nsx = new_cell_x*patchsize\n",
        "      nex = new_cell_x*patchsize+patchsize\n",
        "\n",
        "      current_img0[nsy:ney,nsx:nex] = source_png0[tsy:tey,tsx:tex]\n",
        "      current_img1[nsy:ney,nsx:nex] = source_png1[tsy:tey,tsx:tex]\n",
        "\n",
        "      #write uv\n",
        "\n",
        "      uv0_y = (new_cell_y*patchsize+0.5)/texture_size\n",
        "      uv0_x = (new_cell_x*patchsize+0.5)/texture_size\n",
        "\n",
        "      uv1_y = ((new_cell_y+1)*patchsize-0.5)/texture_size\n",
        "      uv1_x = (new_cell_x*patchsize+0.5)/texture_size\n",
        "\n",
        "      uv2_y = (new_cell_y*patchsize+0.5)/texture_size\n",
        "      uv2_x = ((new_cell_x+1)*patchsize-0.5)/texture_size\n",
        "\n",
        "      uv3_y = ((new_cell_y+1)*patchsize-0.5)/texture_size\n",
        "      uv3_x = ((new_cell_x+1)*patchsize-0.5)/texture_size\n",
        "\n",
        "      current_obj.write(\"vt %.6f %.6f\\n\" % (uv0_x,1-uv0_y))\n",
        "      current_obj.write(\"vt %.6f %.6f\\n\" % (uv1_x,1-uv1_y))\n",
        "      current_obj.write(\"vt %.6f %.6f\\n\" % (uv2_x,1-uv2_y))\n",
        "      current_obj.write(\"vt %.6f %.6f\\n\" % (uv3_x,1-uv3_y))\n",
        "\n",
        "\n",
        "  elif line[0] == 'f':\n",
        "    f1 = int(line[1].split(\"/\")[0])-current_v_offset\n",
        "    f2 = int(line[2].split(\"/\")[0])-current_v_offset\n",
        "    f3 = int(line[3].split(\"/\")[0])-current_v_offset\n",
        "    current_obj.write(\"f %d/%d %d/%d %d/%d\\n\" % (f1,f1,f2,f2,f3,f3))\n",
        "\n",
        "    #create new texture image if current is fill\n",
        "    if i==len(lines)-1 or (lines[i+1].split()[0]!='f' and current_quad_count==texture_patch_size*texture_patch_size):\n",
        "      current_obj.close()\n",
        "\n",
        "      # the following is only required for iphone\n",
        "      # because iphone runs alpha test before the fragment shader\n",
        "      # the viewer code is also changed accordingly\n",
        "      current_img0[:,:,3] = current_img0[:,:,3]//2+128\n",
        "      current_img1[:,:,3] = current_img1[:,:,3]//2+128\n",
        "\n",
        "      cv2.imwrite(target_dir+\"/shape\"+str(current_img_idx)+\".pngfeat0.png\", current_img0, [cv2.IMWRITE_PNG_COMPRESSION,9])\n",
        "      cv2.imwrite(target_dir+\"/shape\"+str(current_img_idx)+\".pngfeat1.png\", current_img1, [cv2.IMWRITE_PNG_COMPRESSION,9])\n",
        "      current_img_idx += 1\n",
        "      current_img0 = np.zeros([texture_size,texture_size,4],np.uint8)\n",
        "      current_img1 = np.zeros([texture_size,texture_size,4],np.uint8)\n",
        "      current_quad_count = 0\n",
        "      if i!=len(lines)-1:\n",
        "        current_obj = open(target_dir+\"/shape\"+str(current_img_idx)+\".obj\",'w')\n",
        "      current_v_offset += current_v_count\n",
        "      current_v_count = 0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#copy the small MLP\n",
        "source_json_dir = obj_save_dir+\"/mlp.json\"\n",
        "current_json_dir = target_dir+\"/mlp.json\"\n",
        "fin = open(source_json_dir,'r')\n",
        "line = fin.readline()\n",
        "fin.close()\n",
        "fout = open(current_json_dir,'w')\n",
        "fout.write(line.strip()[:-1])\n",
        "fout.write(\",\\\"obj_num\\\": \"+str(current_img_idx)+\"}\")\n",
        "fout.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-laQmhfQnvFs"
      },
      "outputs": [],
      "source": [
        "#%% --------------------------------------------------------------------------------\n",
        "# # Save images for testing\n",
        "#%%\n",
        "\n",
        "pred_frames = np.array(frames,np.float32)\n",
        "gt_frames = np.array(data['test']['images'],np.float32)\n",
        "\n",
        "pickle.dump(pred_frames, open(\"pred_frames.pkl\", \"wb\"))\n",
        "pickle.dump(gt_frames, open(\"gt_frames.pkl\", \"wb\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KFhiIYnDVkfn"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}